[
    {
        "title": "Prediction and risk assessment of sepsis-associated encephalopathy in ICU based on interpretable machine learning",
        "link": "https://www.nature.com/articles/s41598-022-27134-6",
        "publication_date": "31 Dec 2022",
        "abstract": "Sepsis-associated encephalopathy (SAE) is a major complication of sepsis and is associated with high mortality and poor long-term prognosis. The purpose of this study is to develop interpretable machine learning models to predict the occurrence of SAE after ICU admission and implement the individual prediction and analysis. Patients with sepsis admitted to ICU were included. SAE was diagnosed as glasgow coma score (GCS) less than 15. Statistical analysis at baseline was performed between SAE and non-SAE. Six machine learning classifiers were employed to predict the occurrence of SAE, and the adjustment of model super parameters was performed by using Bayesian optimization method. Finally, the optimal algorithm was selected according to the prediction efficiency. In addition, professional physicians were invited to evaluate our model prediction results for further quantitative assessment of the model interpretability. The preliminary analysis of variance showed significant differences in the incidence of SAE among patients with pathogen infection. There were significant differences in physical indicators like respiratory rate, temperature, SpO2 and mean arterial pressure (P < 0.001). In addition, the laboratory results were also significantly different. The optimal classification model (XGBoost) indicated that the best risk factors (cut-off points) were creatinine (1.1 mg/dl), mean respiratory rate (18), pH (7.38), age (72), chlorine (101 mmol/L), sodium (138.5 k/ul), SAPSII score (23), platelet count (160), and phosphorus (2.4 and 5.0 mg/dL). The ranked features derived from the best model (AUC is 0.8837) were mechanical ventilation, duration of mechanical ventilation, phosphorus, SOFA score, and vasopressin usage. The SAE risk prediction model based on XGBoost created here can make very accurate predictions using simple indicators and support the visual explanation. The interpretable model was effectively evaluated by professional physicians and can help them predict the occurrence of SAE more intuitively.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [
                "membership inference"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Reverse engineering for reconstructing baseline features of dry age-related macular degeneration in optical coherence tomography",
        "link": "https://www.nature.com/articles/s41598-022-27140-8",
        "publication_date": "31 Dec 2022",
        "abstract": "Age-related macular degeneration (AMD) is the most widespread cause of blindness and the identification of baseline AMD features or biomarkers is critical for early intervention. Optical coherence tomography (OCT) imaging produces a 3D volume consisting of cross sections of retinal tissue while fundus fluorescence (FAF) imaging produces a 2D mapping of retina. FAF has been a good standard for assessing dry AMD late-stage geographic atrophy (GA) while OCT has been used for assessing early AMD biomarkers beyond as well. However, previous approaches in large extent defined AMD features subjectively based on clinicians’ observation. Deep learning—an objective artificial intelligence approach, may enable to discover ’true’ salient AMD features. We develop a novel reverse engineering approach which bases on the backbone of a fully convolutional neural network to objectively identify and visualize AMD early biomarkers in OCT from baseline exams before significant atrophy occurs. Utilizing manually annotated GA regions on FAF from a follow-up visit as ground truth, we segment GA regions and reconstruct early AMD features in baseline OCT volumes. In this preliminary exploration, compared with ground truth, we achieve baseline GA segmentation accuracy of 0.95 and overlapping ratio of 0.65. The reconstructions consistently highlight that large druse and druse clusters with or without mixed hyper-reflective focus lesion on baseline OCT cause the conversion of GA after 12 months. However, hyper-reflective focus lesions and subretinal drusenoid deposit lesions alone are not seen such conversion after 12 months. Further research with larger dataset would be needed to verify these findings.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Revelation of microcracks as tooth structural element by X-ray tomography and machine learning",
        "link": "https://www.nature.com/articles/s41598-022-27062-5",
        "publication_date": "28 Dec 2022",
        "abstract": "Although teeth microcracks (MCs) have long been considered more of an aesthetic problem, their exact role in the structure of a tooth and impact on its functionality is still unknown. The aim of this study was to reveal the possibilities of an X-ray micro-computed tomography (\\(\\mu\\)CT) in combination with convolutional neural network (CNN) assisted voxel classification and volume segmentation for three-dimensional (3D) qualitative analysis of tooth microstructure and verify this approach with four extracted human premolars. Samples were scanned using a \\(\\mu\\)CT instrument (Xradia 520 Versa; ZEISS) and segmented with CNN to identify enamel, dentin, and cracks. A new CNN image segmentation model was trained based on “Multiclass semantic segmentation using DeepLabV3+” example and was implemented with “TensorFlow”. The technique which was used allowed 3D characterization of all MCs of a tooth, regardless of the volume of the tooth in which they begin and extend, and the evaluation of the arrangement of cracks and their structural features. The proposed method revealed an intricate star-shaped network of MCs covering most of the inner tooth, and the main crack planes in all samples were arranged radially in two almost perpendicular directions, suggesting that the cracks could be considered as a planar structure.",
        "conclusions": "The presented novel technique—using X-ray \\(\\mu\\)CT in combination with CNN assisted segmentation - reveals the possibilities for a non-destructive and comprehensive 3D qualitative analysis of tooth microstructure. This method allows 3D characterization of all MCs of a tooth, regardless of the volume of the tooth in which they begin and extend, as well as the evaluation of the arrangement of cracks and their structural features. Anatomical characteristics of the tooth, such as enamel thickness, surface convexity or roughness, should no longer be a barrier to analyzing MCs with the described technique.Using the proposed approach, a network of MCs inside all four healthy teeth (with or without visible MCs on the buccal surface) has been revealed, suggesting that the cracks could be considered as one of the structural and possibly functional (i.e. serving the function of redistribution of forces) elements of the tooth, with a protective, rather than a damaging function.Detailed volumetric imaging of the MCs of a tooth expands our understanding of the cracking pattern in natural hard materials and allows us to gain more insight into how biologically inspired structures could be designed to predict the propagation of cracks in solid materials. From a clinical point of view, there is a need to revise the definition of MC that has been used so far, to re-evaluate the role and impact of these cracks on the integrity and longevity of the tooth, and to develop new algorithms for the monitoring and treatment of teeth with MCs in daily clinical practice.",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Diagnostic potential of the amniotic fluid cells transcriptome in deciphering mendelian disease: a proof-of-concept",
        "link": "https://www.nature.com/articles/s41525-022-00347-4",
        "publication_date": "28 Dec 2022",
        "abstract": "RNA sequencing (RNA-seq) is emerging in genetic diagnoses as it provides functional support for the interpretation of variants of uncertain significance. However, the use of amniotic fluid (AF) cells for RNA-seq has not yet been explored. Here, we examined the expression of clinically relevant genes in AF cells (n = 48) compared with whole blood and fibroblasts. The number of well-expressed genes in AF cells was comparable to that in fibroblasts and much higher than that in blood across different disease categories. We found AF cells RNA-seq feasible and beneficial in prenatal diagnosis (n = 4) as transcriptomic data elucidated the molecular consequence leading to the pathogenicity upgrade of variants in CHD7 and COL1A2 and revising the in silico prediction of a variant in MYRF. AF cells RNA-seq could become a reasonable choice for postnatal patients with advantages over fibroblasts and blood as it prevents invasive procedures.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting graft failure in pediatric liver transplantation based on early biomarkers using machine learning models",
        "link": "https://www.nature.com/articles/s41598-022-25900-0",
        "publication_date": "27 Dec 2022",
        "abstract": "The early detection of graft failure in pediatric liver transplantation is crucial for appropriate intervention. Graft failure is associated with numerous perioperative risk factors. This study aimed to develop an individualized predictive model for 90-days graft failure in pediatric liver transplantation using machine learning methods. We conducted a single-center retrospective cohort study. A total of 87 liver transplantation cases performed in patients aged < 12 years at the Severance Hospital between January 2010 and September 2020 were included as data samples. Preoperative conditions of recipients and donors, intraoperative care, postoperative serial laboratory parameters, and events observed within seven days of surgery were collected as features. A least absolute shrinkage and selection operator (LASSO) -based method was used for feature selection to overcome the high dimensionality and collinearity of variables. Among 146 features, four variables were selected as the resultant features, namely, preoperative hepatic encephalopathy, sodium level at the end of surgery, hepatic artery thrombosis, and total bilirubin level on postoperative day 7. These features were selected from different times and represent distinct clinical aspects. The model with logistic regression demonstrated the best prediction performance among various machine learning methods tested (area under the receiver operating characteristic curve (AUROC) = 0.898 and area under the precision–recall curve (AUPR) = 0.882). The risk scoring system developed based on the logistic regression model showed an AUROC of 0.910 and an AUPR of 0.830. Together, the prediction of graft failure in pediatric liver transplantation using the proposed machine learning model exhibited superior discrimination power and, therefore, can provide valuable information to clinicians for their decision making during the postoperative management of the patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A standalone incompatible insect technique enables mosquito suppression in the urban subtropics",
        "link": "https://www.nature.com/articles/s42003-022-04332-6",
        "publication_date": "27 Dec 2022",
        "abstract": "The strong suppression of Aedes albopictus on two Guangzhou islands in China has been successfully achieved by releasing males with an artificial triple-Wolbachia infection. However, it requires the use of radiation to sterilize residual females to prevent population replacement. To develop a highly effective tool for dengue control, we tested a standalone incompatible insect technique (IIT) to control A. albopictus in the urban area of Changsha, an inland city where dengue recently emerged. Male mosquitoes were produced in a mass rearing facility in Guangzhou and transported over 670 km under low temperature to the release site. After a once-per-week release with high numbers of males (phase I) and a subsequent twice-per-week release with low numbers of males (phase II), the average numbers of hatched eggs and female adults collected weekly per trap were reduced by 97% and 85%, respectively. The population suppression caused a 94% decrease in mosquito biting at the release site compared to the control site. Remarkably, this strong suppression was achieved using only 28% of the number of males released in a previous trial. Despite the lack of irradiation to sterilize residual females, no triple-infected mosquitoes were detected in the field post release based on the monitoring of adult and larval A. albopictus populations for two years, indicating that population replacement was prevented. Our results support the feasibility of implementing a standalone IIT for dengue control in urban areas.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "A new strategy for the early detection of alzheimer disease stages using multifractal geometry analysis based on K-Nearest Neighbor algorithm",
        "link": "https://www.nature.com/articles/s41598-022-26958-6",
        "publication_date": "26 Dec 2022",
        "abstract": "Alzheimer's Disease (AD) is considered one of the most diseases that much prevalent among elderly people all over the world. AD is an incurable neurodegenerative disease affecting cognitive functions and were characterized by progressive and collective functions deteriorating. Remarkably, early detection of AD is essential for the development of new and invented treatment strategies. As Dementia causes irreversible damage to the brain neurons and leads to changes in its structure that can be described adequately within the framework of multifractals. Hence, the present work focus on developing a promising and efficient computing technique to pre-process and classify the AD disease especially in the early stages using multifractal geometry to extract the most changeable features due to AD. Then, A machine learning classification algorithm (K-Nearest Neighbor) has been implemented in order to classify and detect the main four early stages of AD. Two datasets have been used to ensure the validation of the proposed methodology. The proposed technique has achieved 99.4% accuracy and 100% sensitivity. The comparative results show that the proposed classification technique outperforms is recent techniques in terms of performance measures.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A large language model for electronic health records",
        "link": "https://www.nature.com/articles/s41746-022-00742-2",
        "publication_date": "26 Dec 2022",
        "abstract": "There is an increasing interest in developing artificial intelligence (AI) systems to process and interpret electronic health records (EHRs). Natural language processing (NLP) powered by pretrained language models is the key technology for medical AI systems utilizing clinical narratives. However, there are few clinical language models, the largest of which trained in the clinical domain is comparatively small at 110 million parameters (compared with billions of parameters in the general domain). It is not clear how large clinical language models with billions of parameters can help medical AI systems utilize unstructured EHRs. In this study, we develop from scratch a large clinical language model—GatorTron—using >90 billion words of text (including >82 billion words of de-identified clinical text) and systematically evaluate it on five clinical NLP tasks including clinical concept extraction, medical relation extraction, semantic textual similarity, natural language inference (NLI), and medical question answering (MQA). We examine how (1) scaling up the number of parameters and (2) scaling up the size of the training data could benefit these NLP tasks. GatorTron models scale up the clinical language model from 110 million to 8.9 billion parameters and improve five clinical NLP tasks (e.g., 9.6% and 9.5% improvement in accuracy for NLI and MQA), which can be applied to medical AI systems to improve healthcare delivery. The GatorTron models are publicly available at: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/gatortron_og.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development and validation of a predictive scoring system for in-hospital mortality in COVID-19 Egyptian patients: a retrospective study",
        "link": "https://www.nature.com/articles/s41598-022-26471-w",
        "publication_date": "26 Dec 2022",
        "abstract": "SARS-CoV-2 virus has rapidly spread worldwide since December 2019, causing COVID-19 disease. In-hospital mortality is a common indicator for evaluating treatment outcomes. Therefore, the developing and validating a simple score system from observational data could assist in modulating the management procedures. A retrospective cohort study included all data records of patients with positive PCR for SARS-CoV-2. The factors that associated with mortality were analyzed, then allocation of potential predictors of mortality was executed using different logistic regression modeling, subsequently scoring system was developed from the most weighted predictors. The mortality rate of patients with COVID-19 pneumonia was 28.5% and 28.74%, respectively. The most significant factors that affected in-hospital mortality were old age (> 60 years), delay in hospital admission (> 4 days), high neutrophil/lymphocyte ratio “NLR” (> 3); higher computed tomography severity score; and CT-SS (> 20), in addition to using remdesivir and tocilizumab in the treatment protocol (P < 0.001 for all). The validity of the newly performed score was significant; the AUC was 85%, P < 0.001, and its prognostic utility was good; the AUC was 75%, P < 0.001. The prognostic utility of newly developed score system (EGY.Score) was excellent and could be used to adjust the treatment strategy of highly at-risk patients with COVID-19 pneumonia.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Transition in vaginal Lactobacillus species during pregnancy and prediction of preterm birth in Korean women",
        "link": "https://www.nature.com/articles/s41598-022-26058-5",
        "publication_date": "24 Dec 2022",
        "abstract": "The predominance of vaginal Lactobacillus species, specifically L. crispatus, is important for pregnancy maintenance, but varies by race. The composition of the vaginal microbiome can affect susceptibility to adverse pregnancy outcomes. We performed 16S rRNA gene amplicon sequencing on vaginal swabs taken from Korean pregnant women. Here, we report the transition of Lactobacillus spp. in samples of full-term birth (FTB) collected longitudinally in the second and third trimesters of pregnancy in a cohort study (n = 23) and their association with Lactobacillus abundance and preterm birth (PTB) in a case–control study (n = 200). Lactobacillus species, which was dominant in FTB samples including those that received interventions in the second trimester, did not change until 37 weeks of gestation. However, L. crispatus was replaced by other Lactobacillus species after 37 weeks. The PTB risk showed a closer association with the Lactobacillus abundance than with community state type determined by Lactobacillus species. PTB was associated with less than 90% of Lactobacillus abundance and an increase in Ureplasma parvum in the second trimester. Thus, the vaginal microbiome may change in preparation for childbirth in response to multiple intrinsic factors after 37 weeks of gestation. Monitoring the Lactobacillus abundance may help improve the reliability of microbial PTB biomarkers.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A molecular barcode and web-based data analysis tool to identify imported Plasmodium vivax malaria",
        "link": "https://www.nature.com/articles/s42003-022-04352-2",
        "publication_date": "23 Dec 2022",
        "abstract": "Traditionally, patient travel history has been used to distinguish imported from autochthonous malaria cases, but the dormant liver stages of Plasmodium vivax confound this approach. Molecular tools offer an alternative method to identify, and map imported cases. Using machine learning approaches incorporating hierarchical fixation index and decision tree analyses applied to 799 P. vivax genomes from 21 countries, we identified 33-SNP, 50-SNP and 55-SNP barcodes (GEO33, GEO50 and GEO55), with high capacity to predict the infection’s country of origin. The Matthews correlation coefficient (MCC) for an existing, commonly applied 38-SNP barcode (BR38) exceeded 0.80 in 62% countries. The GEO panels outperformed BR38, with median MCCs > 0.80 in 90% countries at GEO33, and 95% at GEO50 and GEO55. An online, open-access, likelihood-based classifier framework was established to support data analysis (vivaxGEN-geo). The SNP selection and classifier methods can be readily amended for other use cases to support malaria control programs.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Surgical gestures as a method to quantify surgical performance and predict patient outcomes",
        "link": "https://www.nature.com/articles/s41746-022-00738-y",
        "publication_date": "22 Dec 2022",
        "abstract": "How well a surgery is performed impacts a patient’s outcomes; however, objective quantification of performance remains an unsolved challenge. Deconstructing a procedure into discrete instrument-tissue “gestures” is a emerging way to understand surgery. To establish this paradigm in a procedure where performance is the most important factor for patient outcomes, we identify 34,323 individual gestures performed in 80 nerve-sparing robot-assisted radical prostatectomies from two international medical centers. Gestures are classified into nine distinct dissection gestures (e.g., hot cut) and four supporting gestures (e.g., retraction). Our primary outcome is to identify factors impacting a patient’s 1-year erectile function (EF) recovery after radical prostatectomy. We find that less use of hot cut and more use of peel/push are statistically associated with better chance of 1-year EF recovery. Our results also show interactions between surgeon experience and gesture types—similar gesture selection resulted in different EF recovery rates dependent on surgeon experience. To further validate this framework, two teams independently constructe distinct machine learning models using gesture sequences vs. traditional clinical features to predict 1-year EF. In both models, gesture sequences are able to better predict 1-year EF (Team 1: AUC 0.77, 95% CI 0.73–0.81; Team 2: AUC 0.68, 95% CI 0.66–0.70) than traditional clinical features (Team 1: AUC 0.69, 95% CI 0.65–0.73; Team 2: AUC 0.65, 95% CI 0.62–0.68). Our results suggest that gestures provide a granular method to objectively indicate surgical performance and outcomes. Application of this methodology to other surgeries may lead to discoveries on methods to improve surgery.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning-assisted system using digital facial images to predict the clinical activity score in thyroid-associated orbitopathy",
        "link": "https://www.nature.com/articles/s41598-022-25887-8",
        "publication_date": "21 Dec 2022",
        "abstract": "Although the clinical activity score (CAS) is a validated scoring system for identifying disease activity of thyroid-associated orbitopathy (TAO), it may produce differing results depending on the evaluator, and an experienced ophthalmologist is required for accurate evaluation. In this study, we developed a machine learning (ML)-assisted system to mimic an expert’s CAS assessment using digital facial images and evaluated its accuracy for predicting the CAS and diagnosing active TAO (CAS ≥ 3). An ML-assisted system was designed to assess five CAS components related to inflammatory signs (redness of the eyelids, redness of the conjunctiva, swelling of the eyelids, inflammation of the caruncle and/or plica, and conjunctival edema) in patients’ facial images and to predict the CAS by considering two components of subjective symptoms (spontaneous retrobulbar pain and pain on gaze). To train and test the system, 3,060 cropped images from 1020 digital facial images of TAO patients were used. The reference CAS for each image was scored by three ophthalmologists, each with > 15 years of clinical experience. We repeated the experiments for 30 randomly split training and test sets at a ratio of 8:2. The sensitivity and specificity of the ML-assisted system for diagnosing active TAO were 72.7% and 83.2% in the test set constructed from the entire dataset. For the test set constructed from the dataset with consistent results for the three ophthalmologists, the sensitivity and specificity for diagnosing active TAO were 88.1% and 86.9%. In the test sets from the entire dataset and from the dataset with consistent results, 40.0% and 49.9% of the predicted CAS values were the same as the reference CAS, respectively. The system predicted the CAS within 1 point of the reference CAS in 84.6% and 89.0% of cases when tested using the entire dataset and in the dataset with consistent results, respectively. An ML-assisted system estimated the clinical activity of TAO and detect inflammatory active TAO with reasonable accuracy. The accuracy could be improved further by obtaining more data. This ML-assisted system can help evaluate the disease activity consistently as well as accurately and enable the early diagnosis and timely treatment of active TAO.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Identifying and evaluating barriers for the implementation of machine learning in the intensive care unit",
        "link": "https://www.nature.com/articles/s43856-022-00225-1",
        "publication_date": "21 Dec 2022",
        "abstract": "Despite apparent promise and the availability of numerous examples in the literature, machine learning models are rarely used in practice in ICU units. This mismatch suggests that there are poorly understood barriers preventing uptake, which we aim to identify.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient",
                "healthcare practitioner"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Early prediction of upper limb functioning after stroke using clinical bedside assessments: a prospective longitudinal study",
        "link": "https://www.nature.com/articles/s41598-022-26585-1",
        "publication_date": "21 Dec 2022",
        "abstract": "Early and accurate prediction of recovery is needed to assist treatment planning and inform patient selection in clinical trials. This study aimed to develop a prediction algorithm using a set of simple early clinical bedside measures to predict upper limb capacity at 3-months post-stroke. A secondary analysis of Stroke Arm Longitudinal Study at Gothenburg University (SALGOT) included 94 adults (mean age 68 years) with upper limb impairment admitted to stroke unit). Cluster analysis was used to define the endpoint outcome strata according to the 3-months Action Research Arm Test (ARAT) scores. Modelling was carried out in a training (70%) and testing set (30%) using traditional logistic regression, random forest models. The final algorithm included 3 simple bedside tests performed 3-days post stroke: ability to grasp, to produce any measurable grip strength and abduct/elevate shoulder. An 86–94% model sensitivity, specificity and accuracy was reached for differentiation between poor, limited and good outcome. Additional measurement of grip strength at 4 weeks post-stroke and haemorrhagic stroke explained the underestimated classifications. External validation of the model is recommended. Simple bedside assessments have advantages over more lengthy and complex assessments and could thereby be integrated into routine clinical practice to aid therapy decisions, guide patient selection in clinical trials and used in data registries.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning-derived gut microbiome signature predicts fatty liver disease in the presence of insulin resistance",
        "link": "https://www.nature.com/articles/s41598-022-26102-4",
        "publication_date": "17 Dec 2022",
        "abstract": "A simple predictive biomarker for fatty liver disease is required for individuals with insulin resistance. Here, we developed a supervised machine learning-based classifier for fatty liver disease using fecal 16S rDNA sequencing data. Based on the Kangbuk Samsung Hospital cohort (n = 777), we generated a random forest classifier to predict fatty liver diseases in individuals with or without insulin resistance (n = 166 and n = 611, respectively). The model performance was evaluated based on metrics, including accuracy, area under receiver operating curve (AUROC), kappa, and F1-score. The developed classifier for fatty liver diseases performed better in individuals with insulin resistance (AUROC = 0.77). We further optimized the classifiers using genetic algorithm. The improved classifier for insulin resistance, consisting of ten microbial genera, presented an advanced classification (AUROC = 0.93), whereas the improved classifier for insulin-sensitive individuals failed to distinguish participants with fatty liver diseases from the healthy. The classifier for individuals with insulin resistance was comparable or superior to previous methods predicting fatty liver diseases (accuracy = 0.83, kappa = 0.50, F1-score = 0.89), such as the fatty liver index. We identified the ten genera as a core set from the human gut microbiome, which could be a diagnostic biomarker of fatty liver diseases for insulin resistant individuals. Collectively, these findings indicate that the machine learning classifier for fatty liver diseases in the presence of insulin resistance is comparable or superior to commonly used methods.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Label-free testing strategy to evaluate packed red blood cell quality before transfusion to leukemia patients",
        "link": "https://www.nature.com/articles/s41598-022-26309-5",
        "publication_date": "17 Dec 2022",
        "abstract": "Patients worldwide require therapeutic transfusions of packed red blood cells (pRBCs), which is applied to the high-risk patients who need periodic transfusions due to leukemia,  lymphoma, myeloma and other blood diseases or disorders. Contrary to the general hospital population where the transfusions are carried out mainly for healthy trauma patients, in case of high-risk patients the proper quality of pRBCs is crucial. This leads to an increased demand for efficient technology providing information on the pRBCs alterations deteriorating their quality. Here we present the design of an innovative, label-free, noninvasive, rapid Raman spectroscopy-based method for pRBCs quality evaluation, starting with the description of sample measurement and data analysis, through correlation of spectroscopic results with reference techniques' outcomes, and finishing with methodology verification and its application in clinical conditions. We have shown that Raman spectra collected from the pRBCs supernatant mixture with a proper chemometric analysis conducted for a minimum one ratio of integral intensities of the chosen Raman marker bands within the spectrum allow evaluation of the pRBC quality in a rapid, noninvasive, and free-label manner, without unsealing the pRBCs bag. Subsequently, spectroscopic data were compared with predefined reference values, either from pRBCs expiration or those defining the pRBCs quality, allowing to assess their utility for transfusion to patients with acute myeloid leukemia (AML) and lymphoblastic leukemia (ALL).",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Periportal steatosis in mice affects distinct parameters of pericentral drug metabolism",
        "link": "https://www.nature.com/articles/s41598-022-26483-6",
        "publication_date": "17 Dec 2022",
        "abstract": "Little is known about the impact of morphological disorders in distinct zones on metabolic zonation. It was described recently that periportal fibrosis did affect the expression of CYP proteins, a set of pericentrally located drug-metabolizing enzymes. Here, we investigated whether periportal steatosis might have a similar effect. Periportal steatosis was induced in C57BL6/J mice by feeding a high-fat diet with low methionine/choline content for either two or four weeks. Steatosis severity was quantified using image analysis. Triglycerides and CYP activity were quantified in photometric or fluorometric assay. The distribution of CYP3A4, CYP1A2, CYP2D6, and CYP2E1 was visualized by immunohistochemistry. Pharmacokinetic parameters of test drugs were determined after injecting a drug cocktail (caffeine, codeine, and midazolam). The dietary model resulted in moderate to severe mixed steatosis confined to periportal and midzonal areas. Periportal steatosis did not affect the zonal distribution of CYP expression but the activity of selected CYPs was associated with steatosis severity. Caffeine elimination was accelerated by microvesicular steatosis, whereas midazolam elimination was delayed in macrovesicular steatosis. In summary, periportal steatosis affected parameters of pericentrally located drug metabolism. This observation calls for further investigations of the highly complex interrelationship between steatosis and drug metabolism and underlying signaling mechanisms.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The influence of patient characteristics on the alarm rate in intensive care units: a retrospective cohort study",
        "link": "https://www.nature.com/articles/s41598-022-26261-4",
        "publication_date": "16 Dec 2022",
        "abstract": "Intensive care units (ICU) are often overflooded with alarms from monitoring devices which constitutes a hazard to both staff and patients. To date, the suggested solutions to excessive monitoring alarms have remained on a research level. We aimed to identify patient characteristics that affect the ICU alarm rate with the goal of proposing a straightforward solution that can easily be implemented in ICUs. Alarm logs from eight adult ICUs of a tertiary care university-hospital in Berlin, Germany were retrospectively collected between September 2019 and March 2021. Adult patients admitted to the ICU with at least 24 h of continuous alarm logs were included in the study. The sum of alarms per patient per day was calculated. The median was 119. A total of 26,890 observations from 3205 patients were included. 23 variables were extracted from patients' electronic health records (EHR) and a multivariable logistic regression was performed to evaluate the association of patient characteristics and alarm rates. Invasive blood pressure monitoring (adjusted odds ratio (aOR) 4.68, 95%CI 4.15–5.29, p < 0.001), invasive mechanical ventilation (aOR 1.24, 95%CI 1.16–1.32, p < 0.001), heart failure (aOR 1.26, 95%CI 1.19–1.35, p < 0.001), chronic renal failure (aOR 1.18, 95%CI 1.10–1.27, p < 0.001), hypertension (aOR 1.19, 95%CI 1.13–1.26, p < 0.001), high RASS (aOR 1.22, 95%CI 1.18–1.25, p < 0.001) and scheduled surgical admission (aOR 1.22, 95%CI 1.13–1.32, p < 0.001) were significantly associated with a high alarm rate. Our study suggests that patient-specific alarm management should be integrated in the clinical routine of ICUs. To reduce the overall alarm load, particular attention regarding alarm management should be paid to patients with invasive blood pressure monitoring, invasive mechanical ventilation, heart failure, chronic renal failure, hypertension, high RASS or scheduled surgical admission since they are more likely to have a high contribution to noise pollution, alarm fatigue and hence compromised patient safety in ICUs.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The PAD-US-AR dataset: Measuring accessible and recreational parks in the contiguous United States",
        "link": "https://www.nature.com/articles/s41597-022-01857-7",
        "publication_date": "16 Dec 2022",
        "abstract": "Most spatial epidemiological studies of nature-health relationships use generalized greenspace measures. For instance, coarse-resolution spatial data containing normalized difference vegetative index (NDVI) values are prominent despite criticisms, such as the inability to restrain exposure estimates to public and private land. Non-threatening natural landscapes can improve health by building capacities for health-promoting behaviors. Recreational and accessible parks may best activate such behaviors. We curated the Parks and Protected Areas Database of the U.S. (PAD-US) to identify parks that are accessible for outdoor recreation. Our title adds “AR” to “PAD-US” where A = Accessible and R = Recreational. We validated the PAD-US-AR by comparisons with greenspace datasets and sociodemographics, which demonstrated its uniqueness from other commonly employed metrics of nature exposure. The PAD-US-AR presents reliable estimates of parks in the contiguous U.S. that are accessible for outdoor recreation. It has strong associations with home prices, shares of female residents, and shares of older residents. This dataset can accompany other nature exposure metrics in environmental epidemiology and allied research fields.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Rebubbling and graft detachment in Descemet membrane endothelial keratoplasty using a standardised protocol",
        "link": "https://www.nature.com/articles/s41433-022-02362-2",
        "publication_date": "15 Dec 2022",
        "abstract": "To analyse risk factors and long-term outcomes after rebubbling and graft detachment in Descemet membrane endothelial keratoplasty (DMEK).",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Expert-level aspiration and penetration detection during flexible endoscopic evaluation of swallowing with artificial intelligence-assisted diagnosis",
        "link": "https://www.nature.com/articles/s41598-022-25618-z",
        "publication_date": "15 Dec 2022",
        "abstract": "Flexible endoscopic evaluation of swallowing (FEES) is considered the gold standard in diagnosing oropharyngeal dysphagia. Recent advances in deep learning have led to a resurgence of artificial intelligence-assisted computer-aided diagnosis (AI-assisted CAD) for a variety of applications. AI-assisted CAD would be a remarkable benefit in providing medical services to populations with inadequate access to dysphagia experts, especially in aging societies. This paper presents an AI-assisted CAD named FEES-CAD for aspiration and penetration detection on video recording during FEES. FEES-CAD segments the input FEES video and classifies penetration, aspiration, residue in the vallecula, and residue in the hypopharynx based on the segmented FEES video. We collected and annotated FEES videos from 199 patients to train the network and tested the performance of FEES-CAD using FEES videos from other 40 patients. These patients consecutively underwent FEES between December 2016 and August 2019 at Fukushima Medical University Hospital. FEES videos were deidentified, randomized, and rated by FEES-CAD and laryngologists with over 15 years of experience in performing FEES. FEES-CAD achieved an average Dice similarity coefficient of 98.6\\(\\%\\). FEES-CAD achieved expert-level accuracy performance on penetration (92.5\\(\\%\\)), aspiration (92.5\\(\\%\\)), residue in the vallecula (100\\(\\%\\)), and residue in the hypopharynx (87.5\\(\\%\\)) classification tasks. To the best of our knowledge, FEES-CAD is the first CNN-based system that achieves expert-level performance in detecting aspiration and penetration.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting multipotency of human adult stem cells derived from various donors through deep learning",
        "link": "https://www.nature.com/articles/s41598-022-25423-8",
        "publication_date": "14 Dec 2022",
        "abstract": "Adult stem cell-based therapeutic approaches have great potential in regenerative medicine because of their immunoregulatory properties and multidifferentiation capacity. Nevertheless, the outcomes of stem cell‑based therapies to date have shown inconsistent efficacy owing to donor variation, thwarting the expectation of clinical effects. However, such donor dependency has been elucidated by biological consequences that current research could not predict. Here, we introduce cellular morphology-based prediction to determine the multipotency rate of human nasal turbinate stem cells (hNTSCs), aiming to predict the differentiation rate of keratocyte progenitors. We characterized the overall genes and morphologies of hNTSCs from five donors and compared stemness-related properties, including multipotency and specific lineages, using mRNA sequencing. It was demonstrated that transformation factors affecting the principal components were highly related to cell morphology. We then performed a convolutional neural network-based analysis, which enabled us to assess the multipotency level of each cell group based on their morphologies with 85.98% accuracy. Surprisingly, the trend in expression levels after ex vivo differentiation matched well with the deep learning prediction. These results suggest that AI‑assisted cellular behavioral prediction can be utilized to perform quantitative, non-invasive, single-cell, and multimarker characterizations of live stem cells for improved quality control in clinical cell therapies.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The WHO estimates of excess mortality associated with the COVID-19 pandemic",
        "link": "https://www.nature.com/articles/s41586-022-05522-2",
        "publication_date": "14 Dec 2022",
        "abstract": "The World Health Organization has a mandate to compile and disseminate statistics on mortality, and we have been tracking the progression of the COVID-19 pandemic since the beginning of 20201. Reported statistics on COVID-19 mortality are problematic for many countries owing to variations in testing access, differential diagnostic capacity and inconsistent certification of COVID-19 as cause of death. Beyond what is directly attributable to it, the pandemic has caused extensive collateral damage that has led to losses of lives and livelihoods. Here we report a comprehensive and consistent measurement of the impact of the COVID-19 pandemic by estimating excess deaths, by month, for 2020 and 2021. We predict the pandemic period all-cause deaths in locations lacking complete reported data using an overdispersed Poisson count framework that applies Bayesian inference techniques to quantify uncertainty. We estimate 14.83 million excess deaths globally, 2.74 times more deaths than the 5.42 million reported as due to COVID-19 for the period. There are wide variations in the excess death estimates across the six World Health Organization regions. We describe the data and methods used to generate these estimates and highlight the need for better reporting where gaps persist. We discuss various summary measures, and the hazards of ranking countries’ epidemic responses.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Optimal deep brain stimulation sites and networks for stimulation of the fornix in Alzheimer’s disease",
        "link": "https://www.nature.com/articles/s41467-022-34510-3",
        "publication_date": "14 Dec 2022",
        "abstract": "Deep brain stimulation (DBS) to the fornix is an investigational treatment for patients with mild Alzheimer’s Disease. Outcomes from randomized clinical trials have shown that cognitive function improved in some patients but deteriorated in others. This could be explained by variance in electrode placement leading to differential engagement of neural circuits. To investigate this, we performed a post-hoc analysis on a multi-center cohort of 46 patients with DBS to the fornix (NCT00658125, NCT01608061). Using normative structural and functional connectivity data, we found that stimulation of the circuit of Papez and stria terminalis robustly associated with cognitive improvement (R = 0.53, p < 0.001). On a local level, the optimal stimulation site resided at the direct interface between these structures (R = 0.48, p < 0.001). Finally, modulating specific distributed brain networks related to memory accounted for optimal outcomes (R = 0.48, p < 0.001). Findings were robust to multiple cross-validation designs and may define an optimal network target that could refine DBS surgery and programming.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Digitalization impacts the COVID-19 pandemic and the stringency of government measures",
        "link": "https://www.nature.com/articles/s41598-022-24726-0",
        "publication_date": "14 Dec 2022",
        "abstract": "COVID-19 poses a significant burden to populations worldwide. Although the pandemic has accelerated digital transformation, little is known about the influence of digitalization on pandemic developments. Therefore, this country-level study aims to explore the impact of pre-pandemic digital adoption on COVID-19 outcomes and government measures. Using the Digital Adoption Index (DAI), we examined the association between countries' digital preparedness levels and COVID-19 cases, deaths, and stringency indices (SI) of government measures until March 2021. Gradient Tree Boosting based algorithm pinpointed essential features related to COVID-19 trends, such as digital adoption, populations' smoker fraction, age, and poverty. Subsequently, regression analyses indicated that higher DAI was associated with significant declines in new cases (β = − 362.25/pm; p < 0.001) and attributed deaths (β = − 5.53/pm; p < 0.001) months after the peak. When plotting DAI against the SI normalized for the starting day, countries with higher DAI adopted slightly more stringent government measures (β = 4.86; p < 0.01). Finally, a scoping review identified 70 publications providing valuable arguments for our findings. Countries with higher DAI before the pandemic show a positive trend in handling the pandemic and facilitate the implementation of more decisive governmental measures. Further distribution of digital adoption may have the potential to attenuate the impact of COVID-19 cases and deaths.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Autoencoders for sample size estimation for fully connected neural network classifiers",
        "link": "https://www.nature.com/articles/s41746-022-00728-0",
        "publication_date": "13 Dec 2022",
        "abstract": "Sample size estimation is a crucial step in experimental design but is understudied in the context of deep learning. Currently, estimating the quantity of labeled data needed to train a classifier to a desired performance, is largely based on prior experience with similar models and problems or on untested heuristics. In many supervised machine learning applications, data labeling can be expensive and time-consuming and would benefit from a more rigorous means of estimating labeling requirements. Here, we study the problem of estimating the minimum sample size of labeled training data necessary for training computer vision models as an exemplar for other deep learning problems. We consider the problem of identifying the minimal number of labeled data points to achieve a generalizable representation of the data, a minimum converging sample (MCS). We use autoencoder loss to estimate the MCS for fully connected neural network classifiers. At sample sizes smaller than the MCS estimate, fully connected networks fail to distinguish classes, and at sample sizes above the MCS estimate, generalizability strongly correlates with the loss function of the autoencoder. We provide an easily accessible, code-free, and dataset-agnostic tool to estimate sample sizes for fully connected networks. Taken together, our findings suggest that MCS and convergence estimation are promising methods to guide sample size estimates for data collection and labeling prior to training deep learning models in computer vision.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Diagnosis of nasal bone fractures on plain radiographs via convolutional neural networks",
        "link": "https://www.nature.com/articles/s41598-022-26161-7",
        "publication_date": "13 Dec 2022",
        "abstract": "This study aimed to assess the performance of deep learning (DL) algorithms in the diagnosis of nasal bone fractures on radiographs and compare it with that of experienced radiologists. In this retrospective study, 6713 patients whose nasal radiographs were examined for suspected nasal bone fractures between January 2009 and October 2020 were assessed. Our dataset was randomly split into training (n = 4325), validation (n = 481), and internal test (n = 1250) sets; a separate external dataset (n = 102) was used. The area under the receiver operating characteristic curve (AUC), sensitivity, and specificity of the DL algorithm and the two radiologists were compared. The AUCs of the DL algorithm for the internal and external test sets were 0.85 (95% CI, 0.83–0.86) and 0.86 (95% CI, 0.78–0.93), respectively, and those of the two radiologists for the external test set were 0.80 (95% CI, 0.73–0.87) and 0.75 (95% CI, 0.68–0.82). The DL algorithm therefore significantly exceeded radiologist 2 (P = 0.021) but did not significantly differ from radiologist 1 (P = 0.142). The sensitivity and specificity of the DL algorithm were 83.1% (95% CI, 71.2–93.2%) and 83.7% (95% CI, 69.8–93.0%), respectively. Our DL algorithm performs comparably to experienced radiologists in diagnosing nasal bone fractures on radiographs.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Interpretable prognostic modeling of endometrial cancer",
        "link": "https://www.nature.com/articles/s41598-022-26134-w",
        "publication_date": "13 Dec 2022",
        "abstract": "Endometrial carcinoma (EC) is one of the most common gynecological cancers in the world. In this work we apply Cox proportional hazards (CPH) and optimal survival tree (OST) algorithms to the retrospective prognostic modeling of disease-specific survival in 842 EC patients. We demonstrate that linear CPH models are preferred for the EC risk assessment based on clinical features alone, while interpretable, non-linear OST models are favored when patient profiles can be supplemented with additional biomarker data. We show how visually interpretable tree models can help generate and explore novel research hypotheses by studying the OST decision path structure, in which L1 cell adhesion molecule expression and estrogen receptor status are correctly indicated as important risk factors in the p53 abnormal EC subgroup. To aid further clinical adoption of advanced machine learning techniques, we stress the importance of quantifying model discrimination and calibration performance in the development of explainable clinical prediction models.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Features derived from blood pressure and intracranial pressure predict elevated intracranial pressure events in critically ill children",
        "link": "https://www.nature.com/articles/s41598-022-25169-3",
        "publication_date": "12 Dec 2022",
        "abstract": "Clinicians frequently observe hemodynamic changes preceding elevated intracranial pressure events. We employed a machine learning approach to identify novel and differentially expressed features associated with elevated intracranial pressure events in children with severe brain injuries. Statistical features from physiologic data streams were derived from non-overlapping 30-min analysis windows prior to 21 elevated intracranial pressure events; 200 records without elevated intracranial pressure events were used as controls. Ten Monte Carlo simulations with training/testing splits provided performance benchmarks for 4 machine learning approaches. XGBoost yielded the best performing predictive models. Shapley Additive Explanations analyses demonstrated that a majority of the top 20 contributing features consistently derived from blood pressure data streams up to 240 min prior to elevated intracranial events. The best performing prediction model was using the 30–60 min analysis window; for this model, the area under the receiver operating characteristic window using XGBoost was 0.82 (95% CI 0.81–0.83); the area under the precision-recall curve was 0.24 (95% CI 0.23–0.25), above the expected baseline of 0.1. We conclude that physiomarkers discernable by machine learning are concentrated within blood pressure and intracranial pressure data up to 4 h prior to elevated intracranial pressure events.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Optimizing multiparametric magnetic resonance imaging-targeted biopsy and detection of clinically significant prostate cancer: the role of perilesional sampling",
        "link": "https://www.nature.com/articles/s41391-022-00620-8",
        "publication_date": "12 Dec 2022",
        "abstract": "The added-value of systematic biopsy (SB) in patients undergoing magnetic resonance imaging (MRI)-targeted biopsy (TB) remains unclear and the spatial distribution of positive cores relative to the MRI lesion has been poorly studied. The aim of this study was to determine the utility of perilesional biopsy in detecting clinically significant prostate cancer (csPCa).",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Identifying myoglobin as a mediator of diabetic kidney disease: a machine learning-based cross-sectional study",
        "link": "https://www.nature.com/articles/s41598-022-25299-8",
        "publication_date": "10 Dec 2022",
        "abstract": "In view of the alarming increase in the burden of diabetes mellitus (DM) today, a rising number of patients with diabetic kidney disease (DKD) is forecasted. Current DKD predictive models often lack reliable biomarkers and perform poorly. In this regard, serum myoglobin (Mb) identified by machine learning (ML) may become a potential DKD indicator. We aimed to elucidate the significance of serum Mb in the pathogenesis of DKD. Electronic health record data from a total of 728 hospitalized patients with DM (286 DKD vs. 442 non-DKD) were used. We developed DKD ML models incorporating serum Mb and metabolic syndrome (MetS) components (insulin resistance and β-cell function, glucose, lipid) while using SHapley Additive exPlanation (SHAP) to interpret features. Restricted cubic spline (RCS) models were applied to evaluate the relationship between serum Mb and DKD. Serum Mb-mediated renal function impairment induced by MetS components was verified by causal mediation effect analysis. The area under the receiver operating characteristic curve of the DKD machine learning models incorporating serum Mb and MetS components reached 0.85. Feature importance analysis and SHAP showed that serum Mb and MetS components were important features. Further RCS models of DKD showed that the odds ratio was greater than 1 when serum Mb was > 80. Serum Mb showed a significant indirect effect in renal function impairment when using MetS components such as HOMA-IR, HGI and HDL-C/TC as a reason. Moderately elevated serum Mb is associated with the risk of DKD. Serum Mb may mediate MetS component-caused renal function impairment.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting an unstable tear film through artificial intelligence",
        "link": "https://www.nature.com/articles/s41598-022-25821-y",
        "publication_date": "10 Dec 2022",
        "abstract": "Dry eye disease is one of the most common ophthalmological complaints and is defined by a loss of tear film homeostasis. Establishing a diagnosis can be time-consuming, resource demanding and unpleasant for the patient. In this pilot study, we retrospectively included clinical data from 431 patients with dry eye disease examined in the Norwegian Dry Eye Clinic to evaluate how artificial intelligence algorithms perform on clinical data related to dry eye disease. The data was processed and subjected to numerous machine learning classification algorithms with the aim to predict decreased tear film break-up time. Moreover, feature selection techniques (information gain and information gain ratio) were applied to determine which clinical factors contribute most to an unstable tear film. The applied machine learning algorithms outperformed baseline classifications performed with ZeroR according to included evaluation metrics. Clinical features such as ocular surface staining, meibomian gland expressibility and dropout, blink frequency, osmolarity, meibum quality and symptom score were recognized as important predictors for tear film instability. We identify and discuss potential limitations and pitfalls.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A Multifaceted benchmarking of synthetic electronic health record generation models",
        "link": "https://www.nature.com/articles/s41467-022-35295-1",
        "publication_date": "09 Dec 2022",
        "abstract": "Synthetic health data have the potential to mitigate privacy concerns in supporting biomedical research and healthcare applications. Modern approaches for data generation continue to evolve and demonstrate remarkable potential. Yet there is a lack of a systematic assessment framework to benchmark methods as they emerge and determine which methods are most appropriate for which use cases. In this work, we introduce a systematic benchmarking framework to appraise key characteristics with respect to utility and privacy metrics. We apply the framework to evaluate synthetic data generation methods for electronic health records data from two large academic medical centers with respect to several use cases. The results illustrate that there is a utility-privacy tradeoff for sharing synthetic health data and further indicate that no method is unequivocally the best on all criteria in each use case, which makes it evident why synthetic data generation methods need to be assessed in context.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [
                "membership inference"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting 180-day mortality for women with ovarian cancer using machine learning and patient-reported outcome data",
        "link": "https://www.nature.com/articles/s41598-022-22614-1",
        "publication_date": "08 Dec 2022",
        "abstract": "Contrary to national guidelines, women with ovarian cancer often receive treatment at the end of life, potentially due to the difficulty in accurately estimating prognosis. We trained machine learning algorithms to guide prognosis by predicting 180-day mortality for women with ovarian cancer using patient-reported outcomes (PRO) data. We collected data from a single academic cancer institution in the United States. Women completed biopsychosocial PRO measures every 90 days. We randomly partitioned our dataset into training and testing samples. We used synthetic minority oversampling to reduce class imbalance in the training dataset. We fitted training data to six machine learning algorithms and combined their classifications on the testing dataset into an unweighted voting ensemble. We assessed each algorithm's accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve (AUROC) using testing data. We recruited 245 patients who completed 1319 PRO assessments. The final voting ensemble produced state-of-the-art results on the task of predicting 180-day mortality for ovarian cancer paitents (Accuracy = 0.79, Sensitivity = 0.71, Specificity = 0.80, AUROC = 0.76). The algorithm correctly identified 25 of the 35 women in the testing dataset who died within 180 days of assessment. Machine learning algorithms trained using PRO data offer encouraging performance in predicting whether a woman with ovarian cancer will die within 180 days. This model could be used to drive data-driven end-of-life care and address current shortcomings in care delivery. Our model demonstrates the potential of biopsychosocial PROM information to make substantial contributions to oncology prediction modeling. This model could inform clinical decision-making Future research is needed to validate these findings in a larger, more diverse sample.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Association of wearable device-measured vigorous intermittent lifestyle physical activity with mortality",
        "link": "https://www.nature.com/articles/s41591-022-02100-x",
        "publication_date": "08 Dec 2022",
        "abstract": "Wearable devices can capture unexplored movement patterns such as brief bursts of vigorous intermittent lifestyle physical activity (VILPA) that is embedded into everyday life, rather than being done as leisure time exercise. Here, we examined the association of VILPA with all-cause, cardiovascular disease (CVD) and cancer mortality in 25,241 nonexercisers (mean age 61.8 years, 14,178 women/11,063 men) in the UK Biobank. Over an average follow-up of 6.9 years, during which 852 deaths occurred, VILPA was inversely associated with all three of these outcomes in a near-linear fashion. Compared with participants who engaged in no VILPA, participants who engaged in VILPA at the sample median VILPA frequency of 3 length-standardized bouts per day (lasting 1 or 2 min each) showed a 38%–40% reduction in all-cause and cancer mortality risk and a 48%–49% reduction in CVD mortality risk. Moreover, the sample median VILPA duration of 4.4 min per day was associated with a 26%–30% reduction in all-cause and cancer mortality risk and a 32%–34% reduction in CVD mortality risk. We obtained similar results when repeating the above analyses for vigorous physical activity (VPA) in 62,344 UK Biobank participants who exercised (1,552 deaths, 35,290 women/27,054 men). These results indicate that small amounts of vigorous nonexercise physical activity are associated with substantially lower mortality. VILPA in nonexercisers appears to elicit similar effects to VPA in exercisers, suggesting that VILPA may be a suitable physical activity target, especially in people not able or willing to exercise.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Heterogeneous graph construction and HinSAGE learning from electronic medical records",
        "link": "https://www.nature.com/articles/s41598-022-25693-2",
        "publication_date": "07 Dec 2022",
        "abstract": "Graph representation learning is a method for introducing how to effectively construct and learn patient embeddings using electronic medical records. Adapting the integration will support and advance the previous methods to predict the prognosis of patients in network models. This study aims to address the challenge of implementing a complex and highly heterogeneous dataset, including the following: (1) demonstrating how to build a multi-attributed and multi-relational graph model (2) and applying a downstream disease prediction task of a patient’s prognosis using the HinSAGE algorithm. We present a bipartite graph schema and a graph database construction in detail. The first constructed graph database illustrates a query of a predictive network that provides analytical insights using a graph representation of a patient’s journey. Moreover, we demonstrate an alternative bipartite model where we apply the model to the HinSAGE to perform the link prediction task for predicting the event occurrence. Consequently, the performance evaluation indicated that our heterogeneous graph model was successfully predicted as a baseline model. Overall, our graph database successfully demonstrated efficient real-time query performance and showed HinSAGE implementation to predict cardiovascular disease event outcomes on supervised link prediction learning.",
        "conclusions": "Our study suggested a visualization method for EMR using two visualization frameworks and how they are built and applied. The graph database was performed to query at efficient runtime and is easily modifiable in real time. Further, benefiting from the graph neural network mechanisms, this work presented a favorable framework compared to previous baseline methods: The HinSAGE was implemented to efficiently predict CVD event outcomes using supervised link prediction learning. Our work demonstrated that graph databases and graph neural networks are great options for building high-dimensional models, for use in the predictive analysis of heart disease treatments.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A proof of concept for a deep learning system that can aid embryologists in predicting blastocyst survival after thaw",
        "link": "https://www.nature.com/articles/s41598-022-25062-z",
        "publication_date": "07 Dec 2022",
        "abstract": "The ability to understand whether embryos survive the thaw process is crucial to transferring competent embryos that can lead to pregnancy. The objective of this study was to develop a proof of concept deep learning model capable of assisting embryologist assessment of survival of thawed blastocysts prior to embryo transfer. A deep learning model was developed using 652 labeled time-lapse videos of freeze–thaw blastocysts. The model was evaluated against and along embryologists on a test set of 99 freeze–thaw blastocysts, using images obtained at 0.5 h increments from 0 to 3 h post-thaw. The model achieved AUCs of 0.869 (95% CI 0.789, 0.934) and 0.807 (95% CI 0.717, 0.886) and the embryologists achieved average AUCs of 0.829 (95% CI 0.747, 0.896) and 0.850 (95% CI 0.773, 0.908) at 2 h and 3 h, respectively. Combining embryologist predictions with model predictions resulted in a significant increase in AUC of 0.051 (95% CI 0.021, 0.083) at 2 h, and an equivalent increase in AUC of 0.010 (95% CI −0.018, 0.037) at 3 h. This study suggests that a deep learning model can predict in vitro blastocyst survival after thaw in aneuploid embryos. After correlation with clinical outcomes of transferred embryos, this model may help embryologists ascertain which embryos may have failed to survive the thaw process and increase the likelihood of pregnancy by preventing the transfer of non-viable embryos.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of oxygen requirement in patients with COVID-19 using a pre-trained chest radiograph xAI model: efficient development of auditable risk prediction models via a fine-tuning approach",
        "link": "https://www.nature.com/articles/s41598-022-24721-5",
        "publication_date": "07 Dec 2022",
        "abstract": "Risk prediction requires comprehensive integration of clinical information and concurrent radiological findings. We present an upgraded chest radiograph (CXR) explainable artificial intelligence (xAI) model, which was trained on 241,723 well-annotated CXRs obtained prior to the onset of the COVID-19 pandemic. Mean area under the receiver operating characteristic curve (AUROC) for detection of 20 radiographic features was 0.955 (95% CI 0.938–0.955) on PA view and 0.909 (95% CI 0.890–0.925) on AP view. Coexistent and correlated radiographic findings are displayed in an interpretation table, and calibrated classifier confidence is displayed on an AI scoreboard. Retrieval of similar feature patches and comparable CXRs from a Model-Derived Atlas provides justification for model predictions. To demonstrate the feasibility of a fine-tuning approach for efficient and scalable development of xAI risk prediction models, we applied our CXR xAI model, in combination with clinical information, to predict oxygen requirement in COVID-19 patients. Prediction accuracy for high flow oxygen (HFO) and mechanical ventilation (MV) was 0.953 and 0.934 at 24 h and 0.932 and 0.836 at 72 h from the time of emergency department (ED) admission, respectively. Our CXR xAI model is auditable and captures key pathophysiological manifestations of cardiorespiratory diseases and cardiothoracic comorbidities. This model can be efficiently and broadly applied via a fine-tuning approach to provide fully automated risk and outcome predictions in various clinical scenarios in real-world practice.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "High molecular diagnostic yields and novel phenotypic expansions involving syndromic anorectal malformations",
        "link": "https://www.nature.com/articles/s41431-022-01255-y",
        "publication_date": "06 Dec 2022",
        "abstract": "Evidence suggests that genetic factors contribute to the development of anorectal malformations (ARMs). However, the etiology of the majority of ARMs cases remains unclear. Exome sequencing (ES) may be underutilized in the diagnostic workup of ARMs due to uncertainty regarding its diagnostic yield. In a clinical database of ~17,000 individuals referred for ES, we identified 130 individuals with syndromic ARMs. A definitive or probable diagnosis was made in 45 of these individuals for a diagnostic yield of 34.6% (45/130). The molecular diagnostic yield of individuals who initially met criteria for VACTERL association was lower than those who did not (26.8% vs 44.1%; p = 0.0437), suggesting that non-genetic factors may play an important role in this subset of syndromic ARM cases. Within this cohort, we identified two individuals who carried de novo pathogenic frameshift variants in ADNP, two individuals who were homozygous for pathogenic variants in BBS1, and single individuals who carried pathogenic or likely pathogenic variants in CREBBP, EP300, FANCC, KDM6A, SETD2, and SMARCA4. The association of these genes with ARMs was supported by previously published cases, and their similarity to known ARM genes as demonstrated using a machine learning algorithm. These data suggest that ES should be considered for all individuals with syndromic ARMs in whom a molecular diagnosis has not been made, and that ARMs represent a low penetrance phenotype associated with Helsmoortel-van der Aa syndrome, Bardet-Biedl syndrome 1, Rubinstein-Taybi syndromes 1 and 2, Fanconi anemia group C, Kabuki syndrome 2, SETD2-related disorders, and Coffin-Siris syndrome 4.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Blood monocyte levels predict the risk of acute exacerbations of chronic obstructive pulmonary disease: a retrospective case–control study",
        "link": "https://www.nature.com/articles/s41598-022-25520-8",
        "publication_date": "06 Dec 2022",
        "abstract": "Monocytes were critical cells in the innate immune system. Monocyte recruitment to the lungs is a crucial process of pathophysiology in chronic obstructive pulmonary disease (COPD). Current evidence on the association between the occurrence of acute exacerbations of COPD (AECOPD) and monocytes was unclear. This study aimed to examine whether blood monocytes are associated with the occurrence of AECOPD and to determine the specific blood monocyte level to predict AECOPD. A retrospective case–control study was conducted at Changhua Christian Hospital. A total of 444 eligible patients with COPD were included between January 2017 and December 2019. Restricted cubic splines were used to analyze the nonlinear relationships between continuous white blood cell values and the occurrence of AECOPD. The association between monocytes and the occurrence of AECOPD was assessed using the logistic, lasso, and ridge regression models. Restricted cubic splines revealed nonlinear associations among the monocyte level, the continuous value of the eosinophil-to-lymphocyte ratio, and the occurrence of AECOPD. The lowest risk of occurrence of AECOPD ranged from 7.4 to 10%; < 7.4% with an absolute count < 0.62 or > 10% indicated significant risk. No significant association was noted between the eosinophil-to-lymphocyte ratio categories in the tertiles (< 0.049, 0.049 to < 0.122, and ≥ 0.122) and the risk of AECOPD. A significantly higher risk was noted in the association of the occurrence of AECOPD with the CAT score; mMRC score; wheezing cough; preexisting chronic pulmonary disease; hypertension and malignancy; use of dual- and triple, and oral long-acting bronchodilators for COPD treatment; and WBC count. We reported a nonlinear relationship between monocytes and the occurrence of AECOPD. Patients with monocyte percentage of > 10% or < 7.4% with an absolute count < 0.62 had higher risk of occurrence of AECOPD. Overall, our study demonstrated the specific value of monocytes in identifying high risks of the occurrence of AECOPD; this value is an easy-to-obtain, inexpensive biomarker in patients with AECOPD and should be further investigated in future prospective clinical studies.",
        "conclusions": "In conclusion, we reported a nonlinear relationship between monocyte level and the occurrence of AECOPD. Patients with monocyte percentage > 10% or < 7.4% with an absolute count < 0.62 were at a high risk of AECOPD. Our findings demonstrated the specific monocyte value for identifying the high risks of AECOPD. This value served as a novel, simple, and inexpensive biomarker in patients with a high risk of AECOPD and should be further investigated in future prospective clinical studies.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Federated learning enables big data for rare cancer boundary detection",
        "link": "https://www.nature.com/articles/s41467-022-33407-5",
        "publication_date": "05 Dec 2022",
        "abstract": "Although machine learning (ML) has shown promise across disciplines, out-of-sample generalizability is concerning. This is currently addressed by sharing multi-site data, but such centralization is challenging/infeasible to scale due to various limitations. Federated ML (FL) provides an alternative paradigm for accurate and generalizable ML, by only sharing numerical model updates. Here we present the largest FL study to-date, involving data from 71 sites across 6 continents, to generate an automatic tumor boundary detector for the rare disease of glioblastoma, reporting the largest such dataset in the literature (n = 6, 314). We demonstrate a 33% delineation improvement for the surgically targetable tumor, and 23% for the complete tumor extent, over a publicly trained model. We anticipate our study to: 1) enable more healthcare studies informed by large diverse data, ensuring meaningful results for rare diseases and underrepresented populations, 2) facilitate further analyses for glioblastoma by releasing our consensus model, and 3) demonstrate the FL effectiveness at such scale and task-complexity as a paradigm shift for multi-site collaborations, alleviating the need for data-sharing.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Differential diagnosis of common etiologies of left ventricular hypertrophy using a hybrid CNN-LSTM model",
        "link": "https://www.nature.com/articles/s41598-022-25467-w",
        "publication_date": "05 Dec 2022",
        "abstract": "Differential diagnosis of left ventricular hypertrophy (LVH) is often obscure on echocardiography and requires numerous additional tests. We aimed to develop a deep learning algorithm to aid in the differentiation of common etiologies of LVH (i.e. hypertensive heart disease [HHD], hypertrophic cardiomyopathy [HCM], and light-chain cardiac amyloidosis [ALCA]) on echocardiographic images. Echocardiograms in 5 standard views (parasternal long-axis, parasternal short-axis, apical 4-chamber, apical 2-chamber, and apical 3-chamber) were obtained from 930 subjects: 112 with HHD, 191 with HCM, 81 with ALCA and 546 normal subjects. The study population was divided into training (n = 620), validation (n = 155), and test sets (n = 155). A convolutional neural network-long short-term memory (CNN-LSTM) algorithm was constructed to independently classify the 3 diagnoses on each view, and the final diagnosis was made by an aggregate network based on the simultaneously predicted probabilities of HCM, HCM, and ALCA. Diagnostic performance of the algorithm was evaluated by the area under the receiver operating characteristic curve (AUC), and accuracy was evaluated by the confusion matrix. The deep learning algorithm was trained and verified using the training and validation sets, respectively. In the test set, the average AUC across the five standard views was 0.962, 0.982 and 0.996 for HHD, HCM and CA, respectively. The overall diagnostic accuracy was significantly higher for the deep learning algorithm (92.3%) than for echocardiography specialists (80.0% and 80.6%). In the present study, we developed a deep learning algorithm for the differential diagnosis of 3 common LVH etiologies (HHD, HCM and ALCA) by applying a hybrid CNN-LSTM model and aggregate network to standard echocardiographic images. The high diagnostic performance of our deep learning algorithm suggests that the use of deep learning can improve the diagnostic process in patients with LVH.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "An iterative and interdisciplinary categorisation process towards FAIRer digital resources for sensitive life-sciences data",
        "link": "https://www.nature.com/articles/s41598-022-25278-z",
        "publication_date": "05 Dec 2022",
        "abstract": "For life science infrastructures, sensitive data generate an additional layer of complexity. Cross-domain categorisation and discovery of digital resources related to sensitive data presents major interoperability challenges. To support this FAIRification process, a toolbox demonstrator aiming at support for discovery of digital objects related to sensitive data (e.g., regulations, guidelines, best practice, tools) has been developed. The toolbox is based upon a categorisation system developed and harmonised across a cluster of 6 life science research infrastructures. Three different versions were built, tested by subsequent pilot studies, finally leading to a system with 7 main categories (sensitive data type, resource type, research field, data type, stage in data sharing life cycle, geographical scope, specific topics). 109 resources attached with the tags in pilot study 3 were used as the initial content for the toolbox demonstrator, a software tool allowing searching of digital objects linked to sensitive data with filtering based upon the categorisation system. Important next steps are a broad evaluation of the usability and user-friendliness of the toolbox, extension to more resources, broader adoption by different life-science communities, and a long-term vision for maintenance and sustainability.",
        "conclusions": "To come to a stable and generally applicable categorisation system and toolbox demonstrator, an iterative process was necessary across life sciences RIs. Approval process started with nominated senior experts from 6 life-science RIs but needs community approval at a larger scale. As the categorisation system is specifying essential metadata for resources about sensitive data, it could be relevant to the FAIR Digital Objects Forum and to the Research Data Alliance (RDA) Metadata Standards Catalog (MSC) Working Group. Initial evaluation of the toolbox demonstrator has been performed with 110 resources from the LS but extension to more resources is needed. Important next steps prior to any realisation of the toolbox will be a broad evaluation of the user acceptance, usability and user-friendliness of the toolbox demonstrator, exploration of AI- or ML- algorithms to support (semi-) automatic tagging of resources and a long-term vision for maintenance and sustainability.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "BNT162b2 induces robust cross-variant SARS-CoV-2 immunity in children",
        "link": "https://www.nature.com/articles/s41541-022-00575-w",
        "publication_date": "03 Dec 2022",
        "abstract": "Currently available mRNA vaccines are extremely safe and effective to prevent severe SARS-CoV-2 infections. However, the emergence of variants of concerns (VOCs) has highlighted the importance of high population-based vaccine rates to effectively suppress viral transmission and breakthrough infections. While initially left out from vaccine efforts, children have become one of the most affected age groups and are key targets to stop community and household spread. Antibodies are central for vaccine-induced protection and emerging data points to the importance of additional Fc effector functions like opsononophagocytosis or cytotoxicity, particularly in the context of VOCs that escape neutralizing antibodies. Here, we observed delayed induction and reduced magnitude of vaccine-induced antibody titers in children 5-11 years receiving two doses of the age-recommended 10 μg dose of the Pfizer SARS-CoV-2 BNT162b2 vaccine compared to adolescents (12–15 years) or adults receiving the 30 μg dose. Conversely, children mounted equivalent or more robust neutralization and opsonophagocytic functions at peak immunogenicity, pointing to a qualitatively more robust humoral functional response in children. Moreover, broad cross-VOC responses were observed across children, with enhanced IgM and parallel IgG cross-reactivity to VOCs in children compared to adults. Collectively, these data argue that despite the lower magnitude of the BNT162b2-induced antibody response in children, vaccine-induced immunity in children target VOCs broadly and exhibit enhanced functionality that may contribute to the attenuation of disease.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Deciphering clinical abbreviations with a privacy protecting machine learning system",
        "link": "https://www.nature.com/articles/s41467-022-35007-9",
        "publication_date": "02 Dec 2022",
        "abstract": "Physicians write clinical notes with abbreviations and shorthand that are difficult to decipher. Abbreviations can be clinical jargon (writing “HIT” for “heparin induced thrombocytopenia”), ambiguous terms that require expertise to disambiguate (using “MS” for “multiple sclerosis” or “mental status”), or domain-specific vernacular (“cb” for “complicated by”). Here we train machine learning models on public web data to decode such text by replacing abbreviations with their meanings. We report a single translation model that simultaneously detects and expands thousands of abbreviations in real clinical notes with accuracies ranging from 92.1%-97.1% on multiple external test datasets. The model equals or exceeds the performance of board-certified physicians (97.6% vs 88.7% total accuracy). Our results demonstrate a general method to contextually decipher abbreviations and shorthand that is built without any privacy-compromising data.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A computational approach to measure the linguistic characteristics of psychotherapy timing, responsiveness, and consistency",
        "link": "https://www.nature.com/articles/s44184-022-00020-9",
        "publication_date": "02 Dec 2022",
        "abstract": "Although individual psychotherapy is generally effective for a range of mental health conditions, little is known about the moment-to-moment language use of effective therapists. Increased access to computational power, coupled with a rise in computer-mediated communication (telehealth), makes feasible the large-scale analyses of language use during psychotherapy. Transparent methodological approaches are lacking, however. Here we present novel methods to increase the efficiency of efforts to examine language use in psychotherapy. We evaluate three important aspects of therapist language use - timing, responsiveness, and consistency - across five clinically relevant language domains: pronouns, time orientation, emotional polarity, therapist tactics, and paralinguistic style. We find therapist language is dynamic within sessions, responds to patient language, and relates to patient symptom diagnosis but not symptom severity. Our results demonstrate that analyzing therapist language at scale is feasible and may help answer longstanding questions about specific behaviors of effective therapists.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Nasal DNA methylation at three CpG sites predicts childhood allergic disease",
        "link": "https://www.nature.com/articles/s41467-022-35088-6",
        "publication_date": "01 Dec 2022",
        "abstract": "Childhood allergic diseases, including asthma, rhinitis and eczema, are prevalent conditions that share strong genetic and environmental components. Diagnosis relies on clinical history and measurements of allergen-specific IgE. We hypothesize that a multi-omics model could accurately diagnose childhood allergic disease. We show that nasal DNA methylation has the strongest predictive power to diagnose childhood allergy, surpassing blood DNA methylation, genetic risk scores, and environmental factors. DNA methylation at only three nasal CpG sites classifies allergic disease in Dutch children aged 16 years well, with an area under the curve (AUC) of 0.86. This is replicated in Puerto Rican children aged 9–20 years (AUC 0.82). DNA methylation at these CpGs additionally detects allergic multimorbidity and symptomatic IgE sensitization. Using nasal single-cell RNA-sequencing data, these three CpGs associate with influx of T cells and macrophages that contribute to allergic inflammation. Our study suggests the potential of methylation-based allergy diagnosis.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Generalizability of an acute kidney injury prediction model across health systems",
        "link": "https://www.nature.com/articles/s42256-022-00563-8",
        "publication_date": "01 Dec 2022",
        "abstract": "Delays in the identification of acute kidney injury in hospitalized patients are a major barrier to the development of effective interventions for treatment. A recent study described a series of models that outperformed previously published models in predicting acute kidney injury up to 48 h in advance, including a recurrent neural network that achieved state-of-the-art performance (area under the curve 0.92) and a gradient-boosted decision tree model that was close behind (area under the curve 0.89). Because these models were trained in a population of US veterans that was 94% male, questions have arisen about its generalizability to other health systems where the populations are more sex balanced. In this study, we aimed to evaluate how well an acute kidney injury model trained in a population of US veterans performs in females at the Veterans Affairs and the extent to which its performance generalizes to a large academic hospital setting. We found that the model performed worse in predicting acute kidney injury in females in both populations, with miscalibration in lower stages of acute kidney injury and worse discrimination (a lower area under the curve) in higher stages of acute kidney injury. We demonstrate that, while this discrepancy in performance can be largely corrected in non-veterans by updating the original model using data from a sex-balanced academic hospital cohort, the worse model performance persists in veterans. Our study sheds light on the importance of characterizing the generalizability of artificial intelligence studies, and on the complexity of discrepancies in model performance in subgroups that cannot be explained simply on the basis of sample size.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Multi-day dataset of forearm and wrist electromyogram for hand gesture recognition and biometrics",
        "link": "https://www.nature.com/articles/s41597-022-01836-y",
        "publication_date": "30 Nov 2022",
        "abstract": "Surface electromyography (sEMG) signals have been used for advanced prosthetics control, hand-gesture recognition (HGR), and more recently as a novel biometric trait. For these sEMG-based applications, the translation from laboratory research setting to real-life scenarios suffers from two major limitations: (1) a small subject pool, and (2) single-session data recordings, both of which prevents acceptable generalization ability. In this longitudinal database, forearm and wrist sEMG data were collected from 43 participants over three different days with long separation (Days 1, 8, and 29) while they performed static hand/wrist gestures. The objective of this dataset is to provide a comprehensive dataset for the development of robust machine learning algorithms of sEMG, for both HGR and biometric applications. We demonstrated the high quality of the current dataset by comparing with the Ninapro dataset. And we presented its usability for both HGR and biometric applications. Among other applications, the dataset can also be used for developing electrode-shift invariant generalized models, which can further bolster the development of wristband and forearm-bracelet sensors.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    }
]