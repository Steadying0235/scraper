[
    {
        "title": "G-computation, propensity score-based methods, and targeted maximum likelihood estimator for causal inference with different covariates sets: a comparative simulation study",
        "link": "https://www.nature.com/articles/s41598-020-65917-x",
        "publication_date": "08 Jun 2020",
        "abstract": "Controlling for confounding bias is crucial in causal inference. Distinct methods are currently employed to mitigate the effects of confounding bias. Each requires the introduction of a set of covariates, which remains difficult to choose, especially regarding the different methods. We conduct a simulation study to compare the relative performance results obtained by using four different sets of covariates (those causing the outcome, those causing the treatment allocation, those causing both the outcome and the treatment allocation, and all the covariates) and four methods: g-computation, inverse probability of treatment weighting, full matching and targeted maximum likelihood estimator. Our simulations are in the context of a binary treatment, a binary outcome and baseline confounders. The simulations suggest that considering all the covariates causing the outcome led to the lowest bias and variance, particularly for g-computation. The consideration of all the covariates did not decrease the bias but significantly reduced the power. We apply these methods to two real-world examples that have clinical relevance, thereby illustrating the real-world importance of using these methods. We propose an R package RISCA to encourage the use of g-computation in causal inference.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Spontaneous MEG activity of the cerebral cortex during eyes closed and open discriminates Alzheimer’s disease from cognitively normal older adults",
        "link": "https://www.nature.com/articles/s41598-020-66034-5",
        "publication_date": "04 Jun 2020",
        "abstract": "This study aimed to examine whether magnetoencephalography (MEG) is useful to detect early stage Alzheimer’s disease (AD). We analyzed MEG data from the early stage AD group (n = 20; 6 with mild cognitive impairment due to AD and 14 with AD dementia) and cognitively normal control group (NC, n = 27). MEG was recorded during resting eyes closed (EC) and eyes open (EO), and the following 6 values for each of 5 bands (θ1: 4-6, θ2: 6-8, α1: 8-10, α2: 10-13, β: 13-20 Hz) in the cerebral 68 regions were compared between the groups: (1) absolute power during EC and (2) EO, (3) whole cerebral normalization (WCN) power during EC and (4) EO, (5) difference of the absolute powers between the EC and EO conditions (the EC-EO difference), and (6) WCN value of the EC-EO difference. We found significant differences between the groups in the WCN powers during the EO condition, and the EC-EO differences. Using a Support Vector Machine classifier, a discrimination accuracy of 83% was obtained and an AUC in an ROC analysis was 0.91. This study demonstrates that MEG during resting EC and EO is useful in discriminating between early stage AD and NC.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Assessing the accuracy of automatic speech recognition for psychotherapy",
        "link": "https://www.nature.com/articles/s41746-020-0285-8",
        "publication_date": "03 Jun 2020",
        "abstract": "Accurate transcription of audio recordings in psychotherapy would improve therapy effectiveness, clinician training, and safety monitoring. Although automatic speech recognition software is commercially available, its accuracy in mental health settings has not been well described. It is unclear which metrics and thresholds are appropriate for different clinical use cases, which may range from population descriptions to individual safety monitoring. Here we show that automatic speech recognition is feasible in psychotherapy, but further improvements in accuracy are needed before widespread use. Our HIPAA-compliant automatic speech recognition system demonstrated a transcription word error rate of 25%. For depression-related utterances, sensitivity was 80% and positive predictive value was 83%. For clinician-identified harm-related sentences, the word error rate was 34%. These results suggest that automatic speech recognition may support understanding of language patterns and subgroup variation in existing treatments but may not be ready for individual-level safety surveillance.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Genome-wide cell-free DNA mutational integration enables ultra-sensitive cancer monitoring",
        "link": "https://www.nature.com/articles/s41591-020-0915-3",
        "publication_date": "01 Jun 2020",
        "abstract": "In many areas of oncology, we lack sensitive tools to track low-burden disease. Although cell-free DNA (cfDNA) shows promise in detecting cancer mutations, we found that the combination of low tumor fraction (TF) and limited number of DNA fragments restricts low-disease-burden monitoring through the prevailing deep targeted sequencing paradigm. We reasoned that breadth may supplant depth of sequencing to overcome the barrier of cfDNA abundance. Whole-genome sequencing (WGS) of cfDNA allowed ultra-sensitive detection, capitalizing on the cumulative signal of thousands of somatic mutations observed in solid malignancies, with TF detection sensitivity as low as 10−5. The WGS approach enabled dynamic tumor burden tracking and postoperative residual disease detection, associated with adverse outcome. Thus, we present an orthogonal framework for cfDNA cancer monitoring via genome-wide mutational integration, enabling ultra-sensitive detection, overcoming the limitation of cfDNA abundance and empowering treatment optimization in low-disease-burden oncology care.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prospective deep phenotyping of choroideremia patients using multimodal structure-function approaches",
        "link": "https://www.nature.com/articles/s41433-020-0974-1",
        "publication_date": "28 May 2020",
        "abstract": "To investigate the retinal changes in choroideremia (CHM) patients to determine correlations between age, structure and function.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Health status among greenhouse workers exposed to different levels of pesticides: A genetic matching analysis",
        "link": "https://www.nature.com/articles/s41598-020-65662-1",
        "publication_date": "26 May 2020",
        "abstract": "(1) Objective: Greenhouse workers are considered a special occupational group who are exposed to more toxic and harmful substances than ordinary farmers. The health problem of this group is a public health problem that warrants attention. Taking greenhouse workers in Ningxia, China, as the research sample, this study analyzed the health risk to practitioners posed by the greenhouse working environment. (2) Method: To analyze the relationship between pesticide exposure and the health of greenhouse workers, the genetic matching method was used to exclude the influence of covariates on the results. (3) Results: The results showed a statistical significance regarding the prevalence of cardiovascular diseases (CVD), skeletal muscle system diseases (SMSD) and digestive diseases between the different exposure groups. Researching the disease symptoms found that different levels of exposure to pesticides in greenhouses could cause multisystem and multisymptom discomfort. In addition to some irritant symptoms such as eye itching, itching, and sneezing, there were also differences in terms of the frequency of discomfort such as back pain, a decline in sleep quality, memory loss, joint pain, swelling and weakness, upper abdominal pain and flatulence, in the different exposure groups. (4) Conclusion: Different levels of exposure to pesticides in greenhouses may be one of the risk factors for practitioners to suffer from various systemic diseases, affecting their health and work efficiency. This hazard is manifested not only in some acute irritant symptoms but also in chronic diseases due to long-term exposure.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [
                "poisoning"
            ],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Homeostasis as a proportional–integral control system",
        "link": "https://www.nature.com/articles/s41746-020-0283-x",
        "publication_date": "22 May 2020",
        "abstract": "According to medical guidelines, the distinction between “healthy” and “unhealthy” patients is commonly based on single, discrete values taken at an isolated point in time (e.g., blood pressure or core temperature). Perhaps a more robust and insightful diagnosis can be obtained by studying the functional interdependence of such indicators and the homeostasis that controls them. This requires quasi-continuous measurements and a procedure to map the data onto a parsimonious control model with a degree of universality. The current research illustrates this approach using glucose homeostasis as a target. Data were obtained from 41 healthy subjects wearing over-the-counter glucose monitors, and projected onto a simple proportional–integral (PI) controller, widely used in engineering applications. The indicators quantifying the control function are clustered for the great majority of subjects, while a few outliers exhibit less responsive homeostasis. Practical implications for healthcare and education are further discussed.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Epiretinal Membrane Detection at the Ophthalmologist Level using Deep Learning of Optical Coherence Tomography",
        "link": "https://www.nature.com/articles/s41598-020-65405-2",
        "publication_date": "21 May 2020",
        "abstract": "Purpose: Previous deep learning studies on optical coherence tomography (OCT) mainly focused on diabetic retinopathy and age-related macular degeneration. We proposed a deep learning model that can identify epiretinal membrane (ERM) in OCT with ophthalmologist-level performance. Design: Cross-sectional study. Participants: A total of 3,618 central fovea cross section OCT images from 1,475 eyes of 964 patients. Methods: We retrospectively collected 7,652 OCT images from 1,197 patients. From these images, 2,171 were normal and 1,447 were ERM OCT. A total of 3,141 OCT images was used as training dataset and 477 images as testing dataset. DL algorithm was used to train the interpretation model. Diagnostic results by four board-certified non-retinal specialized ophthalmologists on the testing dataset were compared with those generated by the DL model. Main Outcome Measures: We calculated for the derived DL model the following characteristics: sensitivity, specificity, F1 score and area under curve (AUC) of the receiver operating characteristic (ROC) curve. These were calculated according to the gold standard results which were parallel diagnoses of the retinal specialist. Performance of the DL model was finally compared with that of non-retinal specialized ophthalmologists. Results: Regarding the diagnosis of ERM in OCT images, the trained DL model had the following characteristics in performance: sensitivity: 98.7%, specificity: 98.0%, and F1 score: 0.945. The accuracy on the training dataset was 99.7% (95% CI: 99.4 - 99.9%), and for the testing dataset, diagnostic accuracy was 98.1% (95% CI: 96.5 - 99.1%). AUC of the ROC curve was 0.999. The DL model slightly outperformed the average non-retinal specialized ophthalmologists. Conclusions: An ophthalmologist-level DL model was built here to accurately identify ERM in OCT images. The performance of the model was slightly better than the average non-retinal specialized ophthalmologists. The derived model may play a role to assist clinicians to promote the efficiency and safety of healthcare in the future.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Auditory Electrooculogram-based Communication System for ALS Patients in Transition from Locked-in to Complete Locked-in State",
        "link": "https://www.nature.com/articles/s41598-020-65333-1",
        "publication_date": "21 May 2020",
        "abstract": "Patients in the transition from locked-in (i.e., a state of almost complete paralysis with voluntary eye movement control, eye blinks or twitches of face muscles, and preserved consciousness) to complete locked-in state (i.e., total paralysis including paralysis of eye-muscles and loss of gaze-fixation, combined with preserved consciousness) are left without any means of communication. An auditory communication system based on electrooculogram (EOG) was developed to enable such patients to communicate. Four amyotrophic lateral sclerosis patients in transition from locked-in state to completely locked-in state, with ALSFRS-R score of 0, unable to use eye trackers for communication, learned to use an auditory EOG-based communication system. The patients, with eye-movement amplitude between the range of ±200μV and ±40μV, were able to form complete sentences and communicate independently and freely, selecting letters from an auditory speller system. A follow-up of one year with one patient shows the feasibility of the proposed system in long-term use and the correlation between speller performance and eye-movement decay. The results of the auditory speller system have the potential to provide a means of communication to patient populations without gaze fixation ability and with low eye-movement amplitude range.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine-learning based exploration of determinants of gray matter volume in the KORA-MRI study",
        "link": "https://www.nature.com/articles/s41598-020-65040-x",
        "publication_date": "20 May 2020",
        "abstract": "To identify the most important factors that impact brain volume, while accounting for potential collinearity, we used a data-driven machine-learning approach. Gray Matter Volume (GMV) was derived from magnetic resonance imaging (3T, FLAIR) and adjusted for intracranial volume (ICV). 93 potential determinants of GMV from the categories sociodemographics, anthropometric measurements, cardio-metabolic variables, lifestyle factors, medication, sleep, and nutrition were obtained from 293 participants from a population-based cohort from Southern Germany. Elastic net regression was used to identify the most important determinants of ICV-adjusted GMV. The four variables age (selected in each of the 1000 splits), glomerular filtration rate (794 splits), diabetes (323 splits) and diabetes duration (122 splits) were identified to be most relevant predictors of GMV adjusted for intracranial volume. The elastic net model showed better performance compared to a constant linear regression (mean squared error = 1.10 vs. 1.59, p < 0.001). These findings are relevant for preventive and therapeutic considerations and for neuroimaging studies, as they suggest to take information on metabolic status and renal function into account as potential confounders.",
        "conclusions": "In conclusion, this study shows that EN regression is a feasible machine-learning approach to identify predictors of ICV-adjusted GMV. The results from this data-driven exploratory analysis could potentially generate hypotheses for more focused, hypothesis-driven studies to follow. Additionally, the identification of diabetes-related parameters and GFR as important predictive variables for GMV suggests that these parameters should be taken into account in neuroimaging studies, especially when investigating effects of aging and neurodegeneration.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Quantification of tissue volume in the hindlimb of mice using microcomputed tomography images and analysing software",
        "link": "https://www.nature.com/articles/s41598-020-65214-7",
        "publication_date": "19 May 2020",
        "abstract": "When studying illnesses that cause disturbance in volume such as lymphedema, reliable quantification of tissue volume is important. Lymphedema results in swelling and enlargement of extremities and can be both physically and psychologically stressful to the patient. Experiments in rodent models provide a cost-effective research platform and are important for preclinical research on lymphedema. When performing such research, it can be crucial to measure the changes in tissue volume. Researchers must ensure that the risk of measurement error, when measuring the tissue volume, is as low as possible. The main goal of this article was to perform a comprehensive examination of the intra- and interrater agreement and hereby assess the risk of measurement error when using microcomputed tomography (µCT) images to measure hindlimb volume. We examined the agreement between four raters with different levels of prior experience and found that the risk of measurement error is extremely low when using this method. The main limitation of this method is that it is relatively expensive and time-consuming. The main advantages of this method are that it is easily learned and that it has a high intra- and interrater agreement, even for raters with no prior measuring experience.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting conversion to wet age-related macular degeneration using deep learning",
        "link": "https://www.nature.com/articles/s41591-020-0867-7",
        "publication_date": "18 May 2020",
        "abstract": "Progression to exudative ‘wet’ age-related macular degeneration (exAMD) is a major cause of visual deterioration. In patients diagnosed with exAMD in one eye, we introduce an artificial intelligence (AI) system to predict progression to exAMD in the second eye. By combining models based on three-dimensional (3D) optical coherence tomography images and corresponding automatic tissue maps, our system predicts conversion to exAMD within a clinically actionable 6-month time window, achieving a per-volumetric-scan sensitivity of 80% at 55% specificity, and 34% sensitivity at 90% specificity. This level of performance corresponds to true positives in 78% and 41% of individual eyes, and false positives in 56% and 17% of individual eyes at the high sensitivity and high specificity points, respectively. Moreover, we show that automatic tissue segmentation can identify anatomical changes before conversion and high-risk subgroups. This AI system overcomes substantial interobserver variability in expert predictions, performing better than five out of six experts, and demonstrates the potential of using AI to predict disease progression.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine Learning (ML) based-method applied in recurrent pregnancy loss (RPL) patients diagnostic work-up: a potential innovation in common clinical practice",
        "link": "https://www.nature.com/articles/s41598-020-64512-4",
        "publication_date": "14 May 2020",
        "abstract": "RPL is a very debated condition, in which many issues concerning definition, etiological factors to investigate or therapies to apply are still controversial. ML could help clinicians to reach an objectiveness in RPL classification and access to care. Our aim was to stratify RPL patients in different risk classes by applying an ML algorithm, through a diagnostic work-up to validate it for the appropriate prognosis and potential therapeutic approach. 734 patients were enrolled and divided into 4 risk classes, according to the numbers of miscarriages. ML method, called Support Vector Machine (SVM), was used to analyze data. Using the whole set of 43 features and the set of the most informative 18 features we obtained comparable results: respectively 81.86 ± 0.35% and 81.71 ± 0.37% Unbalanced Accuracy. Applying the same method, introducing the only features recommended by ESHRE, a correct classification was obtained only in 58.52 ± 0.58%. ML approach could provide a Support Decision System tool to stratify RPL patients and address them objectively to the proper clinical management.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Generation and evaluation of artificial mental health records for Natural Language Processing",
        "link": "https://www.nature.com/articles/s41746-020-0267-x",
        "publication_date": "14 May 2020",
        "abstract": "A serious obstacle to the development of Natural Language Processing (NLP) methods in the clinical domain is the accessibility of textual data. The mental health domain is particularly challenging, partly because clinical documentation relies heavily on free text that is difficult to de-identify completely. This problem could be tackled by using artificial medical data. In this work, we present an approach to generate artificial clinical documents. We apply this approach to discharge summaries from a large mental healthcare provider and discharge summaries from an intensive care unit. We perform an extensive intrinsic evaluation where we (1) apply several measures of text preservation; (2) measure how much the model memorises training data; and (3) estimate clinical validity of the generated text based on a human evaluation task. Furthermore, we perform an extrinsic evaluation by studying the impact of using artificial text in a downstream NLP text classification task. We found that using this artificial data as training data can lead to classification results that are comparable to the original results. Additionally, using only a small amount of information from the original data to condition the generation of the artificial data is successful, which holds promise for reducing the risk of these artificial data retaining rare information from the original data. This is an important finding for our long-term goal of being able to generate artificial clinical data that can be released to the wider research community and accelerate advances in developing computational methods that use healthcare data.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "GaitRec, a large-scale ground reaction force dataset of healthy and impaired gait",
        "link": "https://www.nature.com/articles/s41597-020-0481-z",
        "publication_date": "12 May 2020",
        "abstract": "The quantification of ground reaction forces (GRF) is a standard tool for clinicians to quantify and analyze human locomotion. Such recordings produce a vast amount of complex data and variables which are difficult to comprehend. This makes data interpretation challenging. Machine learning approaches seem to be promising tools to support clinicians in identifying and categorizing specific gait patterns. However, the quality of such approaches strongly depends on the amount of available annotated data to train the underlying models. Therefore, we present GaitRec, a comprehensive and completely annotated large-scale dataset containing bi-lateral GRF walking trials of 2,084 patients with various musculoskeletal impairments and data from 211 healthy controls. The dataset comprises data of patients after joint replacement, fractures, ligament ruptures, and related disorders at the hip, knee, ankle or calcaneus during their entire stay(s) at a rehabilitation center. The data sum up to a total of 75,732 bi-lateral walking trials and enable researchers to classify gait patterns at a large-scale as well as to analyze the entire recovery process of patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The usefulness of the Deep Learning method of variational autoencoder to reduce measurement noise in glaucomatous visual fields",
        "link": "https://www.nature.com/articles/s41598-020-64869-6",
        "publication_date": "12 May 2020",
        "abstract": "The aim of the study was to investigate the usefulness of processing visual field (VF) using a variational autoencoder (VAE). The training data consisted of 82,433 VFs from 16,836 eyes. Testing dataset 1 consisted of test-retest VFs from 104 eyes with open angle glaucoma. Testing dataset 2 was series of 10 VFs from 638 eyes with open angle glaucoma. A VAE model to reconstruct VF was developed using the training dataset. VFs in the testing dataset 1 were then reconstructed using the trained VAE and the mean total deviation (mTD) was calculated (mTDVAE). In testing dataset 2, the mTD value of the tenth VF was predicted using shorter series of VFs. A similar calculation was carried out using a weighted linear regression where the weights were equal to the absolute difference between mTD and mTDVAE. In testing dataset 1, there was a significant relationship between the difference between mTD and mTDVAE from the first VF and the difference between mTD in the first and second VFs. In testing dataset 2, mean squared prediction errors with the weighted mTD trend analysis were significantly smaller than those form the unweighted mTD trend analysis.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Novel artificial intelligence system increases the detection of prostate cancer in whole slide images of core needle biopsies",
        "link": "https://www.nature.com/articles/s41379-020-0551-y",
        "publication_date": "11 May 2020",
        "abstract": "Prostate cancer (PrCa) is the second most common cancer among men in the United States. The gold standard for detecting PrCa is the examination of prostate needle core biopsies. Diagnosis can be challenging, especially for small, well-differentiated cancers. Recently, machine learning algorithms have been developed for detecting PrCa in whole slide images (WSIs) with high test accuracy. However, the impact of these artificial intelligence systems on pathologic diagnosis is not known. To address this, we investigated how pathologists interact with Paige Prostate Alpha, a state-of-the-art PrCa detection system, in WSIs of prostate needle core biopsies stained with hematoxylin and eosin. Three AP-board certified pathologists assessed 304 anonymized prostate needle core biopsy WSIs in 8 hours. The pathologists classified each WSI as benign or cancerous. After ~4 weeks, pathologists were tasked with re-reviewing each WSI with the aid of Paige Prostate Alpha. For each WSI, Paige Prostate Alpha was used to perform cancer detection and, for WSIs where cancer was detected, the system marked the area where cancer was detected with the highest probability. The original diagnosis for each slide was rendered by genitourinary pathologists and incorporated any ancillary studies requested during the original diagnostic assessment. Against this ground truth, the pathologists and Paige Prostate Alpha were measured. Without Paige Prostate Alpha, pathologists had an average sensitivity of 74% and an average specificity of 97%. With Paige Prostate Alpha, the average sensitivity for pathologists significantly increased to 90% with no statistically significant change in specificity. With Paige Prostate Alpha, pathologists more often correctly classified smaller, lower grade tumors, and spent less time analyzing each WSI. Future studies will investigate if similar benefit is yielded when such a system is used to detect other forms of cancer in a setting that more closely emulates real practice.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Isocitrate dehydrogenase (IDH) status prediction in histopathology images of gliomas using deep learning",
        "link": "https://www.nature.com/articles/s41598-020-64588-y",
        "publication_date": "07 May 2020",
        "abstract": "Mutations in isocitrate dehydrogenase genes IDH1 and IDH2 are frequently found in diffuse and anaplastic astrocytic and oligodendroglial tumours as well as in secondary glioblastomas. As IDH is a very important prognostic, diagnostic and therapeutic biomarker for glioma, it is of paramount importance to determine its mutational status. The haematoxylin and eosin (H&E) staining is a valuable tool in precision oncology as it guides histopathology-based diagnosis and proceeding patient’s treatment. However, H&E staining alone does not determine the IDH mutational status of a tumour. Deep learning methods applied to MRI data have been demonstrated to be a useful tool in IDH status prediction, however the effectiveness of deep learning on H&E slides in the clinical setting has not been investigated so far. Furthermore, the performance of deep learning methods in medical imaging has been practically limited by small sample sizes currently available. Here we propose a data augmentation method based on the Generative Adversarial Networks (GAN) deep learning methodology, to improve the prediction performance of IDH mutational status using H&E slides. The H&E slides were acquired from 266 grade II-IV glioma patients from a mixture of public and private databases, including 130 IDH-wildtype and 136 IDH-mutant patients. A baseline deep learning model without data augmentation achieved an accuracy of 0.794 (AUC = 0.920). With GAN-based data augmentation, the accuracy of the IDH mutational status prediction was improved to 0.853 (AUC = 0.927) when the 3,000 GAN generated training samples were added to the original training set (24,000 samples). By integrating also patients’ age into the model, the accuracy improved further to 0.882 (AUC = 0.931). Our findings show that deep learning methodology, enhanced by GAN data augmentation, can support physicians in gliomas’ IDH status prediction.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of the Mortality Risk in Peritoneal Dialysis Patients using Machine Learning Models: A Nation-wide Prospective Cohort in Korea",
        "link": "https://www.nature.com/articles/s41598-020-64184-0",
        "publication_date": "04 May 2020",
        "abstract": "Herein, we aim to assess mortality risk prediction in peritoneal dialysis patients using machine-learning algorithms for proper prognosis prediction. A total of 1,730 peritoneal dialysis patients in the CRC for ESRD prospective cohort from 2008 to 2014 were enrolled in this study. Classification algorithms were used for prediction of N-year mortality including neural network. The survival hazard ratio was presented by machine-learning algorithms using survival statistics and was compared to conventional algorithms. A survival-tree algorithm presented the most accurate prediction model and outperformed a conventional method such as Cox regression (concordance index 0.769 vs 0.745). Among various survival decision-tree models, the modified Charlson Comorbidity index (mCCI) was selected as the best predictor of mortality. If peritoneal dialysis patients with high mCCI (>4) were aged ≥70.5 years old, the survival hazard ratio was predicted as 4.61 compared to the overall study population. Among the various algorithm using longitudinal data, the AUC value of logistic regression was augmented at 0.804. In addition, the deep neural network significantly improved performance to 0.841. We propose machine learning-based final model, mCCI and age were interrelated as notable risk factors for mortality in Korean peritoneal dialysis patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning approach for prediction of hearing preservation in vestibular schwannoma surgery",
        "link": "https://www.nature.com/articles/s41598-020-64175-1",
        "publication_date": "28 Apr 2020",
        "abstract": "In vestibular schwannoma patients with functional hearing status, surgical resection while preserving the hearing is feasible. Hearing levels, tumor size, and location of the tumor have been known to be candidates of predictors. We used a machine learning approach to predict hearing outcomes in vestibular schwannoma patients who underwent hearing preservation surgery: middle cranial fossa, or retrosigmoid approach. After reviewing the medical records of 52 patients with a pathologically confirmed vestibular schwannoma, we included 50 patient’s records in the study. Hearing preservation was regarded as positive if the postoperative hearing was within serviceable hearing (50/50 rule). The categorical variable included the surgical approach, and the continuous variable covered audiometric and vestibular function tests, and the largest diameter of the tumor. Four different algorithms were lined up for comparison of accuracy: support vector machine(SVM), gradient boosting machine(GBM), deep neural network(DNN), and diffuse random forest(DRF). The average accuracy of predicting hearing preservation ranged from 62% (SVM) to 90% (DNN). The current study is the first to incorporate machine learning methodology into a prediction of successful hearing preservation surgery. Although a larger population may be needed for better generalization, this study could aid the surgeon’s decision to perform a hearing preservation approach for vestibular schwannoma surgery.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Accuracy of a new intraocular lens power calculation method based on artificial intelligence",
        "link": "https://www.nature.com/articles/s41433-020-0883-3",
        "publication_date": "28 Apr 2020",
        "abstract": "The purpose of this study is to develop and assess the accuracy of a new intraocular lens (IOL) power calculation method based on machine learning techniques.",
        "conclusions": "The Karmona model proposed here emerged as more accurate than the third-generation formula Haigis, the fourth generation Holladay 2 and Barrett Universal II, and the fifth-generation Hill-RBF. We are presently preparing an open source web site where an updated version of Karmona will be available in Shiny from RStudio [16].Summary\nWhat was known before\n\n\nIntraocular lens power calculation methods and formulas.\n\n\nWhat this study adds\n\n\nTo develop and assess a new intraocular lens power calculation method based on machine learning techniques.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "BEHRT: Transformer for Electronic Health Records",
        "link": "https://www.nature.com/articles/s41598-020-62922-y",
        "publication_date": "28 Apr 2020",
        "abstract": "Today, despite decades of developments in medicine and the growing interest in precision healthcare, vast majority of diagnoses happen once patients begin to show noticeable signs of illness. Early indication and detection of diseases, however, can provide patients and carers with the chance of early intervention, better disease management, and efficient allocation of healthcare resources. The latest developments in machine learning (including deep learning) provides a great opportunity to address this unmet need. In this study, we introduce BEHRT: A deep neural sequence transduction model for electronic health records (EHR), capable of simultaneously predicting the likelihood of 301 conditions in one’s future visits. When trained and evaluated on the data from nearly 1.6 million individuals, BEHRT shows a striking improvement of 8.0–13.2% (in terms of average precision scores for different tasks), over the existing state-of-the-art deep EHR models. In addition to its scalability and superior accuracy, BEHRT enables personalised interpretation of its predictions; its flexible architecture enables it to incorporate multiple heterogeneous concepts (e.g., diagnosis, medication, measurements, and more) to further improve the accuracy of its predictions; its (pre-)training results in disease and patient representations can be useful for future studies (i.e., transfer learning).",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of Intracranial Aneurysm Risk using Machine Learning",
        "link": "https://www.nature.com/articles/s41598-020-63906-8",
        "publication_date": "24 Apr 2020",
        "abstract": "An efficient method for identifying subjects at high risk of an intracranial aneurysm (IA) is warranted to provide adequate radiological screening guidelines and effectively allocate medical resources. We developed a model for pre-diagnosis IA prediction using a national claims database and health examination records. Data from the National Health Screening Program in Korea were utilized as input for several machine learning algorithms: logistic regression (LR), random forest (RF), scalable tree boosting system (XGB), and deep neural networks (DNN). Algorithm performance was evaluated through the area under the receiver operating characteristic curve (AUROC) using different test data from that employed for model training. Five risk groups were classified in ascending order of risk using model prediction probabilities. Incidence rate ratios between the lowest- and highest-risk groups were then compared. The XGB model produced the best IA risk prediction (AUROC of 0.765) and predicted the lowest IA incidence (3.20) in the lowest-risk group, whereas the RF model predicted the highest IA incidence (161.34) in the highest-risk group. The incidence rate ratios between the lowest- and highest-risk groups were 49.85, 35.85, 34.90, and 30.26 for the XGB, LR, DNN, and RF models, respectively. The developed prediction model can aid future IA screening strategies.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development and validation of a deep neural network model to predict postoperative mortality, acute kidney injury, and reintubation using a single feature set",
        "link": "https://www.nature.com/articles/s41746-020-0248-0",
        "publication_date": "20 Apr 2020",
        "abstract": "During the perioperative period patients often suffer complications, including acute kidney injury (AKI), reintubation, and mortality. In order to effectively prevent these complications, high-risk patients must be readily identified. However, most current risk scores are designed to predict a single postoperative complication and often lack specificity on the patient level. In other fields, machine learning (ML) has been shown to successfully create models to predict multiple end points using a single input feature set. We hypothesized that ML can be used to create models to predict postoperative mortality, AKI, reintubation, and a combined outcome using a single set of features available at the end of surgery. A set of 46 features available at the end of surgery, including drug dosing, blood loss, vital signs, and others were extracted. Additionally, six additional features accounting for total intraoperative hypotension were extracted and trialed for different models. A total of 59,981 surgical procedures met inclusion criteria and the deep neural networks (DNN) were trained on 80% of the data, with 20% reserved for testing. The network performances were then compared to ASA Physical Status. In addition to creating separate models for each outcome, a multitask learning model was trialed that used information on all outcomes to predict the likelihood of each outcome individually. The overall rate of the examined complications in this data set was 0.79% for mortality, 22.3% (of 21,676 patients with creatinine values) for AKI, and 1.1% for reintubation. Overall, there was significant overlap between the various model types for each outcome, with no one modeling technique consistently performing the best. However, the best DNN models did beat the ASA score for all outcomes other than mortality. The highest area under the receiver operating characteristic curve (AUC) models were 0.792 (0.775–0.808) for AKI, 0.879 (0.851–0.905) for reintubation, 0.907 (0.872–0.938) for mortality, and 0.874 (0.864–0.866) for any outcome. The ASA score alone achieved AUCs of 0.652 (0.636–0.669) for AKI, 0.787 (0.757–0.818) for reintubation, 0.839 (0.804–0.875) for mortality, and 0.76 (0.748–0.773) for any outcome. Overall, the DNN architecture was able to create models that outperformed the ASA physical status to predict all outcomes based on a single feature set, consisting of objective data available at the end of surgery. No one model architecture consistently performed the best.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Influence of genetic factors in elbow tendon pathology: a case-control study",
        "link": "https://www.nature.com/articles/s41598-020-63030-7",
        "publication_date": "16 Apr 2020",
        "abstract": "Elbow tendinopathy is a common pathology of the upper extremity that impacts both athletes and workers. Some research has examined the genetic component as a risk factor for tendinopathy, mainly in the lower limbs. A case-control study was designed to test for a relationship between certain collagen gene single nucleotide polymorphisms (SNPs) and elbow tendon pathology. A sample of 137 young adult athletes whose sports participation involves loading of the upper limb were examined for the presence of structural abnormalities indicative of pathology in the tendons of the lateral and medial elbow using ultrasound imaging and genotyped for the following SNPs: COL5A1 rs12722, COL11A1 rs3753841, COL11A1 rs1676486, and COL11A2 rs1799907. Anthropometric measurements and data on participants’ elbow pain and dysfunction were collected using the Disabilities of the Arm, Shoulder and Hand and the Mayo Clinic Performance Index for the Elbow questionnaires. Results showed that participants in the structural abnormality group had significantly higher scores in pain and dysfunction. A significant relationship between COL11A1 rs3753841 genotype and elbow tendon pathology was found (p = 0.024), with the CT variant associated with increased risk of pathology.",
        "conclusions": "In the present study, the genotype for SNP COL11A1 rs3753841 was associated with elbow tendon pathology; subjects in the pathology group were significantly more likely to have the CT genotype. None of the other SNPs studied showed a significant association. Significant relationships were also found between the anthropometric variables BMI, percent body fat, and waist circumference and elbow tendon pathology.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Resolving challenges in deep learning-based analyses of histopathological images using explanation methods",
        "link": "https://www.nature.com/articles/s41598-020-62724-2",
        "publication_date": "14 Apr 2020",
        "abstract": "Deep learning has recently gained popularity in digital pathology due to its high prediction quality. However, the medical domain requires explanation and insight for a better understanding beyond standard quantitative performance evaluation. Recently, many explanation methods have emerged. This work shows how heatmaps generated by these explanation methods allow to resolve common challenges encountered in deep learning-based digital histopathology analyses. We elaborate on biases which are typically inherent in histopathological image data. In the binary classification task of tumour tissue discrimination in publicly available haematoxylin-eosin-stained images of various tumour entities, we investigate three types of biases: (1) biases which affect the entire dataset, (2) biases which are by chance correlated with class labels and (3) sampling biases. While standard analyses focus on patch-level evaluation, we advocate pixel-wise heatmaps, which offer a more precise and versatile diagnostic instrument. This insight is shown to not only be helpful to detect but also to remove the effects of common hidden biases, which improves generalisation within and across datasets. For example, we could see a trend of improved area under the receiver operating characteristic (ROC) curve by 5% when reducing a labelling bias. Explanation techniques are thus demonstrated to be a helpful and highly relevant tool for the development and the deployment phases within the life cycle of real-world applications in digital pathology.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Protected Health Information filter (Philter): accurately and securely de-identifying free-text clinical notes",
        "link": "https://www.nature.com/articles/s41746-020-0258-y",
        "publication_date": "14 Apr 2020",
        "abstract": "There is a great and growing need to ascertain what exactly is the state of a patient, in terms of disease progression, actual care practices, pathology, adverse events, and much more, beyond the paucity of data available in structured medical record data. Ascertaining these harder-to-reach data elements is now critical for the accurate phenotyping of complex traits, detection of adverse outcomes, efficacy of off-label drug use, and longitudinal patient surveillance. Clinical notes often contain the most detailed and relevant digital information about individual patients, the nuances of their diseases, the treatment strategies selected by physicians, and the resulting outcomes. However, notes remain largely unused for research because they contain Protected Health Information (PHI), which is synonymous with individually identifying data. Previous clinical note de-identification approaches have been rigid and still too inaccurate to see any substantial real-world use, primarily because they have been trained with too small medical text corpora. To build a new de-identification tool, we created the largest manually annotated clinical note corpus for PHI and develop a customizable open-source de-identification software called Philter (“Protected Health Information filter”). Here we describe the design and evaluation of Philter, and show how it offers substantial real-world improvements over prior methods.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Artificial intelligence for the diagnosis of heart failure",
        "link": "https://www.nature.com/articles/s41746-020-0261-3",
        "publication_date": "08 Apr 2020",
        "abstract": "The diagnosis of heart failure can be difficult, even for heart failure specialists. Artificial Intelligence-Clinical Decision Support System (AI-CDSS) has the potential to assist physicians in heart failure diagnosis. The aim of this work was to evaluate the diagnostic accuracy of an AI-CDSS for heart failure. AI-CDSS for cardiology was developed with a hybrid (expert-driven and machine-learning-driven) approach of knowledge acquisition to evolve the knowledge base with heart failure diagnosis. A retrospective cohort of 1198 patients with and without heart failure was used for the development of AI-CDSS (training dataset, n = 600) and to test the performance (test dataset, n = 598). A prospective clinical pilot study of 97 patients with dyspnea was used to assess the diagnostic accuracy of AI-CDSS compared with that of non-heart failure specialists. The concordance rate between AI-CDSS and heart failure specialists was evaluated. In retrospective cohort, the concordance rate was 98.3% in the test dataset. The concordance rate for patients with heart failure with reduced ejection fraction, heart failure with mid-range ejection fraction, heart failure with preserved ejection fraction, and no heart failure was 100%, 100%, 99.6%, and 91.7%, respectively. In a prospective pilot study of 97 patients presenting with dyspnea to the outpatient clinic, 44% had heart failure. The concordance rate between AI-CDSS and heart failure specialists was 98%, whereas that between non-heart failure specialists and heart failure specialists was 76%. In conclusion, AI-CDSS showed a high diagnostic accuracy for heart failure. Therefore, AI-CDSS may be useful for the diagnosis of heart failure, especially when heart failure specialists are not available.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A mountable toilet system for personalized health monitoring via the analysis of excreta",
        "link": "https://www.nature.com/articles/s41551-020-0534-9",
        "publication_date": "06 Apr 2020",
        "abstract": "Technologies for the longitudinal monitoring of a person’s health are poorly integrated with clinical workflows, and have rarely produced actionable biometric data for healthcare providers. Here, we describe easily deployable hardware and software for the long-term analysis of a user’s excreta through data collection and models of human health. The ‘smart’ toilet, which is self-contained and operates autonomously by leveraging pressure and motion sensors, analyses the user’s urine using a standard-of-care colorimetric assay that traces red–green–blue values from images of urinalysis strips, calculates the flow rate and volume of urine using computer vision as a uroflowmeter, and classifies stool according to the Bristol stool form scale using deep learning, with performance that is comparable to the performance of trained medical personnel. Each user of the toilet is identified through their fingerprint and the distinctive features of their anoderm, and the data are securely stored and analysed in an encrypted cloud server. The toilet may find uses in the screening, diagnosis and longitudinal monitoring of specific patient populations.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The cutaneous microbiome in hospitalized patients with pressure ulcers",
        "link": "https://www.nature.com/articles/s41598-020-62918-8",
        "publication_date": "06 Apr 2020",
        "abstract": "This study investigated whether there are differences in the composition of the cutaneous microbiome of the unaffected skin between patients with pressure ulcers compared with those without pressure ulcers. The cutaneous microbiome of the unaffected skin of 15 patients with sacral pressure ulcers compared to 15 patients without pressure ulcers was analysed. It demonstrated that the inter-individual variation in skin microbiota of patients with pressure ulcers was significantly higher (P = 0.01). The abundance of 23 species was significantly different with Staphylococcus aureus and unclassified Enterococcus the most abundant species in patients with pressure ulcers. Random Forest models showed that eight species were associated with pressure ulcers occurrence in 81% of the patients. A subset of four species gave the strongest interaction. The presence of unclassified Enterococcus had the highest association with pressure ulcer occurrence. This study is the first to demonstrate that the cutaneous microbiome is altered in patients with pressure ulcers.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Classifying post-traumatic stress disorder using the magnetoencephalographic connectome and machine learning",
        "link": "https://www.nature.com/articles/s41598-020-62713-5",
        "publication_date": "03 Apr 2020",
        "abstract": "Given the subjective nature of conventional diagnostic methods for post-traumatic stress disorder (PTSD), an objectively measurable biomarker is highly desirable; especially to clinicians and researchers. Macroscopic neural circuits measured using magnetoencephalography (MEG) has previously been shown to be indicative of the PTSD phenotype and severity. In the present study, we employed a machine learning-based classification framework using MEG neural synchrony to distinguish combat-related PTSD from trauma-exposed controls. Support vector machine (SVM) was used as the core classification algorithm. A recursive random forest feature selection step was directly incorporated in the nested SVM cross validation process (CV-SVM-rRF-FS) for identifying the most important features for PTSD classification. For the five frequency bands tested, the CV-SVM-rRF-FS analysis selected the minimum numbers of edges per frequency that could serve as a PTSD signature and be used as the basis for SVM modelling. Many of the selected edges have been reported previously to be core in PTSD pathophysiology, with frequency-specific patterns also observed. Furthermore, the independent partial least squares discriminant analysis suggested low bias in the machine learning process. The final SVM models built with selected features showed excellent PTSD classification performance (area-under-curve value up to 0.9). Testament to its robustness when distinguishing individuals from a heavily traumatised control group, these developments for a classification model for PTSD also provide a comprehensive machine learning-based computational framework for classifying other mental health challenges using MEG connectome profiles.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Evaluating the performance of raw and epoch non-wear algorithms using multiple accelerometers and electrocardiogram recordings",
        "link": "https://www.nature.com/articles/s41598-020-62821-2",
        "publication_date": "03 Apr 2020",
        "abstract": "Accurate detection of accelerometer non-wear time is crucial for calculating physical activity summary statistics. In this study, we evaluated three epoch-based non-wear algorithms (Hecht, Troiano, and Choi) and one raw-based algorithm (Hees). In addition, we performed a sensitivity analysis to provide insight into the relationship between the algorithms’ hyperparameters and classification performance, as well as to generate tuned hyperparameter values to better detect episodes of wear and non-wear time. We used machine learning to construct a gold-standard dataset by combining two accelerometers and electrocardiogram recordings. The Hecht and Troiano algorithms achieved poor classification performance, while Choi exhibited moderate performance. Meanwhile, Hees outperformed all epoch-based algorithms. The sensitivity analysis and hyperparameter tuning revealed that all algorithms were able to achieve increased classification performance by employing larger intervals and windows, while more stringently defining artificial movement. These classification gains were associated with the ability to lower the false positives (type I error) and do not necessarily indicate a more accurate detection of the total non-wear time. Moreover, our results indicate that with tuned hyperparameters, epoch-based non-wear algorithms are able to perform just as well as raw-based non-wear algorithms with respect to their ability to correctly detect true wear and non-wear episodes.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Personalized predictions of patient outcomes during and after hospitalization using artificial intelligence",
        "link": "https://www.nature.com/articles/s41746-020-0249-z",
        "publication_date": "03 Apr 2020",
        "abstract": "Hospital systems, payers, and regulators have focused on reducing length of stay (LOS) and early readmission, with uncertain benefit. Interpretable machine learning (ML) may assist in transparently identifying the risk of important outcomes. We conducted a retrospective cohort study of hospitalizations at a tertiary academic medical center and its branches from January 2011 to May 2018. A consecutive sample of all hospitalizations in the study period were included. Algorithms were trained on medical, sociodemographic, and institutional variables to predict readmission, length of stay (LOS), and death within 48–72 h. Prediction performance was measured by area under the receiver operator characteristic curve (AUC), Brier score loss (BSL), which measures how well predicted probability matches observed probability, and other metrics. Interpretations were generated using multiple feature extraction algorithms. The study cohort included 1,485,880 hospitalizations for 708,089 unique patients (median age of 59 years, first and third quartiles (QI) [39, 73]; 55.6% female; 71% white). There were 211,022 30-day readmissions for an overall readmission rate of 14% (for patients ≥65 years: 16%). Median LOS, including observation and labor and delivery patients, was 2.94 days (QI [1.67, 5.34]), or, if these patients are excluded, 3.71 days (QI [2.15, 6.51]). Predictive performance was as follows: 30-day readmission (AUC 0.76/BSL 0.11); LOS > 5 days (AUC 0.84/BSL 0.15); death within 48–72 h (AUC 0.91/BSL 0.001). Explanatory diagrams showed factors that impacted each prediction.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [
                "poisoning"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A machine learning algorithm for simulating immunohistochemistry: development of SOX10 virtual IHC and evaluation on primarily melanocytic neoplasms",
        "link": "https://www.nature.com/articles/s41379-020-0526-z",
        "publication_date": "01 Apr 2020",
        "abstract": "Immunohistochemistry (IHC) is a diagnostic technique used throughout pathology. A machine learning algorithm that could predict individual cell immunophenotype based on hematoxylin and eosin (H&E) staining would save money, time, and reduce tissue consumed. Prior approaches have lacked the spatial accuracy needed for cell-specific analytical tasks. Here IHC performed on destained H&E slides is used to create a neural network that is potentially capable of predicting individual cell immunophenotype. Twelve slides were stained with H&E and scanned to create digital whole slide images. The H&E slides were then destained, and stained with SOX10 IHC. The SOX10 IHC slides were scanned, and corresponding H&E and IHC digital images were registered. Color-thresholding and machine learning techniques were applied to the registered H&E and IHC images to segment 3,396,668 SOX10-negative cells and 306,166 SOX10-positive cells. The resulting segmentation was used to annotate the original H&E images, and a convolutional neural network was trained to predict SOX10 nuclear staining. Sixteen thousand three hundred and nine image patches were used to train the virtual IHC (vIHC) neural network, and 1,813 image patches were used to quantitatively evaluate it. The resulting vIHC neural network achieved an area under the curve of 0.9422 in a receiver operator characteristics analysis when sorting individual nuclei. The vIHC network was applied to additional images from clinical practice, and was evaluated qualitatively by a board-certified dermatopathologist. Further work is needed to make the process more efficient and accurate for clinical use. This proof-of-concept demonstrates the feasibility of creating neural network-driven vIHC assays.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction model for short-term mortality after palliative radiotherapy for patients having advanced cancer: a cohort study from routine electronic medical data",
        "link": "https://www.nature.com/articles/s41598-020-62826-x",
        "publication_date": "01 Apr 2020",
        "abstract": "We developed a predictive score system for 30-day mortality after palliative radiotherapy by using predictors from routine electronic medical record. Patients with metastatic cancer receiving first course palliative radiotherapy from 1 July, 2007 to 31 December, 2017 were identified. 30-day mortality odds ratios and probabilities of the death predictive score were obtained using multivariable logistic regression model. Overall, 5,795 patients participated. Median follow-up was 39.6 months (range, 24.5–69.3) for all surviving patients. 5,290 patients died over a median 110 days, of whom 995 (17.2%) died within 30 days of radiotherapy commencement. The most important mortality predictors were primary lung cancer (odds ratio: 1.73, 95% confidence interval: 1.47–2.04) and log peripheral blood neutrophil lymphocyte ratio (odds ratio: 1.71, 95% confidence interval: 1.52–1.92). The developed predictive scoring system had 10 predictor variables and 20 points. The cross-validated area under curve was 0.81 (95% confidence interval: 0.79–0.82). The calibration suggested a reasonably good fit for the model (likelihood-ratio statistic: 2.81, P = 0.094), providing an accurate prediction for almost all 30-day mortality probabilities. The predictive scoring system accurately predicted 30-day mortality among patients with stage IV cancer. Oncologists may use this to tailor palliative therapy for patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The molecular etiology of deafness and auditory performance in the postlingually deafened cochlear implantees",
        "link": "https://www.nature.com/articles/s41598-020-62647-y",
        "publication_date": "01 Apr 2020",
        "abstract": "Recent advances in molecular genetic testing (MGT) have improved identification of genetic aetiology of candidates for cochlear implantation (CI). However, whether genetic information increases CI outcome predictability in post-lingual deafness remains unclear. Therefore, we evaluated the outcomes of CI with respect to genetic aetiology and clinical predictors by comparing the data of study subjects; those with an identified genetic aetiology (GD group), and those without identifiable variants (GUD group). First, we identified the genetic aetiology in 21 of 40 subjects and also observed genetic etiologic heterogeneity. The GD group demonstrated significantly greater improvement in speech perception scores over a 1-year period than did the GUD group. Further, inverse correlation between deafness duration and the 1-year improvement in speech perception scores was tighter in the GD group than in the GUD group. The weak correlation between deafness duration and CI outcomes in the GUD group might suggest the pathophysiology underlying GUD already significantly involves the cortex, leading to lesser sensitivity to further cortex issues such as deafness duration. Under our MGT protocol, the correlation between deafness duration and CI outcomes were found to rely on the presence of identifiable genetic aetiology, strongly advocating early CI in individual with proven genetic aetiologies.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting Short-term Survival after Liver Transplantation using Machine Learning",
        "link": "https://www.nature.com/articles/s41598-020-62387-z",
        "publication_date": "27 Mar 2020",
        "abstract": "Liver transplantation is one of the most effective treatments for end-stage liver disease, but the demand for livers is much higher than the available donor livers. Model for End-stage Liver Disease (MELD) score is a commonly used approach to prioritize patients, but previous studies have indicated that MELD score may fail to predict well for the postoperative patients. This work proposes to use data-driven approach to devise a predictive model to predict postoperative survival within 30 days based on patient’s preoperative physiological measurement values. We use random forest (RF) to select important features, including clinically used features and new features discovered from physiological measurement values. Moreover, we propose a new imputation method to deal with the problem of missing values and the results show that it outperforms the other alternatives. In the predictive model, we use patients’ blood test data within 1–9 days before surgery to construct the model to predict postoperative patients’ survival. The experimental results on a real data set indicate that RF outperforms the other alternatives. The experimental results on the temporal validation set show that our proposed model achieves area under the curve (AUC) of 0.771 and specificity of 0.815, showing superior discrimination power in predicting postoperative survival.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning prediction of incidence of Alzheimer’s disease using large-scale administrative health data",
        "link": "https://www.nature.com/articles/s41746-020-0256-0",
        "publication_date": "26 Mar 2020",
        "abstract": "Nationwide population-based cohort provides a new opportunity to build an automated risk prediction model based on individuals’ history of health and healthcare beyond existing risk prediction models. We tested the possibility of machine learning models to predict future incidence of Alzheimer’s disease (AD) using large-scale administrative health data. From the Korean National Health Insurance Service database between 2002 and 2010, we obtained de-identified health data in elders above 65 years (N = 40,736) containing 4,894 unique clinical features including ICD-10 codes, medication codes, laboratory values, history of personal and family illness and socio-demographics. To define incident AD we considered two operational definitions: “definite AD” with diagnostic codes and dementia medication (n = 614) and “probable AD” with only diagnosis (n = 2026). We trained and validated random forest, support vector machine and logistic regression to predict incident AD in 1, 2, 3, and 4 subsequent years. For predicting future incidence of AD in balanced samples (bootstrapping), the machine learning models showed reasonable performance in 1-year prediction with AUC of 0.775 and 0.759, based on “definite AD” and “probable AD” outcomes, respectively; in 2-year, 0.730 and 0.693; in 3-year, 0.677 and 0.644; in 4-year, 0.725 and 0.683. The results were similar when the entire (unbalanced) samples were used. Important clinical features selected in logistic regression included hemoglobin level, age and urine protein level. This study may shed a light on the utility of the data-driven machine learning model based on large-scale administrative health data in AD risk prediction, which may enable better selection of individuals at risk for AD in clinical trials or early detection in clinical settings.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Siamese neural networks for continuous disease severity evaluation and change detection in medical imaging",
        "link": "https://www.nature.com/articles/s41746-020-0255-1",
        "publication_date": "26 Mar 2020",
        "abstract": "Using medical images to evaluate disease severity and change over time is a routine and important task in clinical decision making. Grading systems are often used, but are unreliable as domain experts disagree on disease severity category thresholds. These discrete categories also do not reflect the underlying continuous spectrum of disease severity. To address these issues, we developed a convolutional Siamese neural network approach to evaluate disease severity at single time points and change between longitudinal patient visits on a continuous spectrum. We demonstrate this in two medical imaging domains: retinopathy of prematurity (ROP) in retinal photographs and osteoarthritis in knee radiographs. Our patient cohorts consist of 4861 images from 870 patients in the Imaging and Informatics in Retinopathy of Prematurity (i-ROP) cohort study and 10,012 images from 3021 patients in the Multicenter Osteoarthritis Study (MOST), both of which feature longitudinal imaging data. Multiple expert clinician raters ranked 100 retinal images and 100 knee radiographs from excluded test sets for severity of ROP and osteoarthritis, respectively. The Siamese neural network output for each image in comparison to a pool of normal reference images correlates with disease severity rank (ρ = 0.87 for ROP and ρ = 0.89 for osteoarthritis), both within and between the clinical grading categories. Thus, this output can represent the continuous spectrum of disease severity at any single time point. The difference in these outputs can be used to show change over time. Alternatively, paired images from the same patient at two time points can be directly compared using the Siamese neural network, resulting in an additional continuous measure of change between images. Importantly, our approach does not require manual localization of the pathology of interest and requires only a binary label for training (same versus different). The location of disease and site of change detected by the algorithm can be visualized using an occlusion sensitivity map-based approach. For a longitudinal binary change detection task, our Siamese neural networks achieve test set receiving operator characteristic area under the curves (AUCs) of up to 0.90 in evaluating ROP or knee osteoarthritis change, depending on the change detection strategy. The overall performance on this binary task is similar compared to a conventional convolutional deep-neural network trained for multi-class classification. Our results demonstrate that convolutional Siamese neural networks can be a powerful tool for evaluating the continuous spectrum of disease severity and change in medical imaging.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Alzheimer’s disease, mild cognitive impairment, and normal aging distinguished by multi-modal parcellation and machine learning",
        "link": "https://www.nature.com/articles/s41598-020-62378-0",
        "publication_date": "25 Mar 2020",
        "abstract": "A 360-area surface-based cortical parcellation is extended to study mild cognitive impairment (MCI) and Alzheimer’s disease (AD) from healthy control (HC) using the joint human connectome project multi-modal parcellation (JHCPMMP) proposed by us. We propose a novel classification method named as JMMP-LRR to accurately identify different stages toward AD by integrating the JHCPMMP with the logistic regression-recursive feature elimination (LR-RFE). In three-group classification, the average accuracy is 89.0% for HC, MCI, and AD compared to previous studies using other cortical separation with the best classification accuracy of 81.5%. By counting the number of brain regions whose feature is in the feature subset selected with JMMP-LRR, we find that five brain areas often appear in the selected features. The five core brain areas are Fusiform Face Complex (L-FFC), Area 10d (L-10d), Orbital Frontal Complex (R-OFC), Perirhinal Ectorhinal (L-PeEc) and Area TG dorsal (L-TGd, R-TGd). The features corresponding to the five core brain areas are used to form a new feature subset for three classifications with the average accuracy of 80.0%. Results demonstrate the importance of the five core brain regions in identifying different stages toward AD. Experiment results show that the proposed method has better accuracy for the classification of HC, MCI, AD, and it also proves that the division of brain regions using JHCPMMP is more scientific and effective than other methods.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development and Validation of a Semi-Automated Surveillance Algorithm for Cardiac Device Infections: Insights from the VA CART program",
        "link": "https://www.nature.com/articles/s41598-020-62083-y",
        "publication_date": "24 Mar 2020",
        "abstract": "Procedure-related cardiac electronic implantable device (CIED) infections have high morbidity and mortality, highlighting the urgent need for infection prevention efforts to include electrophysiology procedures. We developed and validated a semi-automated algorithm based on structured electronic health records data to reliably identify CIED infections. A sample of CIED procedures entered into the Veterans’ Health Administration Clinical Assessment Reporting and Tracking program from FY 2008–2015 was reviewed for the presence of CIED infection. This sample was then randomly divided into training (2/3) validation sets (1/3). The training set was used to develop a detection algorithm containing structured variables mapped from the clinical pathways of CIED infection. Performance of this algorithm was evaluated using the validation set. 2,107 unique CIED procedures from a cohort of 5,753 underwent manual review; 97 CIED infections (4.6%) were identified. Variables strongly associated with true infections included presence of a microbiology order, billing codes for surgical site infections and post-procedural antibiotic prescriptions. The combined algorithm to detect infection demonstrated high c-statistic (0.95; 95% confidence interval: 0.92–0.98), sensitivity (87.9%) and specificity (90.3%) in the validation data. Structured variables derived from clinical pathways can guide development of a semi-automated detection tool to surveil for CIED infection.",
        "conclusions": "Existing surveillance structures for CIED infections are absent in many institutions, partially due to limited resources for detection and monitoring35. This study demonstrates that electronic surveillance tools based on structured data elements can be developed with high sensitivity and specificity and have the potential to expand measurement with audit and feedback to clinical areas that have not been served by traditional surveillance programs. Future improvements could include strategies to enhance detection of variables primarily captured in clinical notes.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Immune predictors of oral poliovirus vaccine immunogenicity among infants in South India",
        "link": "https://www.nature.com/articles/s41541-020-0178-5",
        "publication_date": "23 Mar 2020",
        "abstract": "Identification of the causes of poor oral vaccine immunogenicity in low-income countries might lead to more effective vaccines. We measured mucosal and systemic immune parameters at the time of vaccination with oral poliovirus vaccine (OPV) in 292 Indian infants aged 6–11 months, including plasma cytokines, leukocyte counts, fecal biomarkers of environmental enteropathy and peripheral blood T-cell phenotype, focused on gut-homing regulatory CD4+ populations. We did not find a distinct immune phenotype associated with OPV immunogenicity, although viral pathogens were more prevalent in stool at the time of immunization among infants who failed to seroconvert (63.9% vs. 45.6%, p = 0.002). Using a machine-learning approach, we could predict seroconversion a priori using immune parameters and infection status with a median 58% accuracy (cross-validation IQR: 50–69%) compared with 50% expected by chance. Better identification of immune predictors of OPV immunogenicity is likely to require sampling of mucosal tissue and improved oral poliovirus infection models.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Immunogenomic profiling determines responses to combined PARP and PD-1 inhibition in ovarian cancer",
        "link": "https://www.nature.com/articles/s41467-020-15315-8",
        "publication_date": "19 Mar 2020",
        "abstract": "Combined PARP and immune checkpoint inhibition has yielded encouraging results in ovarian cancer, but predictive biomarkers are lacking. We performed immunogenomic profiling and highly multiplexed single-cell imaging on tumor samples from patients enrolled in a Phase I/II trial of niraparib and pembrolizumab in ovarian cancer (NCT02657889). We identify two determinants of response; mutational signature 3 reflecting defective homologous recombination DNA repair, and positive immune score as a surrogate of interferon-primed exhausted CD8 + T-cells in the tumor microenvironment. Presence of one or both features associates with an improved outcome while concurrent absence yields no responses. Single-cell spatial analysis reveals prominent interactions of exhausted CD8 + T-cells and PD-L1 + macrophages and PD-L1 + tumor cells as mechanistic determinants of response. Furthermore, spatial analysis of two extreme responders shows differential clustering of exhausted CD8 + T-cells with PD-L1 + macrophages in the first, and exhausted CD8 + T-cells with cancer cells harboring genomic PD-L1 and PD-L2 amplification in the second.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Novel body fat estimation using machine learning and 3-dimensional optical imaging",
        "link": "https://www.nature.com/articles/s41430-020-0603-x",
        "publication_date": "16 Mar 2020",
        "abstract": "Estimates of body composition have been derived using 3-dimensional optical imaging (3DO), but no equations to date have been calibrated using a 4-component (4C) model criterion. This investigation reports the development of a novel body fat prediction formula using anthropometric data from 3DO imaging and a 4C model. Anthropometric characteristics and body composition of 179 participants were measured via 3DO (Size Stream® SS20) and a 4C model. Machine learning was used to identify significant anthropometric predictors of body fat (BF%), and stepwise/lasso regression analyses were employed to develop new 3DO-derived BF% prediction equations. The combined equation was externally cross-validated using paired 3DO and DXA assessments (n = 158), producing a R2 value of 0.78 and a constant error of (X ± SD) 0.8 ± 4.5%. 3DO BF% estimates demonstrated equivalence with DXA based on equivalence testing with no proportional bias in the Bland–Altman analysis. Machine learning methods may hold potential for enhancing 3DO-derived BF% estimates.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Skin-interfaced biosensors for advanced wireless physiological monitoring in neonatal and pediatric intensive-care units",
        "link": "https://www.nature.com/articles/s41591-020-0792-9",
        "publication_date": "11 Mar 2020",
        "abstract": "Standard clinical care in neonatal and pediatric intensive-care units (NICUs and PICUs, respectively) involves continuous monitoring of vital signs with hard-wired devices that adhere to the skin and, in certain instances, can involve catheter-based pressure sensors inserted into the arteries. These systems entail risks of causing iatrogenic skin injuries, complicating clinical care and impeding skin-to-skin contact between parent and child. Here we present a wireless, non-invasive technology that not only offers measurement equivalency to existing clinical standards for heart rate, respiration rate, temperature and blood oxygenation, but also provides a range of important additional features, as supported by data from pilot clinical studies in both the NICU and PICU. These new modalities include tracking movements and body orientation, quantifying the physiological benefits of skin-to-skin care, capturing acoustic signatures of cardiac activity, recording vocal biomarkers associated with tonality and temporal characteristics of crying and monitoring a reliable surrogate for systolic blood pressure. These platforms have the potential to substantially enhance the quality of neonatal and pediatric critical care.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting pregnancy test results after embryo transfer by image feature extraction and analysis using machine learning",
        "link": "https://www.nature.com/articles/s41598-020-61357-9",
        "publication_date": "10 Mar 2020",
        "abstract": "Assessing the viability of a blastosyst is still empirical and non-reproducible nowadays. We developed an algorithm based on artificial vision and machine learning (and other classifiers) that predicts pregnancy using the beta human chorionic gonadotropin (b-hCG) test from both the morphology of an embryo and the age of the patients. We employed two high-quality databases with known pregnancy outcomes (n = 221). We created a system consisting of different classifiers that is feed with novel morphometric features extracted from the digital micrographs, along with other non-morphometric data to predict pregnancy. It was evaluated using five different classifiers: probabilistic bayesian, Support Vector Machines (SVM), deep neural network, decision tree, and Random Forest (RF), using a k-fold cross validation to assess the model’s generalization capabilities. In the database A, the SVM classifier achieved an F1 score of 0.74, and AUC of 0.77. In the database B the RF classifier obtained a F1 score of 0.71, and AUC of 0.75. Our results suggest that the system is able to predict a positive pregnancy test from a single digital image, offering a novel approach with the advantages of using a small database, being highly adaptable to different laboratory settings, and easy integration into clinical practice.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning for characterizing risk of type 2 diabetes mellitus in a rural Chinese population: the Henan Rural Cohort Study",
        "link": "https://www.nature.com/articles/s41598-020-61123-x",
        "publication_date": "10 Mar 2020",
        "abstract": "With the development of data mining, machine learning offers opportunities to improve discrimination by analyzing complex interactions among massive variables. To test the ability of machine learning algorithms for predicting risk of type 2 diabetes mellitus (T2DM) in a rural Chinese population, we focus on a total of 36,652 eligible participants from the Henan Rural Cohort Study. Risk assessment models for T2DM were developed using six machine learning algorithms, including logistic regression (LR), classification and regression tree (CART), artificial neural networks (ANN), support vector machine (SVM), random forest (RF) and gradient boosting machine (GBM). The model performance was measured in an area under the receiver operating characteristic curve, sensitivity, specificity, positive predictive value, negative predictive value and area under precision recall curve. The importance of variables was identified based on each classifier and the shapley additive explanations approach. Using all available variables, all models for predicting risk of T2DM demonstrated strong predictive performance, with AUCs ranging between 0.811 and 0.872 using laboratory data and from 0.767 to 0.817 without laboratory data. Among them, the GBM model performed best (AUC: 0.872 with laboratory data and 0.817 without laboratory data). Performance of models plateaued when introduced 30 variables to each model except CART model. Among the top-10 variables across all methods were sweet flavor, urine glucose, age, heart rate, creatinine, waist circumference, uric acid, pulse pressure, insulin, and hypertension. New important risk factors (urinary indicators, sweet flavor) were not found in previous risk prediction methods, but determined by machine learning in our study. Through the results, machine learning methods showed competence in predicting risk of T2DM, leading to greater insights on disease risk factors with no priori assumption of causality.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Automated prediction of mastitis infection patterns in dairy herds using machine learning",
        "link": "https://www.nature.com/articles/s41598-020-61126-8",
        "publication_date": "09 Mar 2020",
        "abstract": "Mastitis in dairy cattle is extremely costly both in economic and welfare terms and is one of the most significant drivers of antimicrobial usage in dairy cattle. A critical step in the prevention of mastitis is the diagnosis of the predominant route of transmission of pathogens into either contagious (CONT) or environmental (ENV), with environmental being further subdivided as transmission during either the nonlactating “dry” period (EDP) or lactating period (EL). Using data from 1000 farms, random forest algorithms were able to replicate the complex herd level diagnoses made by specialist veterinary clinicians with a high degree of accuracy. An accuracy of 98%, positive predictive value (PPV) of 86% and negative predictive value (NPV) of 99% was achieved for the diagnosis of CONT vs ENV (with CONT as a “positive” diagnosis), and an accuracy of 78%, PPV of 76% and NPV of 81% for the diagnosis of EDP vs EL (with EDP as a “positive” diagnosis). An accurate, automated mastitis diagnosis tool has great potential to aid non-specialist veterinary clinicians to make a rapid herd level diagnosis and promptly implement appropriate control measures for an extremely damaging disease in terms of animal health, productivity, welfare and antimicrobial use.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Early prediction of circulatory failure in the intensive care unit using machine learning",
        "link": "https://www.nature.com/articles/s41591-020-0789-4",
        "publication_date": "09 Mar 2020",
        "abstract": "Intensive-care clinicians are presented with large quantities of measurements from multiple monitoring systems. The limited ability of humans to process complex information hinders early recognition of patient deterioration, and high numbers of monitoring alarms lead to alarm fatigue. We used machine learning to develop an early-warning system that integrates measurements from multiple organ systems using a high-resolution database with 240 patient-years of data. It predicts 90% of circulatory-failure events in the test set, with 82% identified more than 2 h in advance, resulting in an area under the receiver operating characteristic curve of 0.94 and an area under the precision-recall curve of 0.63. On average, the system raises 0.05 alarms per patient and hour. The model was externally validated in an independent patient cohort. Our model provides early identification of patients at risk for circulatory failure with a much lower false-alarm rate than conventional threshold-based systems.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Cutaneous optical coherence tomography for longitudinal volumetric assessment of intradermal volumes in a mouse model",
        "link": "https://www.nature.com/articles/s41598-020-61276-9",
        "publication_date": "06 Mar 2020",
        "abstract": "Clinical evaluation of skin lesions requires precise and reproducible technologies for their qualitative and quantitative assessment. In this study, we investigate the applicability of a custom-built dermatologic OCT system for longitudinal assessment of intradermal volumes in a mouse model. The OCT, based on an akinetic swept laser working at 1310 nm was employed for visualization and quantification of intradermal deposits of three different hyaluronic acid-based hydrogel formulations – one commercial and two test substances. Hydrogels were applied in 22 BALB/c mice, and measurements were performed over a six-month time period. All hydrogels increased in volume within the first weeks and degraded steadily thereafter. The half-lifes of the test hydrogels (27.2 ± 13.6 weeks for Hydrogel 1, 31.5 ± 17.2 weeks for Hydrogel 2) were higher in comparison to the commercially available HA hydrogel (21.4 ± 12.0 weeks), although differences were not significant. The sphericity parameter was used for evaluation of the deposit geometry. While on the injection day the sphericities were similar (~0.75 ± 0.04), at later time points significant differences between the different test substances were found (T24: PRV 0.59 ± 0.09, Hydrogel 1 0.70 ± 0.11, Hydrogel 2 0.78 ± 0.07; p ≤ 0.012 for all pairs). This study shows the applicability of OCT imaging for quantitative assessment of the volumetric behavior of intradermal deposits in vivo.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    }
]