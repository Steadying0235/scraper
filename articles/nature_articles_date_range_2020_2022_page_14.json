[
    {
        "title": "Serum metabolic biomarkers for synucleinopathy conversion in isolated REM sleep behavior disorder",
        "link": "https://www.nature.com/articles/s41531-021-00184-9",
        "publication_date": "13 May 2021",
        "abstract": "Isolated rapid eye movement (REM) sleep behavior disorder (iRBD) is a prodromal stage of Lewy-type synucleinopathies (LTS), which can present either with an initial predominant parkinsonism (Parkinson’s disease (PD)) or dementia (dementia with Lewy bodies (DLB)). To provide insights into the underlying pathogenic mechanisms, the lipoprotein and protein glycosylation profile of 82 iRBD patients, collected before and/or after their conversion to an overt LTS, and 29 matched control serum samples were assessed by nuclear magnetic resonance (NMR) spectroscopy. Data were statistically analyzed to identify altered metabolites and construct predictive models. Univariant analysis detected no differences between iRBD patients with an LTS compared to controls. However, significant differences were found when the analysis distinguished between iRBD patients that manifested initially predominant parkinsonism (pre-PD) or dementia (pre-DLB). Significant differences were also found in the analysis of paired iRBD samples pre- and post-LTS diagnosis. Predictive models were built and distinguished between controls and pre-DLB patients, and between pre-DLB and pre-PD patients. This allowed a prediction of the possible future clinical outcome of iRBD patients. We provide evidence of altered lipoprotein and glycosylation profiles in subgroups of iRBD patients. Our results indicate that metabolic alterations and inflammation are involved in iRBD pathophysiology, and suggest biological differences underlying the progression of LTS in iRBD patients. Our data also indicate that profiling of serum samples by NMR may be a useful tool for identifying short-term high-risk iRBD patients for conversion to parkinsonism or dementia.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Noninvasive transcranial classification of stroke using a portable eddy current damping sensor",
        "link": "https://www.nature.com/articles/s41598-021-89735-x",
        "publication_date": "13 May 2021",
        "abstract": "Existing paradigms for stroke diagnosis typically involve computed tomography (CT) imaging to classify ischemic versus hemorrhagic stroke variants, as treatment for these subtypes varies widely. Delays in diagnosis and transport of unstable patients may worsen neurological status. To address these issues, we describe the development of a rapid, portable, and accurate eddy current damping (ECD) stroke sensor. Copper wire was wound to create large (11.4 cm), medium (4.5 cm), and small (1.5 cm) solenoid coils with varying diameters, with each connected to an inductance-to-digital converter. Eight human participants were recruited between December 15, 2019 and March 15, 2020, including two hemorrhagic stroke, two ischemic stroke, one subarachnoid hemorrhage, and three control participants. Observers were blinded to lesion type and location. A head cap with 8 horizontal scanning paths was placed on the patient. The sensor was tangentially rotated across each row on the patient’s head circumferentially. Consent, positioning, and scanning with the sensor took roughly 15 min from start to end for each participant and all scanning took place at the patient bedside. The ECD sensor accurately classified and imaged each of the varying stroke types in each patient. The sensor additionally detected ischemic and hemorrhagic lesions located deep inside the brain, and its range is selectively tunable during sensor design and fabrication.",
        "conclusions": "We demonstrated feasibility of rapid and accurate bedside stroke detection using handheld ECD sensors in live human clinical ischemic and hemorrhagic stroke settings. We show that diagnosis of stroke may potentially be reduced from several hours to minutes, with additional spatial localization of intracranial hemorrhage or infarct. The sensor additionally detects ischemic and hemorrhagic lesions located deep inside the brain, and its range can be selectively tuned during sensor design and fabrication through the use of various sized coils. Further research is warranted to optimize the sensor for millimeter and sub-millimeter lesion detection to accurately and confidently guide clinical intervention.",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Random forest-based prediction of stroke outcome",
        "link": "https://www.nature.com/articles/s41598-021-89434-7",
        "publication_date": "12 May 2021",
        "abstract": "We research into the clinical, biochemical and neuroimaging factors associated with the outcome of stroke patients to generate a predictive model using machine learning techniques for prediction of mortality and morbidity 3-months after admission. The dataset consisted of patients with ischemic stroke (IS) and non-traumatic intracerebral hemorrhage (ICH) admitted to Stroke Unit of a European Tertiary Hospital prospectively registered. We identified the main variables for machine learning Random Forest (RF), generating a predictive model that can estimate patient mortality/morbidity according to the following groups: (1) IS + ICH, (2) IS, and (3) ICH. A total of 6022 patients were included: 4922 (mean age 71.9 ± 13.8 years) with IS and 1100 (mean age 73.3 ± 13.1 years) with ICH. NIHSS at 24, 48 h and axillary temperature at admission were the most important variables to consider for evolution of patients at 3-months. IS + ICH group was the most stable for mortality prediction [0.904 ± 0.025 of area under the receiver operating characteristics curve (AUC)]. IS group presented similar results, although variability between experiments was slightly higher (0.909 ± 0.032 of AUC). ICH group was the one in which RF had more problems to make adequate predictions (0.9837 vs. 0.7104 of AUC). There were no major differences between IS and IS + ICH groups according to morbidity prediction (0.738 and 0.755 of AUC) but, after checking normality with a Shapiro Wilk test with the null hypothesis that the data follow a normal distribution, it was rejected with W = 0.93546 (p-value < 2.2e−16). Conditions required for a parametric test do not hold, and we performed a paired Wilcoxon Test assuming the null hypothesis that all the groups have the same performance. The null hypothesis was rejected with a value < 2.2e−16, so there are statistical differences between IS and ICH groups. In conclusion, machine learning algorithms RF can be effectively used in stroke patients for long-term outcome prediction of mortality and morbidity.",
        "conclusions": "Machine learning algorithms, particularly Random Forest, can be effectively used in long-term outcome prediction of mortality and morbidity of stroke patients. NIHSS at 24, 48 h and axillary temperature are the most important variables to consider in the evolution of the patients at 3 months. Future studies could incorporate the use of imaging and genetic information. Furthermore, the robust model developed could be used in other applications and different scopes with similar data; such as traumatic brain injury, or dementia (Alzheimer's and Parkinson's disease).",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "COVID-Classifier: an automated machine learning model to assist in the diagnosis of COVID-19 infection in chest X-ray images",
        "link": "https://www.nature.com/articles/s41598-021-88807-2",
        "publication_date": "10 May 2021",
        "abstract": "Chest-X ray (CXR) radiography can be used as a first-line triage process for non-COVID-19 patients with pneumonia. However, the similarity between features of CXR images of COVID-19 and pneumonia caused by other infections makes the differential diagnosis by radiologists challenging. We hypothesized that machine learning-based classifiers can reliably distinguish the CXR images of COVID-19 patients from other forms of pneumonia. We used a dimensionality reduction method to generate a set of optimal features of CXR images to build an efficient machine learning classifier that can distinguish COVID-19 cases from non-COVID-19 cases with high accuracy and sensitivity. By using global features of the whole CXR images, we successfully implemented our classifier using a relatively small dataset of CXR images. We propose that our COVID-Classifier can be used in conjunction with other tests for optimal allocation of hospital resources by rapid triage of non-COVID-19 cases.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Novel AI driven approach to classify infant motor functions",
        "link": "https://www.nature.com/articles/s41598-021-89347-5",
        "publication_date": "10 May 2021",
        "abstract": "The past decade has evinced a boom of computer-based approaches to aid movement assessment in early infancy. Increasing interests have been dedicated to develop AI driven approaches to complement the classic Prechtl general movements assessment (GMA). This study proposes a novel machine learning algorithm to detect an age-specific movement pattern, the fidgety movements (FMs), in a prospectively collected sample of typically developing infants. Participants were recorded using a passive, single camera RGB video stream. The dataset of 2800 five-second snippets was annotated by two well-trained and experienced GMA assessors, with excellent inter- and intra-rater reliabilities. Using OpenPose, the infant full pose was recovered from the video stream in the form of a 25-points skeleton. This skeleton was used as input vector for a shallow multilayer neural network (SMNN). An ablation study was performed to justify the network’s architecture and hyperparameters. We show for the first time that the SMNN is sufficient to discriminate fidgety from non-fidgety movements in a sample of age-specific typical movements with a classification accuracy of 88%. The computer-based solutions will complement original GMA to consistently perform accurate and efficient screening and diagnosis that may become universally accessible in daily clinical practice in the future.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Environmental determinants of COVID-19 transmission across a wide climatic gradient in Chile",
        "link": "https://www.nature.com/articles/s41598-021-89213-4",
        "publication_date": "10 May 2021",
        "abstract": "Several studies have examined the transmission dynamics of the novel COVID-19 disease in different parts of the world. Some have reported relationships with various environmental variables, suggesting that spread of the disease is enhanced in colder and drier climates. However, evidence is still scarce and mostly limited to a few countries, particularly from Asia. We examined the potential role of multiple environmental variables in COVID-19 infection rate [measured as mean relative infection rate = (number of infected inhabitants per week / total population) × 100.000) from February 23 to August 16, 2020 across 360 cities of Chile. Chile has a large climatic gradient (≈ 40º of latitude, ≈ 4000 m of altitude and 5 climatic zones, from desert to tundra), but all cities share their social behaviour patterns and regulations. Our results indicated that COVID-19 transmission in Chile was mostly related to three main climatic factors (minimum temperature, atmospheric pressure and relative humidity). Transmission was greater in colder and drier cities and when atmospheric pressure was lower. The results of this study support some previous findings about the main climatic determinants of COVID-19 transmission, which may be useful for decision-making and management of the disease.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Validation of a DKK1 RNAscope chromogenic in situ hybridization assay for gastric and gastroesophageal junction adenocarcinoma tumors",
        "link": "https://www.nature.com/articles/s41598-021-89060-3",
        "publication_date": "10 May 2021",
        "abstract": "Dickkopf-1 (DKK1) is a secreted modulator of Wnt signaling that is frequently overexpressed in tumors and associated with poor clinical outcomes. DKN-01 is a humanized monoclonal therapeutic antibody that binds DKK1 with high affinity and has demonstrated clinical activity in gastric/gastroesophageal junction (G/GEJ) patients with elevated tumoral expression of DKK1. Here we report on the validation of a DKK1 RNAscope chromogenic in situ hybridization assay to assess DKK1 expression in G/GEJ tumor tissue. To reduce pathologist time, potential pathologist variability from manual scoring and support pathologist decision making, a digital image analysis algorithm that identifies tumor cells and quantifies the DKK1 signal was developed. Following CLIA guidelines the DKK1 RNAscope chromogenic in situ hybridization assay and digital image analysis algorithm were successfully validated for sensitivity, specificity, accuracy, and precision. The DKK1 RNAscope assay in conjunction with the digital image analysis solution is acceptable for prospective screening of G/GEJ adenocarcinoma patients. The work described here will further advance the companion diagnostic development of our DKK1 RNAscope assay and could generally be used as a guide for the validation of RNAscope assays with digital image quantification.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [
                "evasion"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A hierarchical expert-guided machine learning framework for clinical decision support systems: an application to traumatic brain injury prognostication",
        "link": "https://www.nature.com/articles/s41746-021-00445-0",
        "publication_date": "07 May 2021",
        "abstract": "Prognosis of the long-term functional outcome of traumatic brain injury is essential for personalized management of that injury. Nonetheless, accurate prediction remains unavailable. Although machine learning has shown promise in many fields, including medical diagnosis and prognosis, such models are rarely deployed in real-world settings due to a lack of transparency and trustworthiness. To address these drawbacks, we propose a machine learning-based framework that is explainable and aligns with clinical domain knowledge. To build such a framework, additional layers of statistical inference and human expert validation are added to the model, which ensures the predicted risk score’s trustworthiness. Using 831 patients with moderate or severe traumatic brain injury to build a model using the proposed framework, an area under the receiver operating characteristic curve (AUC) and accuracy of 0.8085 and 0.7488 were achieved, respectively, in determining which patients will experience poor functional outcomes. The performance of the machine learning classifier is not adversely affected by the imposition of statistical and domain knowledge “checks and balances”. Finally, through a case study, we demonstrate how the decision made by a model might be biased if it is not audited carefully.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Analysing nystagmus waveforms: a computational framework",
        "link": "https://www.nature.com/articles/s41598-021-89094-7",
        "publication_date": "07 May 2021",
        "abstract": "We present a new computational approach to analyse nystagmus waveforms. Our framework is designed to fully characterise the state of the nystagmus, aid clinical diagnosis and to quantify the dynamical changes in the oscillations over time. Both linear and nonlinear analyses of time series were used to determine the regularity and complexity of a specific homogenous phenotype of nystagmus. Two-dimensional binocular eye movement recordings were carried out on 5 adult subjects who exhibited a unilateral, uniplanar, vertical nystagmus secondary to a monocular late-onset severe visual loss in the oscillating eye (the Heimann-Bielschowsky Phenomenon). The non-affected eye held a central gaze in both horizontal and vertical planes (± 10 min. of arc). All affected eyes exhibited vertical oscillations, with mean amplitudes and frequencies ranging from 2.0°–4.0° to 0.25–1.5 Hz, respectively. Unstable periodic orbit analysis revealed only 1 subject exhibited a periodic oscillation. The remaining subjects were found to display quasiperiodic (n = 1) and nonperiodic (n = 3) oscillations. Phase space reconstruction allowed attractor identification and the computation of a time series complexity measure—the permutation entropy. The entropy measure was found to be able to distinguish between a periodic oscillation associated with a limit cycle attractor, a quasiperiodic oscillation associated with a torus attractor and nonperiodic oscillations associated with higher-dimensional attractors. Importantly, the permutation entropy was able to rank the oscillations, thereby providing an objective index of nystagmus complexity (range 0.15–0.21) that could not be obtained via unstable periodic orbit analysis or attractor identification alone. These results suggest that our framework provides a comprehensive methodology for characterising nystagmus, aiding differential diagnosis and also permitting investigation of the waveforms over time, thereby facilitating the quantification of future therapeutic managements. In addition, permutation entropy could provide an additional tool for future oculomotor modelling.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Systematic misestimation of machine learning performance in neuroimaging studies of depression",
        "link": "https://www.nature.com/articles/s41386-021-01020-7",
        "publication_date": "06 May 2021",
        "abstract": "We currently observe a disconcerting phenomenon in machine learning studies in psychiatry: While we would expect larger samples to yield better results due to the availability of more data, larger machine learning studies consistently show much weaker performance than the numerous small-scale studies. Here, we systematically investigated this effect focusing on one of the most heavily studied questions in the field, namely the classification of patients suffering from Major Depressive Disorder (MDD) and healthy controls based on neuroimaging data. Drawing upon structural MRI data from a balanced sample of N = 1868 MDD patients and healthy controls from our recent international Predictive Analytics Competition (PAC), we first trained and tested a classification model on the full dataset which yielded an accuracy of 61%. Next, we mimicked the process by which researchers would draw samples of various sizes (N = 4 to N = 150) from the population and showed a strong risk of misestimation. Specifically, for small sample sizes (N = 20), we observe accuracies of up to 95%. For medium sample sizes (N = 100) accuracies up to 75% were found. Importantly, further investigation showed that sufficiently large test sets effectively protect against performance misestimation whereas larger datasets per se do not. While these results question the validity of a substantial part of the current literature, we outline the relatively low-cost remedy of larger test sets, which is readily available in most cases.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Diagnostic accuracy of current machine learning classifiers for age-related macular degeneration: a systematic review and meta-analysis",
        "link": "https://www.nature.com/articles/s41433-021-01540-y",
        "publication_date": "06 May 2021",
        "abstract": "The objective of this study was to systematically review and meta-analyze the diagnostic accuracy of current machine learning classifiers for age-related macular degeneration (AMD). Artificial intelligence diagnostic algorithms can automatically detect and diagnose AMD through training data from large sets of fundus or OCT images. The use of AI algorithms is a powerful tool, and it is a method of obtaining a cost-effective, simple, and fast diagnosis of AMD.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Inspection of the lens thickness with preoperative biometric measurements prevents an erroneous interpretation of posterior capsule during FLACS",
        "link": "https://www.nature.com/articles/s41598-021-89209-0",
        "publication_date": "06 May 2021",
        "abstract": "Optical opacity reduces quality of biometry images, making it potentially difficult to find the correct location for irradiation during femtosecond laser-assisted cataract surgery (FLACS). After experiencing a case of posterior capsule (PC) rupture because of optical opacity, we started lens thickness (LT) inspection, which indicates comparison of between intra- and pre-operatively measured LT. We retrospectively investigated the effectiveness of the LT inspection. One observer reviewed all FLACS treatment summaries for 3 years by CATALYS in the Jikei University Hospital, Tokyo. Based on the lines defining the PC on intraoperative OCT images, all cases were classified into three groups: undescribed, appropriate and inappropriate PC. Among the 1070 cases, 1047 cases had appropriate PC. In 19 cases, the PC line was undescribed because of dense cataract. Among 474 cases with no inspection, 4 cases had an inappropriate PC. Whereas, in 596 cases with the LT inspection, there was no case of an inappropriate PC. LT inspection significantly reduced the cases with inappropriate PC. The safety margins normally work to prevent severe complications. However, rare outlier cases had a high risk of severe complications. We propose LT inspection could be the most practical and convenient way for safety surgery.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning-based mortality prediction model for heat-related illness",
        "link": "https://www.nature.com/articles/s41598-021-88581-1",
        "publication_date": "04 May 2021",
        "abstract": "In this study, we aimed to develop and validate a machine learning-based mortality prediction model for hospitalized heat-related illness patients. After 2393 hospitalized patients were extracted from a multicentered heat-related illness registry in Japan, subjects were divided into the training set for development (n = 1516, data from 2014, 2017–2019) and the test set (n = 877, data from 2020) for validation. Twenty-four variables including characteristics of patients, vital signs, and laboratory test data at hospital arrival were trained as predictor features for machine learning. The outcome was death during hospital stay. In validation, the developed machine learning models (logistic regression, support vector machine, random forest, XGBoost) demonstrated favorable performance for outcome prediction with significantly increased values of the area under the precision-recall curve (AUPR) of 0.415 [95% confidence interval (CI) 0.336–0.494], 0.395 [CI 0.318–0.472], 0.426 [CI 0.346–0.506], and 0.528 [CI 0.442–0.614], respectively, compared to that of the conventional acute physiology and chronic health evaluation (APACHE)-II score of 0.287 [CI 0.222–0.351] as a reference standard. The area under the receiver operating characteristic curve (AUROC) values were also high over 0.92 in all models, although there were no statistical differences compared to APACHE-II. This is the first demonstration of the potential of machine learning-based mortality prediction models for heat-related illnesses.",
        "conclusions": "In conclusion, a novel mortality prediction model for patients hospitalized with heat-related illness was developed using a machine learning technique. Although further improvement in the performance quality with increased sample size or inclusion of important variables, as well as prospective validation in a clinical setting are needed, our study demonstrated for the first time the potential of machine learning-based prediction models for heat-related illness.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Interrogation of gender disparity uncovers androgen receptor as the transcriptional activator for oncogenic miR-125b in gastric cancer",
        "link": "https://www.nature.com/articles/s41419-021-03727-3",
        "publication_date": "04 May 2021",
        "abstract": "There is a male preponderance in gastric cancer (GC), which suggests a role of androgen and androgen receptor (AR). However, the mechanism of AR signaling in GC especially in female patients remains obscure. We sought to identify the AR signaling pathway that might be related to prognosis and examine the potential clinical utility of the AR antagonist for treatment. Deep learning and gene set enrichment analysis was used to identify potential critical factors associated with gender bias in GC (n = 1390). Gene expression profile analysis was performed to screen differentially expressed genes associated with AR expression in the Tianjin discovery set (n = 90) and TCGA validation set (n = 341). Predictors of survival were identified via lasso regression analyses and validated in the expanded Tianjin cohort (n = 373). In vitro and in vivo experiments were established to determine the drug effect. The GC gender bias was attributable to sex chromosome abnormalities and AR signaling dysregulation. The candidates for AR-related gene sets were screened, and AR combined with miR-125b was associated with poor prognosis, particularly among female patients. AR was confirmed to directly regulate miR-125b expression. AR-miR-125b signaling pathway inhibited apoptosis and promoted proliferation. AR antagonist, bicalutamide, exerted anti-tumor activities and induced apoptosis both in vitro and in vivo, using GC cell lines and female patient-derived xenograft (PDX) model. We have shed light on gender differences by revealing a hormone-regulated oncogenic signaling pathway in GC. Our preclinical studies suggest that AR is a potential therapeutic target for this deadly cancer type, especially in female patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Gait analysis may distinguish progressive supranuclear palsy and Parkinson disease since the earliest stages",
        "link": "https://www.nature.com/articles/s41598-021-88877-2",
        "publication_date": "29 Apr 2021",
        "abstract": "Progressive supranuclear palsy (PSP) is a rare and rapidly progressing atypical parkinsonism. Albeit existing clinical criteria for PSP have good specificity and sensitivity, there is a need for biomarkers able to capture early objective disease-specific abnormalities. This study aimed to identify gait patterns specifically associated with early PSP. The study population comprised 104 consecutively enrolled participants (83 PD and 21 PSP patients). Gait was investigated using a gait analysis system during normal gait and a cognitive dual task. Univariate statistical analysis and binary logistic regression were used to compare all PD patients and all PSP patients, as well as newly diagnosed PD and early PSP patients. Gait pattern was poorer in PSP patients than in PD patients, even from early stages. PSP patients exhibited reduced velocity and increased measures of dynamic instability when compared to PD patients. Application of predictive models to gait data revealed that PD gait pattern was typified by increased cadence and longer cycle length, whereas a longer stance phase characterized PSP patients in both mid and early disease stages. The present study demonstrates that quantitative gait evaluation clearly distinguishes PSP patients from PD patients since the earliest stages of disease. First, this might candidate gait analysis as a reliable biomarker in both clinical and research setting. Furthermore, our results may offer speculative clues for conceiving early disease-specific rehabilitation strategies.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Quality by design modelling to support rapid RNA vaccine production against emerging infectious diseases",
        "link": "https://www.nature.com/articles/s41541-021-00322-7",
        "publication_date": "29 Apr 2021",
        "abstract": "Rapid-response vaccine production platform technologies, including RNA vaccines, are being developed to combat viral epidemics and pandemics. A key enabler of rapid response is having quality-oriented disease-agnostic manufacturing protocols ready ahead of outbreaks. We are the first to apply the Quality by Design (QbD) framework to enhance rapid-response RNA vaccine manufacturing against known and future viral pathogens. This QbD framework aims to support the development and consistent production of safe and efficacious RNA vaccines, integrating a novel qualitative methodology and a quantitative bioprocess model. The qualitative methodology identifies and assesses the direction, magnitude and shape of the impact of critical process parameters (CPPs) on critical quality attributes (CQAs). The mechanistic bioprocess model quantifies and maps the effect of four CPPs on the CQA of effective yield of RNA drug substance. Consequently, the first design space of an RNA vaccine synthesis bioreactor is obtained. The cost-yield optimization together with the probabilistic design space contribute towards automation of rapid-response, high-quality RNA vaccine production.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A randomized sham-controlled trial on the effect of continuous positive airway pressure treatment on gait control in severe obstructive sleep apnea patients",
        "link": "https://www.nature.com/articles/s41598-021-88642-5",
        "publication_date": "29 Apr 2021",
        "abstract": "To determine the effect of continuous positive airway pressure (CPAP), the gold standard treatment for obstructive sleep apnea syndrome (OSAS), on gait control in severe OSAS patients. We conducted a randomized, double-blind, parallel-group, sham-controlled monocentric study in Grenoble Alpes University Hospital, France. Gait parameters were recorded under single and dual-task conditions using a visuo-verbal cognitive task (Stroop test), before and after the 8-week intervention period. Stride-time variability, a marker of gait control, was the primary study endpoint. Changes in the determinants of gait control were the main secondary outcomes. ClinicalTrials.gov Identifier: (NCT02345694). 24 patients [median (Q1; Q3)]: age: 59.5 (46.3; 66.8) years, 87.5% male, body mass index: 28.2 (24.7; 29.8) kg. m−2, apnea–hypopnea index: 51.6 (35.0; 61.4) events/h were randomized to be treated by effective CPAP (n = 12) or by sham-CPAP (n = 12). A complete case analysis  was performed, using a mixed linear regression model. CPAP elicited no significant improvement in stride-time variability compared to sham-CPAP. No difference was found regarding the determinants of gait control. This study is the first RCT to investigate the effects of CPAP on gait control. Eight weeks of CPAP treatment did not improve gait control in severe non-obese OSAS patients. These results substantiate the complex OSAS-neurocognitive function relationship.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A novel algorithm to detect non-wear time from raw accelerometer data using deep convolutional neural networks",
        "link": "https://www.nature.com/articles/s41598-021-87757-z",
        "publication_date": "23 Apr 2021",
        "abstract": "To date, non-wear detection algorithms commonly employ a 30, 60, or even 90 mins interval or window in which acceleration values need to be below a threshold value. A major drawback of such intervals is that they need to be long enough to prevent false positives (type I errors), while short enough to prevent false negatives (type II errors), which limits detecting both short and longer episodes of non-wear time. In this paper, we propose a novel non-wear detection algorithm that eliminates the need for an interval. Rather than inspecting acceleration within intervals, we explore acceleration right before and right after an episode of non-wear time. We trained a deep convolutional neural network that was able to infer non-wear time by detecting when the accelerometer was removed and when it was placed back on again. We evaluate our algorithm against several baseline and existing non-wear algorithms, and our algorithm achieves a perfect precision, a recall of 0.9962, and an F1 score of 0.9981, outperforming all evaluated algorithms. Although our algorithm was developed using patterns learned from a hip-worn accelerometer, we propose algorithmic steps that can easily be applied to a wrist-worn accelerometer and a retrained classification model.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Neural network predicts need for red blood cell transfusion for patients with acute gastrointestinal bleeding admitted to the intensive care unit",
        "link": "https://www.nature.com/articles/s41598-021-88226-3",
        "publication_date": "23 Apr 2021",
        "abstract": "Acute gastrointestinal bleeding is the most common gastrointestinal cause for hospitalization. For high-risk patients requiring intensive care unit stay, predicting transfusion needs during the first 24 h using dynamic risk assessment may improve resuscitation with red blood cell transfusion in admitted patients with severe acute gastrointestinal bleeding. A patient cohort admitted for acute gastrointestinal bleeding (N = 2,524) was identified from the Medical Information Mart for Intensive Care III (MIMIC-III) critical care database and separated into training (N = 2,032) and internal validation (N = 492) sets. The external validation patient cohort was identified from the eICU collaborative database of patients admitted for acute gastrointestinal bleeding presenting to large urban hospitals (N = 1,526). 62 demographic, clinical, and laboratory test features were consolidated into 4-h time intervals over the first 24 h from admission. The outcome measure was the transfusion of red blood cells during each 4-h time interval. A long short-term memory (LSTM) model, a type of Recurrent Neural Network, was compared to a regression-based models on time-updated data. The LSTM model performed better than discrete time regression-based models for both internal validation (AUROC 0.81 vs 0.75 vs 0.75; P < 0.001) and external validation (AUROC 0.65 vs 0.56 vs 0.56; P < 0.001). A LSTM model can be used to predict the need for transfusion of packed red blood cells over the first 24 h from admission to help personalize the care of high-risk patients with acute gastrointestinal bleeding.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Assessment of patient specific information in the wild on fundus photography and optical coherence tomography",
        "link": "https://www.nature.com/articles/s41598-021-86577-5",
        "publication_date": "21 Apr 2021",
        "abstract": "In this paper we analyse the performance of machine learning methods in predicting patient information such as age or sex solely from retinal imaging modalities in a heterogeneous clinical population. Our dataset consists of N = 135,667 fundus images and N = 85,536 volumetric OCT scans. Deep learning models were trained to predict the patient’s age and sex from fundus images, OCT cross sections and OCT volumes. For sex prediction, a ROC AUC of 0.80 was achieved for fundus images, 0.84 for OCT cross sections and 0.90 for OCT volumes. Age prediction mean absolute errors of 6.328 years for fundus, 5.625 years for OCT cross sections and 4.541 for OCT volumes were observed. We assess the performance of OCT scans containing different biomarkers and note a peak performance of AUC = 0.88 for OCT cross sections and 0.95 for volumes when there is no pathology on scans. Performance drops in case of drusen, fibrovascular pigment epitheliuum detachment and geographic atrophy present. We conclude that deep learning based methods are capable of classifying the patient’s sex and age from color fundus photography and OCT for a broad spectrum of patients irrespective of underlying disease or image quality. Non-random sex prediction using fundus images seems only possible if the eye fovea and optic disc are visible.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development and validation of an early warning tool for sepsis and decompensation in children during emergency department triage",
        "link": "https://www.nature.com/articles/s41598-021-87595-z",
        "publication_date": "21 Apr 2021",
        "abstract": "This study was designed to develop and validate an early warning system for sepsis based on a predictive model of critical decompensation. Data from the electronic medical records for 537,837 visits to a pediatric Emergency Department (ED) from March 2013 to December 2019 were collected. A multiclass stochastic gradient boosting model was built to identify early warning signs associated with death, severe sepsis, non-severe sepsis, and bacteremia. Model features included triage vital signs, previous diagnoses, medications, and healthcare utilizations within 6 months of the index ED visit. There were 483 patients who had severe sepsis and/or died, 1102 had non-severe sepsis, 1103 had positive bacteremia tests, and the remaining had none of the events. The most important predictors were age, heart rate, length of stay of previous hospitalizations, temperature, systolic blood pressure, and prior sepsis. The one-versus-all area under the receiver operator characteristic curve (AUROC) were 0.979 (0.967, 0.991), 0.990 (0.985, 0.995), 0.976 (0.972, 0.981), and 0.968 (0.962, 0.974) for death, severe sepsis, non-severe sepsis, and bacteremia without sepsis respectively. The multi-class macro average AUROC and area under the precision recall curve were 0.977 and 0.316 respectively. The study findings were used to develop an automated early warning decision tool for sepsis. Implementation of this model in pediatric EDs will allow sepsis-related critical decompensation to be predicted accurately after a few seconds of triage.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Exploring photoacoustic spectroscopy-based machine learning together with metabolomics to assess breast tumor progression in a xenograft model ex vivo",
        "link": "https://www.nature.com/articles/s41374-021-00597-3",
        "publication_date": "19 Apr 2021",
        "abstract": "In the current study, a breast tumor xenograft was established in athymic nude mice by subcutaneous injection of the MCF-7 cell line and assessed the tumor progression by photoacoustic spectroscopy combined with machine learning tools. The advancement of breast tumors in nude mice was validated by tumor volume kinetics and histopathology and corresponding image analysis by TissueQuant software compared to controls. The ex vivo tumors in progressive conditions belonging to time points, day 5th, 10th, 15th & 20th, were excited with 281 nm pulsed laser light and recorded the corresponding photoacoustic spectra in time domain. The spectra were then pre-processed, augmented for a 10-fold increase in the data strength, and subjected to wavelet packet transformation for feature extraction and selection using MATLAB software. In the present study, the top 10 features from all the time point groups under study were selected based on their prediction ranking values using the mRMR algorithm. The chosen features of all the time-point groups were then subjected to multi-class Support Vector Machine (SVM) algorithms for learning and classifying into respective time point groups under study. The analysis demonstrated accuracy values of 95.2%, 99.5%, and 80.3% with SVM- Radial Basis Function (SVM-RBF), SVM-Polynomial & SVM-Linear, respectively. The serum metabolomic levels during tumor progression complemented photoacoustic patterns of tumor progression, depicting breast cancer pathophysiology.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Interpretable survival prediction for colorectal cancer using deep learning",
        "link": "https://www.nature.com/articles/s41746-021-00427-2",
        "publication_date": "19 Apr 2021",
        "abstract": "Deriving interpretable prognostic features from deep-learning-based prognostic histopathology models remains a challenge. In this study, we developed a deep learning system (DLS) for predicting disease-specific survival for stage II and III colorectal cancer using 3652 cases (27,300 slides). When evaluated on two validation datasets containing 1239 cases (9340 slides) and 738 cases (7140 slides), respectively, the DLS achieved a 5-year disease-specific survival AUC of 0.70 (95% CI: 0.66–0.73) and 0.69 (95% CI: 0.64–0.72), and added significant predictive value to a set of nine clinicopathologic features. To interpret the DLS, we explored the ability of different human-interpretable features to explain the variance in DLS scores. We observed that clinicopathologic features such as T-category, N-category, and grade explained a small fraction of the variance in DLS scores (R2 = 18% in both validation sets). Next, we generated human-interpretable histologic features by clustering embeddings from a deep-learning-based image-similarity model and showed that they explained the majority of the variance (R2 of 73–80%). Furthermore, the clustering-derived feature most strongly associated with high DLS scores was also highly prognostic in isolation. With a distinct visual appearance (poorly differentiated tumor cell clusters adjacent to adipose tissue), this feature was identified by annotators with 87.0–95.5% accuracy. Our approach can be used to explain predictions from a prognostic deep learning model and uncover potentially-novel prognostic features that can be reliably identified by people for future validation studies.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Spatio-temporal feature learning with reservoir computing for T-cell segmentation in live-cell \\(\\hbox {Ca}^{2+}\\) fluorescence microscopy",
        "link": "https://www.nature.com/articles/s41598-021-87607-y",
        "publication_date": "15 Apr 2021",
        "abstract": "Advances in high-resolution live-cell \\(\\hbox {Ca}^{2+}\\) imaging enabled subcellular localization of early \\(\\hbox {Ca}^{2+}\\) signaling events in T-cells and paved the way to investigate the interplay between receptors and potential target channels in \\(\\hbox {Ca}^{2+}\\) release events. The huge amount of acquired data requires efficient, ideally automated image processing pipelines, with cell localization/segmentation as central tasks. Automated segmentation in live-cell cytosolic \\(\\hbox {Ca}^{2+}\\) imaging data is, however, challenging due to temporal image intensity fluctuations, low signal-to-noise ratio, and photo-bleaching. Here, we propose a reservoir computing (RC) framework for efficient and temporally consistent segmentation. Experiments were conducted with Jurkat T-cells and anti-CD3 coated beads used for T-cell activation. We compared the RC performance with a standard U-Net and a convolutional long short-term memory (LSTM) model. The RC-based models (1) perform on par in terms of segmentation accuracy with the deep learning models for cell-only segmentation, but show improved temporal segmentation consistency compared to the U-Net; (2) outperform the U-Net for two-emission wavelengths image segmentation and differentiation of T-cells and beads; and (3) perform on par with the convolutional LSTM for single-emission wavelength T-cell/bead segmentation and differentiation. In turn, RC models contain only a fraction of the parameters of the baseline models and reduce the training time considerably.",
        "conclusions": "The current work demonstrates reservoir computing to be an efficient alternative to computationally expensive deep learning-based networks for temporally consistent cell segmentation in high-resolution live-cell \\(\\hbox {Ca}^{2+}\\) imaging.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Medical records-based chronic kidney disease phenotype for clinical care and “big data” observational and genetic studies",
        "link": "https://www.nature.com/articles/s41746-021-00428-1",
        "publication_date": "13 Apr 2021",
        "abstract": "Chronic Kidney Disease (CKD) represents a slowly progressive disorder that is typically silent until late stages, but early intervention can significantly delay its progression. We designed a portable and scalable electronic CKD phenotype to facilitate early disease recognition and empower large-scale observational and genetic studies of kidney traits. The algorithm uses a combination of rule-based and machine-learning methods to automatically place patients on the staging grid of albuminuria by glomerular filtration rate (“A-by-G” grid). We manually validated the algorithm by 451 chart reviews across three medical systems, demonstrating overall positive predictive value of 95% for CKD cases and 97% for healthy controls. Independent case-control validation using 2350 patient records demonstrated diagnostic specificity of 97% and sensitivity of 87%. Application of the phenotype to 1.3 million patients demonstrated that over 80% of CKD cases are undetected using ICD codes alone. We also demonstrated several large-scale applications of the phenotype, including identifying stage-specific kidney disease comorbidities, in silico estimation of kidney trait heritability in thousands of pedigrees reconstructed from medical records, and biobank-based multicenter genome-wide and phenome-wide association studies.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Investigations on the potential of optical coherence tomography as an imaging tool for eustachian tube",
        "link": "https://www.nature.com/articles/s41598-021-87637-6",
        "publication_date": "13 Apr 2021",
        "abstract": "The purpose of this study was to explore the feasibility of eustachian tube optical coherence tomography (ET-OCT) for imaging the pharyngeal region of the eustachian tube (ET). Ten subjects with ear complaints underwent ET-OCT guided by nasal endoscopy, and ET-OCT examination was performed on both sides of each subject's ETs. The process and resulting images were analysed. Ten subjects ranging from 21 to 73 years old (45 ± 14.77) were enrolled in this study. Eighteen ET-OCT imaging examinations were completed. The mean duration of each examination was 2.80 ± 1.62 min (ranging from 2 to 7 min). There were no adverse events or complications. In some subjects, the ET-OCT images clearly presented the microstructures of the ET wall, including the lumen, mucosa, submucosa, cartilage and plica. However, in some subjects, it showed different characteristics, such as an unclear hierarchy and secretions in the lumen. ET-OCT may help to distinguish the structural composition of the ET and elucidate related pathophysiological mechanisms. It is a valuable imaging tool suited for the ET, with potential diagnostic value in determining the morphology of the lumen, intraluminal mucosa and submucosal tissue in the pharyngeal region of the ET.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "COVID-19 information retrieval with deep-learning based semantic search, question answering, and abstractive summarization",
        "link": "https://www.nature.com/articles/s41746-021-00437-0",
        "publication_date": "12 Apr 2021",
        "abstract": "The COVID-19 global pandemic has resulted in international efforts to understand, track, and mitigate the disease, yielding a significant corpus of COVID-19 and SARS-CoV-2-related publications across scientific disciplines. Throughout 2020, over 400,000 coronavirus-related publications have been collected through the COVID-19 Open Research Dataset. Here, we present CO-Search, a semantic, multi-stage, search engine designed to handle complex queries over the COVID-19 literature, potentially aiding overburdened health workers in finding scientific answers and avoiding misinformation during a time of crisis. CO-Search is built from two sequential parts: a hybrid semantic-keyword retriever, which takes an input query and returns a sorted list of the 1000 most relevant documents, and a re-ranker, which further orders them by relevance. The retriever is composed of a deep learning model (Siamese-BERT) that encodes query-level meaning, along with two keyword-based models (BM25, TF-IDF) that emphasize the most important words of a query. The re-ranker assigns a relevance score to each document, computed from the outputs of (1) a question–answering module which gauges how much each document answers the query, and (2) an abstractive summarization module which determines how well a query matches a generated summary of the document. To account for the relatively limited dataset, we develop a text augmentation technique which splits the documents into pairs of paragraphs and the citations contained in them, creating millions of (citation title, paragraph) tuples for training the retriever. We evaluate our system (http://einstein.ai/covid) on the data of the TREC-COVID information retrieval challenge, obtaining strong performance across multiple key information retrieval metrics.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient",
                "healthcare practitioner"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Central and mid-peripheral corneal astigmatism in an elderly population: a retrospective analysis of Scheimpflug topography results",
        "link": "https://www.nature.com/articles/s41598-021-81772-w",
        "publication_date": "12 Apr 2021",
        "abstract": "Implantation of toric intraocular lenses (IOLs) has become standard in the correction of corneal astigmatism. The IOL selection is based on keratometric measurements of the central cornea. However, mid-peripheral corneal changes may yield suboptimal correction in patients with larger pupils. This study retrospectively analyzed corneal topography data collected using a Scheimpflug device during routine clinical examinations. Of 11,953 patients, 641 met the inclusion criteria. Total corneal astigmatism was compared between five concentric zones (2–6 mm) using vector analysis. The absolute difference between astigmatism at 2 mm and 6 mm was 0.30 D (− 0.36 to 0.64), which decreased to 0.10 D (0 to 0.20) between the 5- and 6-mm zone. With-the-rule astigmatism was the most prevalent (53%), 34% had against-the-rule (ATR), and 13% had oblique. The decrease of the cylinder power with the diameter differed significantly between the three types, with ATR and oblique astigmatism being associated with the steepest change. Patients with high corneal astigmatism tend to demonstrate larger differences between the center and mid-periphery than those with low and moderate astigmatism. In conclusion, we demonstrated that central corneal astigmatism differs from that measured at the mid-periphery and that a larger difference was found in patients with ATR, oblique and high astigmatism.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A reporting and analysis framework for structured evaluation of COVID-19 clinical and imaging data",
        "link": "https://www.nature.com/articles/s41746-021-00439-y",
        "publication_date": "12 Apr 2021",
        "abstract": "The COVID-19 pandemic has worldwide individual and socioeconomic consequences. Chest computed tomography has been found to support diagnostics and disease monitoring. A standardized approach to generate, collect, analyze, and share clinical and imaging information in the highest quality possible is urgently needed. We developed systematic, computer-assisted and context-guided electronic data capture on the FDA-approved mint LesionTM software platform to enable cloud-based data collection and real-time analysis. The acquisition and annotation include radiological findings and radiomics performed directly on primary imaging data together with information from the patient history and clinical data. As proof of concept, anonymized data of 283 patients with either suspected or confirmed SARS-CoV-2 infection from eight European medical centers were aggregated in data analysis dashboards. Aggregated data were compared to key findings of landmark research literature. This concept has been chosen for use in the national COVID-19 response of the radiological departments of all university hospitals in Germany.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Motor and sensory features successfully decode autism spectrum disorder and combine with the original RDoC framework to boost diagnostic classification",
        "link": "https://www.nature.com/articles/s41598-021-87455-w",
        "publication_date": "09 Apr 2021",
        "abstract": "Sensory processing and motor coordination atypicalities are not commonly identified as primary characteristics of autism spectrum disorder (ASD), nor are they well captured in the NIMH’s original Research Domain Criteria (RDoC) framework. Here, motor and sensory features performed similarly to RDoC features in support vector classification of 30 ASD youth against 33 typically developing controls. Combining sensory with RDoC features boosted classification performance, achieving a Matthews Correlation Coefficient (MCC) of 0.949 and balanced accuracy (BAcc) of 0.971 (p = 0.00020, calculated against a permuted null distribution). Sensory features alone successfully classified ASD (MCC = 0.565, BAcc = 0.773, p = 0.0222) against a clinically relevant control group of 26 youth with Developmental Coordination Disorder (DCD) and were in fact required to decode against DCD above chance. These findings highlight the importance of sensory and motor features to the ASD phenotype and their relevance to the RDoC framework.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development of a multivariable prediction model for severe COVID-19 disease: a population-based study from Hong Kong",
        "link": "https://www.nature.com/articles/s41746-021-00433-4",
        "publication_date": "08 Apr 2021",
        "abstract": "Recent studies have reported numerous predictors for adverse outcomes in COVID-19 disease. However, there have been few simple clinical risk scores available for prompt risk stratification. The objective is to develop a simple risk score for predicting severe COVID-19 disease using territory-wide data based on simple clinical and laboratory variables. Consecutive patients admitted to Hong Kong’s public hospitals between 1 January and 22 August 2020 and diagnosed with COVID-19, as confirmed by RT-PCR, were included. The primary outcome was composite intensive care unit admission, need for intubation or death with follow-up until 8 September 2020. An external independent cohort from Wuhan was used for model validation. COVID-19 testing was performed in 237,493 patients and 4442 patients (median age 44.8 years old, 95% confidence interval (CI): [28.9, 60.8]); 50% males) were tested positive. Of these, 209 patients (4.8%) met the primary outcome. A risk score including the following components was derived from Cox regression: gender, age, diabetes mellitus, hypertension, atrial fibrillation, heart failure, ischemic heart disease, peripheral vascular disease, stroke, dementia, liver diseases, gastrointestinal bleeding, cancer, increases in neutrophil count, potassium, urea, creatinine, aspartate transaminase, alanine transaminase, bilirubin, D-dimer, high sensitive troponin-I, lactate dehydrogenase, activated partial thromboplastin time, prothrombin time, and C-reactive protein, as well as decreases in lymphocyte count, platelet, hematocrit, albumin, sodium, low-density lipoprotein, high-density lipoprotein, cholesterol, glucose, and base excess. The model based on test results taken on the day of admission demonstrated an excellent predictive value. Incorporation of test results on successive time points did not further improve risk prediction. The derived score system was evaluated with out-of-sample five-cross-validation (AUC: 0.86, 95% CI: 0.82–0.91) and external validation (N = 202, AUC: 0.89, 95% CI: 0.85–0.93). A simple clinical score accurately predicted severe COVID-19 disease, even without including symptoms, blood pressure or oxygen status on presentation, or chest radiograph results.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development of machine learning model for diagnostic disease prediction based on laboratory tests",
        "link": "https://www.nature.com/articles/s41598-021-87171-5",
        "publication_date": "07 Apr 2021",
        "abstract": "The use of deep learning and machine learning (ML) in medical science is increasing, particularly in the visual, audio, and language data fields. We aimed to build a new optimized ensemble model by blending a DNN (deep neural network) model with two ML models for disease prediction using laboratory test results. 86 attributes (laboratory tests) were selected from datasets based on value counts, clinical importance-related features, and missing values. We collected sample datasets on 5145 cases, including 326,686 laboratory test results. We investigated a total of 39 specific diseases based on the International Classification of Diseases, 10th revision (ICD-10) codes. These datasets were used to construct light gradient boosting machine (LightGBM) and extreme gradient boosting (XGBoost) ML models and a DNN model using TensorFlow. The optimized ensemble model achieved an F1-score of 81% and prediction accuracy of 92% for the five most common diseases. The deep learning and ML models showed differences in predictive power and disease classification patterns. We used a confusion matrix and analyzed feature importance using the SHAP value method. Our new ML model achieved high efficiency of disease prediction through classification of diseases. This study will be useful in the prediction and diagnosis of diseases.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Crowdsourced privacy-preserved feature tagging of short home videos for machine learning ASD detection",
        "link": "https://www.nature.com/articles/s41598-021-87059-4",
        "publication_date": "07 Apr 2021",
        "abstract": "Standard medical diagnosis of mental health conditions requires licensed experts who are increasingly outnumbered by those at risk, limiting reach. We test the hypothesis that a trustworthy crowd of non-experts can efficiently annotate behavioral features needed for accurate machine learning detection of the common childhood developmental disorder Autism Spectrum Disorder (ASD) for children under 8 years old. We implement a novel process for identifying and certifying a trustworthy distributed workforce for video feature extraction, selecting a workforce of 102 workers from a pool of 1,107. Two previously validated ASD logistic regression classifiers, evaluated against parent-reported diagnoses, were used to assess the accuracy of the trusted crowd’s ratings of unstructured home videos. A representative balanced sample (N = 50 videos) of videos were evaluated with and without face box and pitch shift privacy alterations, with AUROC and AUPRC scores > 0.98. With both privacy-preserving modifications, sensitivity is preserved (96.0%) while maintaining specificity (80.0%) and accuracy (88.0%) at levels comparable to prior classification methods without alterations. We find that machine learning classification from features extracted by a certified nonexpert crowd achieves high performance for ASD detection from natural home videos of the child at risk and maintains high sensitivity when privacy-preserving mechanisms are applied. These results suggest that privacy-safeguarded crowdsourced analysis of short home videos can help enable rapid and mobile machine-learning detection of developmental delays in children.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Assessing the relationship between pregravid body mass index and risk of adverse maternal pregnancy and neonatal outcomes: prospective data in Southwest China",
        "link": "https://www.nature.com/articles/s41598-021-87135-9",
        "publication_date": "07 Apr 2021",
        "abstract": "The relevance of pregestational body mass index (BMI) on adverse pregnancy outcomes remained unclear in Southwest China. This study aimed to investigate the overall and age-category specific association between pre-gestational BMI and gestational diabetes mellitus (GDM), preeclampsia, cesarean delivery, preterm delivery, stillbirth, macrosomia, and small-for-gestational age (SGA) or large-for-gestational age (LGA) neonates in Southwest China. Furthermore, it explores the relative importance of influence of pregravid BMI and maternal age on pregnancy outcomes. 51,125 Chinese singleton pregnant women were recruited as study subjects. Multiple logistic regression models were used to examine the influence of pre-pregnancy BMI on adverse pregnancy outcomes. Gradient boosting machine was used to evaluate the relative importance of influence of pregravid BMI and maternal age on pregnancy outcomes. It is found that women who were overweight or obese before pregnancy are at higher risk of adverse pregnancy outcomes except for SGA neonates, while pre-pregnancy underweight is a protective factor for GDM, preeclampsia, cesarean delivery, macrosomia and LGA, but not SGA. Younger mothers are more susceptible to GDM and macrosomia neonates, while older mothers are more prone to preeclampsia. Pre-pregnancy BMI has more influence on various pregnancy outcomes than maternal age. To improve pregnancy outcomes, normal BMI weight as well as relatively young maternal ages are recommended for women in child-bearing age.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Real-time coronary artery stenosis detection based on modern neural networks",
        "link": "https://www.nature.com/articles/s41598-021-87174-2",
        "publication_date": "07 Apr 2021",
        "abstract": "Invasive coronary angiography remains the gold standard for diagnosing coronary artery disease, which may be complicated by both, patient-specific anatomy and image quality. Deep learning techniques aimed at detecting coronary artery stenoses may facilitate the diagnosis. However, previous studies have failed to achieve superior accuracy and performance for real-time labeling. Our study is aimed at confirming the feasibility of real-time coronary artery stenosis detection using deep learning methods. To reach this goal we trained and tested eight promising detectors based on different neural network architectures (MobileNet, ResNet-50, ResNet-101, Inception ResNet, NASNet) using clinical angiography data of 100 patients. Three neural networks have demonstrated superior results. The network based on Faster-RCNN Inception ResNet V2 is the most accurate and it achieved the mean Average Precision of 0.95, F1-score 0.96 and the slowest prediction rate of 3 fps on the validation subset. The relatively lightweight SSD MobileNet V2 network proved itself as the fastest one with a low mAP of 0.83, F1-score of 0.80 and a mean prediction rate of 38 fps. The model based on RFCN ResNet-101 V2 has demonstrated an optimal accuracy-to-speed ratio. Its mAP makes up 0.94, F1-score 0.96 while the prediction speed is 10 fps. The resultant performance-accuracy balance of the modern neural networks has confirmed the feasibility of real-time coronary artery stenosis detection supporting the decision-making process of the Heart Team interpreting coronary angiography findings.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Evaluating eligibility criteria of oncology trials using real-world data and AI",
        "link": "https://www.nature.com/articles/s41586-021-03430-5",
        "publication_date": "07 Apr 2021",
        "abstract": "There is a growing focus on making clinical trials more inclusive but the design of trial eligibility criteria remains challenging1,2,3. Here we systematically evaluate the effect of different eligibility criteria on cancer trial populations and outcomes with real-world data using the computational framework of Trial Pathfinder. We apply Trial Pathfinder to emulate completed trials of advanced non-small-cell lung cancer using data from a nationwide database of electronic health records comprising 61,094 patients with advanced non-small-cell lung cancer. Our analyses reveal that many common criteria, including exclusions based on several laboratory values, had a minimal effect on the trial hazard ratios. When we used a data-driven approach to broaden restrictive criteria, the pool of eligible patients more than doubled on average and the hazard ratio of the overall survival decreased by an average of 0.05. This suggests that many patients who were not eligible under the original trial criteria could potentially benefit from the treatments. We further support our findings through analyses of other types of cancer and patient-safety data from diverse clinical trials. Our data-driven methodology for evaluating eligibility criteria can facilitate the design of more-inclusive trials while maintaining safeguards for patient safety.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Towards increasing the clinical applicability of machine learning biomarkers in psychiatry",
        "link": "https://www.nature.com/articles/s41562-021-01085-w",
        "publication_date": "05 Apr 2021",
        "abstract": "arising from M. A. Just et al. Nature Human Behaviour https://doi.org/10.1038/s41562-017-0234-y (2017)",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Unsupervised behaviour analysis and magnification (uBAM) using deep learning",
        "link": "https://www.nature.com/articles/s42256-021-00326-x",
        "publication_date": "05 Apr 2021",
        "abstract": "Motor behaviour analysis is essential to biomedical research and clinical diagnostics as it provides a non-invasive strategy for identifying motor impairment and its change caused by interventions. State-of-the-art instrumented movement analysis is time- and cost-intensive, because it requires the placement of physical or virtual markers. As well as the effort required for marking the keypoints or annotations necessary for training or fine-tuning a detector, users need to know the interesting behaviour beforehand to provide meaningful keypoints. Here, we introduce unsupervised behaviour analysis and magnification (uBAM), an automatic deep learning algorithm for analysing behaviour by discovering and magnifying deviations. A central aspect is unsupervised learning of posture and behaviour representations to enable an objective comparison of movement. Besides discovering and quantifying deviations in behaviour, we also propose a generative model for visually magnifying subtle behaviour differences directly in a video without requiring a detour via keypoints or annotations. Essential for this magnification of deviations, even across different individuals, is a disentangling of appearance and behaviour. Evaluations on rodents and human patients with neurological diseases demonstrate the wide applicability of our approach. Moreover, combining optogenetic stimulation with our unsupervised behaviour analysis shows its suitability as a non-invasive diagnostic tool correlating function to brain plasticity.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A novel prognostic model to predict outcome of artificial liver support system treatment",
        "link": "https://www.nature.com/articles/s41598-021-87055-8",
        "publication_date": "05 Apr 2021",
        "abstract": "The prognosis of Artificial liver support system (ALSS) for hepatitis B virus-related acute-on-chronic liver failure (HBV-ACLF) is hard to be expected, which results in multiple operations of ALSS and excessive consumption of plasma, increase in clinical cost. A total of 375 HBV-ACLF patients receiving ALSS treatment were randomly divided a train set and an independent test set. Logistic regression analysis was conducted and a decision tree was built based on 3-month survival as outcome. The ratio of total bilirubin before and after the first time of ALSS treatment was the most significant prognostic factor, we named it RPTB. Further, a decision tree based on the multivariate logistic regression model using CTP score and the RPTB was built, dividing patients into 3 main groups such as favorable prognosis group, moderate prognosis group and poor prognosis group. A clearly-presented and easily-understood decision tree was built with a good predictive value of prognosis in HBV-related ACLF patients after first-time ALSS treatment. It will help maximal the therapeutic value of ALSS treatment and may play an important role in organ allocation for liver transplantation in the future.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting mortality risk for preterm infants using random forest",
        "link": "https://www.nature.com/articles/s41598-021-86748-4",
        "publication_date": "31 Mar 2021",
        "abstract": "Mortality is an unfortunately common outcome of extremely and very preterm birth. Existing clinical prediction models capture mortality risk at birth but fail to account for the remainder of the hospital course. Infants born < 32 weeks gestation with complete physiologic and clinical data were included in this retrospective study. Mortality risk was quantified by conventional means (clinical factors) using the CRIB-II score and the optimal logistic regression model. A random forest (RF) model was trained using a subset of the cohort, labeling data within 6 h of death as “worry.” The model was then tested using the remaining infants. A total of 275 infants were included in the study with a mean gestational age of 27 weeks, mean birth weight of 929 g, 49% female, and a mortality rate of 21%. The CRIB-II and logistic regression models had acceptable performance with sensitivities of 71% and 80% AUC scores of 0.78 and 0.84, respectively. The RF model had superior performance with a sensitivity of 88% and an AUC of 0.93. A random forest model which incorporates fixed clinical factors with the influence of aberrancies in subsequent physiology has superior performance for mortality prediction compared to conventional models.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Deep learning and ensemble stacking technique for differentiating polypoidal choroidal vasculopathy from neovascular age-related macular degeneration",
        "link": "https://www.nature.com/articles/s41598-021-86526-2",
        "publication_date": "30 Mar 2021",
        "abstract": "Polypoidal choroidal vasculopathy (PCV) and neovascular age-related macular degeneration (nAMD) share some similarity in clinical imaging manifestations. However, their disease entity and treatment strategy as well as visual outcomes are very different. To distinguish these two vision-threatening diseases is somewhat challenging but necessary. In this study, we propose a new artificial intelligence model using an ensemble stacking technique, which combines a color fundus photograph-based deep learning (DL) model and optical coherence tomography-based biomarkers, for differentiation of PCV from nAMD. Furthermore, we introduced multiple correspondence analysis, a method of transforming categorical data into principal components, to handle the dichotomous data for combining with another image DL system. This model achieved a robust performance with an accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve of 83.67%, 80.76%, 84.72%, and 88.57%, respectively, by training nearly 700 active cases with suitable imaging quality and transfer learning architecture. This work could offer an alternative method of developing a multimodal DL model, improve its efficiency for distinguishing different diseases, and facilitate the broad application of medical engineering in a DL model design.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Variable selection with false discovery rate control in deep neural networks",
        "link": "https://www.nature.com/articles/s42256-021-00308-z",
        "publication_date": "29 Mar 2021",
        "abstract": "Deep neural networks are famous for their high prediction accuracy, but they are also known for their black-box nature and poor interpretability. We consider the problem of variable selection, that is, selecting the input variables that have significant predictive power on the output, in deep neural networks. Most existing variable selection methods for neural networks are only applicable to shallow networks or are computationally infeasible on large datasets; moreover, they lack a control on the quality of selected variables. Here we propose a backward elimination procedure called SurvNet, which is based on a new measure of variable importance that applies to a wide variety of networks. More importantly, SurvNet is able to estimate and control the false discovery rate of selected variables empirically. Further, SurvNet adaptively determines how many variables to eliminate at each step in order to maximize the selection efficiency. The validity and efficiency of SurvNet are shown on various simulated and real datasets, and its performance is compared with other methods. Especially, a systematic comparison with knockoff-based methods shows that although they have more rigorous false discovery rate control on data with strong variable correlation, SurvNet usually has higher power.",
        "conclusions": "We have presented a largely automatic procedure for variable selection in neural networks (SurvNet). It is based on a new measure of variable importance that applies to a variety of networks, deep or shallow, for regression or classification, and with one or multiple output units. More importantly, SurvNet aims to estimate and control the FDR of selected variables in neural networks, which is essential for applications where the trustworthiness of variable selection is pivotal. By introducing surrogate variables, it avoids training multiple networks in parallel. SurvNet also adjusts the number of variables to eliminate at each step, and the ‘warm start’ nature of backward elimination facilitates the training of networks. On multiple simulation datasets and real datasets, SurvNet has effectively identified the significant variables. It has given a dependable estimate of FDR as well, in almost all datasets we considered.SurvNet takes advantages of modern developments of DNNs. The importance scores of input variables that are based on derivatives with respect to the inputs can be efficiently computed by functions in deep-learning packages such as TensorFlow, PyTorch, and Theano. Moreover, advances in optimization techniques and computation platforms have made the training of DNNs highly scalable. In particular, DNNs can accommodate a large number of input variables, which enables the introduction of surrogate variables.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Transforming electronic health record polysomnographic data into the Observational Medical Outcome Partnership's Common Data Model: a pilot feasibility study",
        "link": "https://www.nature.com/articles/s41598-021-86564-w",
        "publication_date": "29 Mar 2021",
        "abstract": "Well-defined large-volume polysomnographic (PSG) data can identify subgroups and predict outcomes of obstructive sleep apnea (OSA). However, current PSG data are scattered across numerous sleep laboratories and have different formats in the electronic health record (EHR). Hence, this study aimed to convert EHR PSG into a standardized data format—the Observational Medical Outcome Partnership (OMOP) common data model (CDM). We extracted the PSG data of a university hospital for the period from 2004 to 2019. We designed and implemented an extract–transform–load (ETL) process to transform PSG data into the OMOP CDM format and verified the data quality through expert evaluation. We converted the data of 11,797 sleep studies into CDM and added 632,841 measurements and 9,535 observations to the existing CDM database. Among 86 PSG parameters, 20 were mapped to CDM standard vocabulary and 66 could not be mapped; thus, new custom standard concepts were created. We validated the conversion and usefulness of PSG data through patient-level prediction analyses for the CDM data. We believe that this study represents the first CDM conversion of PSG. In the future, CDM transformation will enable network research in sleep medicine and will contribute to presenting more relevant clinical evidence.",
        "conclusions": "The Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) is a standard data format and has been applied to various EHR databases. However, its application to PSG data has not been attempted till date. To the best of our knowledge, this study represents the first attempt to transform PSG data into the OMOP CDM format. Well-defined large-volume OMOP CDM databases of PSG data can potentially enable the identification of clinically relevant OSA phenotypes, estimation of disease outcomes at the population level and prediction of outcomes at the patient-level. We expect the CDM mapping and CDM custom vocabulary of the PSG proposed in this study to contribute to the CDM conversion of PSG databases and future studies leveraging such databases.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning prediction of pathologic myopia using tomographic elevation of the posterior sclera",
        "link": "https://www.nature.com/articles/s41598-021-85699-0",
        "publication_date": "26 Mar 2021",
        "abstract": "Qualitative analysis of fundus photographs enables straightforward pattern recognition of advanced pathologic myopia. However, it has limitations in defining the classification of the degree or extent of early disease, such that it may be biased by subjective interpretation. In this study, we used the fovea, optic disc, and deepest point of the eye (DPE) as the three major markers (i.e., key indicators) of the posterior globe to quantify the relative tomographic elevation of the posterior sclera (TEPS). Using this quantitative index from eyes of 860 myopic patients, support vector machine based machine learning classifier predicted pathologic myopia an AUROC of 0.828, with 77.5% sensitivity and 88.07% specificity. Axial length and choroidal thickness, the existing quantitative indicator of pathologic myopia only reached an AUROC of 0.758, with 75.0% sensitivity and 76.61% specificity. When all six indices were applied (four TEPS, AxL, and SCT), the discriminative ability of the SVM model was excellent, demonstrating an AUROC of 0.868, with 80.0% sensitivity and 93.58% specificity. Our model provides an accurate modality for identification of patients with pathologic myopia and may help prioritize these patients for further treatment.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Bacteremic sepsis leads to higher mortality when adjusting for confounders with propensity score matching",
        "link": "https://www.nature.com/articles/s41598-021-86346-4",
        "publication_date": "26 Mar 2021",
        "abstract": "One can falsely assume that it is well known that bacteremia is associated with higher mortality in sepsis. Only a handful of studies specifically focus on the comparison of culture-negative and culture-positive sepsis with different conclusions depending on study design. The aim of this study was to describe outcome for critically ill patients with either culture-positive or -negative sepsis in a clinical review. We also aimed to identify subphenotypes of sepsis with culture status included as candidate clinical variables. Out of 784 patients treated in intensive care with a sepsis diagnosis, blood cultures were missing in 140 excluded patients and 95 excluded patients did not fulfill a sepsis diagnosis. Of 549 included patients, 295 (54%) had bacteremia, 90 (16%) were non-bacteremic but with relevant pathogens detected and in 164 (30%) no relevant pathogen was detected. After adjusting for confounders, 90-day mortality was higher in bacteremic patients, 47%, than in non-bacteremic patients, 36%, p = 0.04. We identified 8 subphenotypes, with different mortality rates, where pathogen detection in microbial samples were important for subphenotype distinction and outcome. In conclusion, bacteremic patients had higher mortality than their non-bacteremic counter-parts and bacteremia is more common in sepsis when studied in a clinical review. For reducing population heterogeneity and improve the outcome of trials and treatment for sepsis, distinction of subphenotypes might be useful and pathogen detection an important factor.",
        "conclusions": "In summary, bacteremia as well as preceding antibiotic treatment in non-bacteremic patients are related to poor outcome. Bacteremia is more common than previously described in sepsis, when a clinical chart review is used as gold-standard. A substantial portion of sepsis patients that remain microbiology-negative cannot be attributed to misdiagnosis or preceding antibiotic treatment. Distinction of subphenotypes might be useful and we demonstrated microbiological-negativity to be an important factor of a subphenotype for sepsis, with potential to reduce population and treatment heterogeneity for sepsis and improve the outcome of trials.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Methodological considerations for identifying multiple plasma proteins associated with all-cause mortality in a population-based prospective cohort",
        "link": "https://www.nature.com/articles/s41598-021-85991-z",
        "publication_date": "24 Mar 2021",
        "abstract": "Novel methods to characterize the plasma proteome has made it possible to examine a wide range of proteins in large longitudinal cohort studies, but the complexity of the human proteome makes it difficult to identify robust protein-disease associations. Nevertheless, identification of individuals at high risk of early mortality is a central issue in clinical decision making and novel biomarkers may be useful to improve risk stratification. With adjustment for established risk factors, we examined the associations between 138 plasma proteins measured using two proximity extension assays and long-term risk of all-cause mortality in 3,918 participants of the population-based Malmö Diet and Cancer Study. To examine the reproducibility of protein-mortality associations we used a two-step random-split approach to simulate a discovery and replication cohort and conducted analyses using four different methods: Cox regression, stepwise Cox regression, Lasso-Cox regression, and random survival forest (RSF). In the total study population, we identified eight proteins that associated with all-cause mortality after adjustment for established risk factors and with Bonferroni correction for multiple testing. In the two-step analyses, the number of proteins selected for model inclusion in both random samples ranged from 6 to 21 depending on the method used. However, only three proteins were consistently included in both samples across all four methods (growth/differentiation factor-15 (GDF-15), N-terminal pro-B-type natriuretic peptide, and epididymal secretory protein E4). Using the total study population, the C-statistic for a model including established risk factors was 0.7222 and increased to 0.7284 with inclusion of the most predictive protein (GDF-15; P < 0.0001). All multiple protein models showed additional improvement in the C-statistic compared to the single protein model (all P < 0.0001). We identified several plasma proteins associated with increased risk of all-cause mortality independently of established risk factors. Further investigation into the putatively causal role of these proteins for longevity is needed. In addition, the examined methods for identifying multiple proteins showed tendencies for overfitting by including several putatively false positive findings. Thus, the reproducibility of findings using such approaches may be limited.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development of a semi-automated segmentation tool for high frequency ultrasound image analysis of mouse echocardiograms",
        "link": "https://www.nature.com/articles/s41598-021-85971-3",
        "publication_date": "22 Mar 2021",
        "abstract": "Echocardiography is a widely used and clinically translatable imaging modality for the evaluation of cardiac structure and function in preclinical drug discovery and development. Echocardiograms are among the first in vivo diagnostic tools utilized to evaluate the heart due to its relatively low cost, high throughput acquisition, and non-invasive nature; however lengthy manual image analysis, intra- and inter-operator variability, and subjective image analysis presents a challenge for reproducible data generation in preclinical research. To combat the image-processing bottleneck and address both variability and reproducibly challenges, we developed a semi-automated analysis algorithm workflow to analyze long- and short-axis murine left ventricle (LV) ultrasound images. The long-axis B-mode algorithm executes a script protocol that is trained using a reference library of 322 manually segmented LV ultrasound images. The short-axis script was engineered to analyze M-mode ultrasound images in a semi-automated fashion using a pixel intensity evaluation approach, allowing analysts to place two seed-points to triangulate the local maxima of LV wall boundary annotations. Blinded operator evaluation of the semi-automated analysis tool was performed and compared to the current manual segmentation methodology for testing inter- and intra-operator reproducibility at baseline and after a pharmacologic challenge. Comparisons between manual and semi-automatic derivation of LV ejection fraction resulted in a relative difference of 1% for long-axis (B-mode) images and 2.7% for short-axis (M-mode) images. Our semi-automatic workflow approach reduces image analysis time and subjective bias, as well as decreases inter- and intra-operator variability, thereby enhancing throughput and improving data quality for pre-clinical in vivo studies that incorporate cardiac structure and function endpoints.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Changes in the brain structural connectome after a prospective randomized clinical trial of lithium and quetiapine treatment in youth with bipolar disorder",
        "link": "https://www.nature.com/articles/s41386-021-00989-5",
        "publication_date": "22 Mar 2021",
        "abstract": "The goals of the current study were to determine whether topological organization of brain structural networks is altered in youth with bipolar disorder, whether such alterations predict treatment outcomes, and whether they are normalized by treatment. Youth with bipolar disorder were randomized to double-blind treatment with quetiapine or lithium and assessed weekly. High-resolution MRI images were collected from children and adolescents with bipolar disorder who were experiencing a mixed or manic episode (n = 100) and healthy youth (n = 63). Brain networks were constructed based on the similarity of morphological features across regions and analyzed using graph theory approaches. We tested for pretreatment anatomical differences between bipolar and healthy youth and for changes in neuroanatomic network metrics following treatment in the youth with bipolar disorder. Youth with bipolar disorder showed significantly increased clustering coefficient (Cp) (p = 0.009) and characteristic path length (Lp) (p = 0.04) at baseline, and altered nodal centralities in insula, inferior frontal gyrus, and supplementary motor area. Cp, Lp, and nodal centrality of the insula exhibited normalization in patients following treatment. Changes in these neuroanatomic parameters were correlated with improvement in manic symptoms but did not differ between the two drug therapies. Baseline structural network matrices significantly differentiated medication responders and non-responders with 80% accuracy. These findings demonstrate that both global and nodal structural network features are altered in early course bipolar disorder, and that pretreatment alterations in neuroanatomic features predicted treatment outcome and were reduced by treatment. Similar connectome normalization with lithium and quetiapine suggests that the connectome changes are a downstream effect of both therapies that is related to their clinical efficacy.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Distant metastasis time to event analysis with CNNs in independent head and neck cancer cohorts",
        "link": "https://www.nature.com/articles/s41598-021-85671-y",
        "publication_date": "19 Mar 2021",
        "abstract": "Deep learning models based on medical images play an increasingly important role for cancer outcome prediction. The standard approach involves usage of convolutional neural networks (CNNs) to automatically extract relevant features from the patient’s image and perform a binary classification of the occurrence of a given clinical endpoint. In this work, a 2D-CNN and a 3D-CNN for the binary classification of distant metastasis (DM) occurrence in head and neck cancer patients were extended to perform time-to-event analysis. The newly built CNNs incorporate censoring information and output DM-free probability curves as a function of time for every patient. In total, 1037 patients were used to build and assess the performance of the time-to-event model. Training and validation was based on 294 patients also used in a previous benchmark classification study while for testing 743 patients from three independent cohorts were used. The best network could reproduce the good results from 3-fold cross validation [Harrell’s concordance indices (HCIs) of 0.78, 0.74 and 0.80] in two out of three testing cohorts (HCIs of 0.88, 0.67 and 0.77). Additionally, the capability of the models for patient stratification into high and low-risk groups was investigated, the CNNs being able to significantly stratify all three testing cohorts. Results suggest that image-based deep learning models show good reliability for DM time-to-event analysis and could be used for treatment personalisation.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Semi-automatic liver segmentation based on probabilistic models and anatomical constraints",
        "link": "https://www.nature.com/articles/s41598-021-85436-7",
        "publication_date": "17 Mar 2021",
        "abstract": "Segmenting a liver and its peripherals from abdominal computed tomography is a crucial step toward computer aided diagnosis and therapeutic intervention. Despite the recent advances in computing methods, faithfully segmenting the liver has remained a challenging task, due to indefinite boundary, intensity inhomogeneity, and anatomical variations across subjects. In this paper, a semi-automatic segmentation method based on multivariable normal distribution of liver tissues and graph-cut sub-division is presented. Although it is not fully automated, the method minimally involves human interactions. Specifically, it consists of three main stages. Firstly, a subject specific probabilistic model was built from an interior patch, surrounding a seed point specified by the user. Secondly, an iterative assignment of pixel labels was applied to gradually update the probabilistic map of the tissues based on spatio-contextual information. Finally, the graph-cut model was optimized to extract the 3D liver from the image. During post-processing, overly segmented nodal regions due to fuzzy tissue separation were removed, maintaining its correct anatomy by using robust bottleneck detection with adjacent contour constraint. The proposed system was implemented and validated on the MICCAI SLIVER07 dataset. The experimental results were benchmarked against the state-of-the-art methods, based on major clinically relevant metrics. Both visual and numerical assessments reported herein indicated that the proposed system could improve the accuracy and reliability of asymptomatic liver segmentation.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    }
]