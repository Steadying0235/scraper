[
    {
        "title": "Differentiation of recurrent glioblastoma from radiation necrosis using diffusion radiomics with machine learning model development and external validation",
        "link": "https://www.nature.com/articles/s41598-021-82467-y",
        "publication_date": "03 Feb 2021",
        "abstract": "The purpose of this study was to establish a high-performing radiomics strategy with machine learning from conventional and diffusion MRI to differentiate recurrent glioblastoma (GBM) from radiation necrosis (RN) after concurrent chemoradiotherapy (CCRT) or radiotherapy. Eighty-six patients with GBM were enrolled in the training set after they underwent CCRT or radiotherapy and presented with new or enlarging contrast enhancement within the radiation field on follow-up MRI. A diagnosis was established either pathologically or clinicoradiologically (63 recurrent GBM and 23 RN). Another 41 patients (23 recurrent GBM and 18 RN) from a different institution were enrolled in the test set. Conventional MRI sequences (T2-weighted and postcontrast T1-weighted images) and ADC were analyzed to extract 263 radiomic features. After feature selection, various machine learning models with oversampling methods were trained with combinations of MRI sequences and subsequently validated in the test set. In the independent test set, the model using ADC sequence showed the best diagnostic performance, with an AUC, accuracy, sensitivity, specificity of 0.80, 78%, 66.7%, and 87%, respectively. In conclusion, the radiomics models models using other MRI sequences showed AUCs ranging from 0.65 to 0.66 in the test set. The diffusion radiomics may be helpful in differentiating recurrent GBM from RN.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Data-driven identification of ageing-related diseases from electronic health records",
        "link": "https://www.nature.com/articles/s41598-021-82459-y",
        "publication_date": "03 Feb 2021",
        "abstract": "Reducing the burden of late-life morbidity requires an understanding of the mechanisms of ageing-related diseases (ARDs), defined as diseases that accumulate with increasing age. This has been hampered by the lack of formal criteria to identify ARDs. Here, we present a framework to identify ARDs using two complementary methods consisting of unsupervised machine learning and actuarial techniques, which we applied to electronic health records (EHRs) from 3,009,048 individuals in England using primary care data from the Clinical Practice Research Datalink (CPRD) linked to the Hospital Episode Statistics admitted patient care dataset between 1 April 2010 and 31 March 2015 (mean age 49.7 years (s.d. 18.6), 51% female, 70% white ethnicity). We grouped 278 high-burden diseases into nine main clusters according to their patterns of disease onset, using a hierarchical agglomerative clustering algorithm. Four of these clusters, encompassing 207 diseases spanning diverse organ systems and clinical specialties, had rates of disease onset that clearly increased with chronological age. However, the ages of onset for these four clusters were strikingly different, with median age of onset 82 years (IQR 82–83) for Cluster 1, 77 years (IQR 75–77) for Cluster 2, 69 years (IQR 66–71) for Cluster 3 and 57 years (IQR 54–59) for Cluster 4. Fitting to ageing-related actuarial models confirmed that the vast majority of these 207 diseases had a high probability of being ageing-related. Cardiovascular diseases and cancers were highly represented, while benign neoplastic, skin and psychiatric conditions were largely absent from the four ageing-related clusters. Our framework identifies and clusters ARDs and can form the basis for fundamental and translational research into ageing pathways.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "An open source machine learning framework for efficient and transparent systematic reviews",
        "link": "https://www.nature.com/articles/s42256-020-00287-7",
        "publication_date": "01 Feb 2021",
        "abstract": "To help researchers conduct a systematic review or meta-analysis as efficiently and transparently as possible, we designed a tool to accelerate the step of screening titles and abstracts. For many tasks—including but not limited to systematic reviews and meta-analyses—the scientific literature needs to be checked systematically. Scholars and practitioners currently screen thousands of studies by hand to determine which studies to include in their review or meta-analysis. This is error prone and inefficient because of extremely imbalanced data: only a fraction of the screened studies is relevant. The future of systematic reviewing will be an interaction with machine learning algorithms to deal with the enormous increase of available text. We therefore developed an open source machine learning-aided pipeline applying active learning: ASReview. We demonstrate by means of simulation studies that active learning can yield far more efficient reviewing than manual reviewing while providing high quality. Furthermore, we describe the options of the free and open source research software and present the results from user experience tests. We invite the community to contribute to open source projects such as our own that provide measurable and reproducible improvements over current practice.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Breath can discriminate tuberculosis from other lower respiratory illness in children",
        "link": "https://www.nature.com/articles/s41598-021-80970-w",
        "publication_date": "01 Feb 2021",
        "abstract": "Pediatric tuberculosis (TB) remains a global health crisis. Despite progress, pediatric patients remain difficult to diagnose, with approximately half of all childhood TB patients lacking bacterial confirmation. In this pilot study (n = 31), we identify a 4-compound breathprint and subsequent machine learning model that accurately classifies children with confirmed TB (n = 10) from children with another lower respiratory tract infection (LRTI) (n = 10) with a sensitivity of 80% and specificity of 100% observed across cross validation folds. Importantly, we demonstrate that the breathprint identified an additional nine of eleven patients who had unconfirmed clinical TB and whose symptoms improved while treated for TB. While more work is necessary to validate the utility of using patient breath to diagnose pediatric TB, it shows promise as a triage instrument or paired as part of an aggregate diagnostic scheme.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Synthetic skull bone defects for automatic patient-specific craniofacial implant design",
        "link": "https://www.nature.com/articles/s41597-021-00806-0",
        "publication_date": "29 Jan 2021",
        "abstract": "Patient-specific craniofacial implants are used to repair skull bone defects after trauma or surgery. Currently, cranial implants are designed and produced by third-party suppliers, which is usually time-consuming and expensive. Recent advances in additive manufacturing made the in-hospital or in-operation-room fabrication of personalized implants feasible. However, the implants are still manufactured by external companies. To facilitate an optimized workflow, fast and automatic implant manufacturing is highly desirable. Data-driven approaches, such as deep learning, show currently great potential towards automatic implant design. However, a considerable amount of data is needed to train such algorithms, which is, especially in the medical domain, often a bottleneck. Therefore, we present CT-imaging data of the craniofacial complex from 24 patients, in which we injected various artificial cranial defects, resulting in 240 data pairs and 240 corresponding implants. Based on this work, automatic implant design and manufacturing processes can be trained. Additionally, the data of this work build a solid base for researchers to work on automatic cranial implant designs.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Time-ordered comorbidity correlations identify patients at risk of mis- and overdiagnosis",
        "link": "https://www.nature.com/articles/s41746-021-00382-y",
        "publication_date": "29 Jan 2021",
        "abstract": "Diagnostic errors are common and can lead to harmful treatments. We present a data-driven, generic approach for identifying patients at risk of being mis- or overdiagnosed, here exemplified by chronic obstructive pulmonary disease (COPD). It has been estimated that 5–60% of all COPD cases are misdiagnosed. High-throughput methods are therefore needed in this domain. We have used a national patient registry, which contains hospital diagnoses for 6.9 million patients across the entire Danish population for 21 years and identified statistically significant disease trajectories for COPD patients. Using 284,154 patients diagnosed with COPD, we identified frequent disease trajectories comprising time-ordered comorbidities. Interestingly, as many as 42,459 patients did not present with these time-ordered, common comorbidities. Comparison of the individual disease history for each non-follower to the COPD trajectories, demonstrated that 9597 patients were unusual. Survival analysis showed that this group died significantly earlier than COPD patients following a trajectory. Out of the 9597 patients, we identified one subgroup comprising 2185 patients at risk of misdiagnosed COPD without the typical events of COPD patients. In all, 10% of these patients were diagnosed with lung cancer, and it seems likely that they are underdiagnosed for lung cancer as their laboratory test values and survival pattern are similar to such patients. Furthermore, only 4% had a lung function test to confirm the COPD diagnosis. Another subgroup with 2368 patients were found to be at risk of “classically” overdiagnosed COPD that survive >5.5 years after the COPD diagnosis, but without the typical complications of COPD.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [
                "poisoning"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Reduced hippocampal subfield volumes and memory performance in preterm children with and without germinal matrix-intraventricular hemorrhage",
        "link": "https://www.nature.com/articles/s41598-021-81802-7",
        "publication_date": "28 Jan 2021",
        "abstract": "Preterm newborns with germinal matrix-intraventricular hemorrhage (GM-IVH) are at a higher risk of evidencing neurodevelopmental alterations. Present study aimed to explore the long-term effects that GM-IVH have on hippocampal subfields, and their correlates with memory. The sample consisted of 58 participants, including 36 preterm-born (16 with GM-IVH and 20 without neonatal brain injury), and 22 full-term children aged between 6 and 15 years old. All participants underwent a cognitive assessment and magnetic resonance imaging study. GM-IVH children evidenced lower scores in Full Intelligence Quotient and memory measures compared to their low-risk preterm and full-term peers. High-risk preterm children with GM-IVH evidenced significantly lower total hippocampal volumes bilaterally and hippocampal subfield volumes compared to both low-risk preterm and full-term groups. Finally, significant positive correlations between memory and hippocampal subfield volumes were only found in preterm participants together; memory and the right CA-field correlation remained significant after Bonferroni correction was applied (p = .002). In conclusion, memory alterations and both global and regional volumetric reductions in the hippocampus were found to be specifically related to a preterm sample with GM-IVH. Nevertheless, results also suggest that prematurity per se has a long-lasting impact on the association between the right CA-field volume and memory during childhood.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Quantitative evaluation of the human vocal fold extracellular matrix using multiphoton microscopy and optical coherence tomography",
        "link": "https://www.nature.com/articles/s41598-021-82157-9",
        "publication_date": "28 Jan 2021",
        "abstract": "Identifying distinct normal extracellular matrix (ECM) features from pathology is of the upmost clinical importance for laryngeal diagnostics and therapy. Despite remarkable histological contributions, our understanding of the vocal fold (VF) physiology remains murky. The emerging field of non-invasive 3D optical imaging may be well-suited to unravel the complexity of the VF microanatomy. This study focused on characterizing the entire VF ECM in length and depth with optical imaging. A quantitative morphometric evaluation of the human vocal fold lamina propria using two-photon excitation fluorescence (TPEF), second harmonic generation (SHG), and optical coherence tomography (OCT) was investigated. Fibrillar morphological features, such as fiber diameter, orientation, anisotropy, waviness and second-order statistics features were evaluated and compared according to their spatial distribution. The evidence acquired in this study suggests that the VF ECM is not a strict discrete three-layer structure as traditionally described but instead a continuous assembly of different fibrillar arrangement anchored by predominant collagen transitions zones. We demonstrated that the ECM composition is distinct and markedly thinned in the anterior one-third of itself, which may play a role in the development of some laryngeal diseases. We further examined and extracted the relationship between OCT and multiphoton imaging, promoting correspondences that could lead to accurate 3D mapping of the VF architecture in real-time during phonosurgeries. As miniaturization of optical probes is consistently improving, a clinical translation of OCT imaging and multiphoton imaging, with valuable qualitative and quantitative features, may have significant implications for treating voice disorders.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Inhibition of mitochondrial function by metformin increases glucose uptake, glycolysis and GDF-15 release from intestinal cells",
        "link": "https://www.nature.com/articles/s41598-021-81349-7",
        "publication_date": "28 Jan 2021",
        "abstract": "Even though metformin is widely used to treat type2 diabetes, reducing glycaemia and body weight, the mechanisms of action are still elusive. Recent studies have identified the gastrointestinal tract as an important site of action. Here we used intestinal organoids to explore the effects of metformin on intestinal cell physiology. Bulk RNA-sequencing analysis identified changes in hexose metabolism pathways, particularly glycolytic genes. Metformin increased expression of Slc2a1 (GLUT1), decreased expression of Slc2a2 (GLUT2) and Slc5a1 (SGLT1) whilst increasing GLUT-dependent glucose uptake and glycolytic rate as observed by live cell imaging of genetically encoded metabolite sensors and measurement of oxygen consumption and extracellular acidification rates. Metformin caused mitochondrial dysfunction and metformin’s effects on 2D-cultures were phenocopied by treatment with rotenone and antimycin-A, including upregulation of GDF15 expression, previously linked to metformin dependent weight loss. Gene expression changes elicited by metformin were replicated in 3D apical-out organoids and distal small intestines of metformin treated mice. We conclude that metformin affects glucose uptake, glycolysis and GDF-15 secretion, likely downstream of the observed mitochondrial dysfunction. This may explain the effects of metformin on intestinal glucose utilisation and food balance.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Using machine learning improves predictions of herd-level bovine tuberculosis breakdowns in Great Britain",
        "link": "https://www.nature.com/articles/s41598-021-81716-4",
        "publication_date": "26 Jan 2021",
        "abstract": "In the United Kingdom, despite decades of control efforts, bovine tuberculosis (bTB) has not been controlled and currently costs ~ £100 m annually. Critical in the failure of control efforts has been the lack of a sufficiently sensitive diagnostic test. Here we use machine learning (ML) to predict herd-level bTB breakdowns in Great Britain (GB) with the aim of improving herd-level diagnostic sensitivity. The results of routinely-collected herd-level tests were correlated with risk factor data. Four ML methods were independently trained with data from 2012–2014 including ~ 4700 positive herd-level test results annually. The best model’s performance was compared to the observed sensitivity and specificity of the herd-level test calculated on the 2015 data resulting in an increased herd-level sensitivity from 61.3 to 67.6% (95% confidence interval (CI): 66.4–68.8%) and herd-level specificity from 90.5 to 92.3% (95% CI: 91.6–93.1%). This approach can improve predictive capability for herd-level bTB and support disease control.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting the central 10 degrees visual field in glaucoma by applying a deep learning algorithm to optical coherence tomography images",
        "link": "https://www.nature.com/articles/s41598-020-79494-6",
        "publication_date": "26 Jan 2021",
        "abstract": "We aimed to develop a model to predict visual field (VF) in the central 10 degrees in patients with glaucoma, by training a convolutional neural network (CNN) with optical coherence tomography (OCT) images and adjusting the values with Humphrey Field Analyzer (HFA) 24–2 test. The training dataset included 558 eyes from 312 glaucoma patients and 90 eyes from 46 normal subjects. The testing dataset included 105 eyes from 72 glaucoma patients. All eyes were analyzed by the HFA 10-2 test and OCT; eyes in the testing dataset were additionally analyzed by the HFA 24-2 test. During CNN model training, the total deviation (TD) values of the HFA 10-2 test point were predicted from the combined OCT-measured macular retinal layers’ thicknesses. Then, the predicted TD values were corrected using the TD values of the innermost four points from the HFA 24-2 test. Mean absolute error derived from the CNN models ranged between 9.4 and 9.5 B. These values reduced to 5.5 dB on average, when the data were corrected using the HFA 24-2 test. In conclusion, HFA 10-2 test results can be predicted with a OCT images using a trained CNN model with adjustment using HFA 24-2 test.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The impact of tinnitus distress on cognition",
        "link": "https://www.nature.com/articles/s41598-021-81728-0",
        "publication_date": "26 Jan 2021",
        "abstract": "Tinnitus is the chronic perception of a phantom sound with different levels of related distress. Past research has elucidated interactions of tinnitus distress with audiological, affective and further clinical variables. The influence of tinnitus distress on cognition is underinvestigated. Our study aims at investigating specific influences of tinnitus distress and further associated predictors on cognition in a cohort of n = 146 out-ward clinical tinnitus patients. Age, educational level, hearing loss, Tinnitus Questionnaire (TQ) score, tinnitus duration, speech in noise (SIN), stress, anxiety and depression, and psychological well-being were included as predictors of a machine learning regression approach (elastic net) in three models with scores of a multiple choice vocabulary test (MWT-B), or two trail-making tests (TMT-A and TMT-B), as dependent variables. TQ scores predicted lower MWT-B scores and higher TMT-B test completion time. Stress, emotional, and psychological variables were not found to be relevant predictors in all models with the exception of small positive influences of SIN and depression on TMT-B. Effect sizes were small to medium for all models and predictors. Results are indicative of specific influence of tinnitus distress on cognitive performance, especially on general or crystallized intelligence and executive functions. More research is needed at the delicate intersection of tinnitus distress and cognitive skills needed in daily functioning.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Stress testing reveals gaps in clinic readiness of image-based diagnostic artificial intelligence models",
        "link": "https://www.nature.com/articles/s41746-020-00380-6",
        "publication_date": "21 Jan 2021",
        "abstract": "Artificial intelligence models match or exceed dermatologists in melanoma image classification. Less is known about their robustness against real-world variations, and clinicians may incorrectly assume that a model with an acceptable area under the receiver operating characteristic curve or related performance metric is ready for clinical use. Here, we systematically assessed the performance of dermatologist-level convolutional neural networks (CNNs) on real-world non-curated images by applying computational “stress tests”. Our goal was to create a proxy environment in which to comprehensively test the generalizability of off-the-shelf CNNs developed without training or evaluation protocols specific to individual clinics. We found inconsistent predictions on images captured repeatedly in the same setting or subjected to simple transformations (e.g., rotation). Such transformations resulted in false positive or negative predictions for 6.5–22% of skin lesions across test datasets. Our findings indicate that models meeting conventionally reported metrics need further validation with computational stress tests to assess clinic readiness.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Personal neoantigen vaccines induce persistent memory T cell responses and epitope spreading in patients with melanoma",
        "link": "https://www.nature.com/articles/s41591-020-01206-4",
        "publication_date": "21 Jan 2021",
        "abstract": "Personal neoantigen vaccines have been envisioned as an effective approach to induce, amplify and diversify antitumor T cell responses. To define the long-term effects of such a vaccine, we evaluated the clinical outcome and circulating immune responses of eight patients with surgically resected stage IIIB/C or IVM1a/b melanoma, at a median of almost 4 years after treatment with NeoVax, a long-peptide vaccine targeting up to 20 personal neoantigens per patient (NCT01970358). All patients were alive and six were without evidence of active disease. We observed long-term persistence of neoantigen-specific T cell responses following vaccination, with ex vivo detection of neoantigen-specific T cells exhibiting a memory phenotype. We also found diversification of neoantigen-specific T cell clones over time, with emergence of multiple T cell receptor clonotypes exhibiting distinct functional avidities. Furthermore, we detected evidence of tumor infiltration by neoantigen-specific T cell clones after vaccination and epitope spreading, suggesting on-target vaccine-induced tumor cell killing. Personal neoantigen peptide vaccines thus induce T cell responses that persist over years and broaden the spectrum of tumor-specific cytotoxicity in patients with melanoma.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predictors of change in suicidal ideation across treatment phases of major depressive disorder: analysis of the STAR*D data",
        "link": "https://www.nature.com/articles/s41386-020-00953-9",
        "publication_date": "21 Jan 2021",
        "abstract": "The effects of common antidepressants on suicidal ideation (SI) is unclear. In the landmark STAR*D trial antidepressants were effective for Major Depressive Disorder (MDD) in early treatment phases, but less effective in later phases. The effects of antidepressants on SI across the entire sample of the STAR*D trial has never been investigated. We performed a secondary analysis of the STAR*D data with the primary outcome of change in score on the suicide item (item three) of the Hamilton Rating Scale for Depression (HRSD17) across all four study levels. We used descriptive statistics and logistic regression analyses. Pearson correlation was used for change in SI versus change in depression (HRSD16). Reduction in mean (SD) SI was greater in levels one: 0.29 (±0.78) (p < 0.001) and two: 0.26 (±0.88) (p < 0.001) than in levels three: 0.16 (±0.92) (p = 0.005) and four: 0.18 (±0.93) (p = 0.094). A history of past suicide attempts (OR 1.72, p = 0.007), comorbid medical illness (OR 2.23, p = 0.005), and a family history of drug abuse (OR 1.69, p = 0.008) were correlated with worsening of SI across level one. Treatment with bupropion (OR 0.24, p < 0.001) or buspirone (OR 0.24, p = 0.001) were correlated with lowering of SI across level two. Improvement in SI was correlated with improvement in overall depression (HRSD16) at level one: r(3756) = 0.48; level two: r(1027) = 0.38; level three: r(249) = 0.31; and level four: r(75) = 0.42 (p < 0.001 for all levels). Improvement in SI is limited with pharmacotherapy in patients with treatment-resistant depression. Treatments with known anti-suicidal effects in MDD, such as ECT, should be considered in these patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Impaired meningeal lymphatic drainage in patients with idiopathic Parkinson’s disease",
        "link": "https://www.nature.com/articles/s41591-020-01198-1",
        "publication_date": "18 Jan 2021",
        "abstract": "Animal studies implicate meningeal lymphatic dysfunction in the pathogenesis of neurodegenerative diseases such as Alzheimer’s disease and Parkinson’s disease (PD). However, there is no direct evidence in humans to support this role1,2,3,4,5. In this study, we used dynamic contrast-enhanced magnetic resonance imaging to assess meningeal lymphatic flow in cognitively normal controls and patients with idiopathic PD (iPD) or atypical Parkinsonian (AP) disorders. We found that patients with iPD exhibited significantly reduced flow through the meningeal lymphatic vessels (mLVs) along the superior sagittal sinus and sigmoid sinus, as well as a notable delay in deep cervical lymph node perfusion, compared to patients with AP. There was no significant difference in the size (cross-sectional area) of mLVs in patients with iPD or AP versus controls. In mice injected with α-synuclein (α-syn) preformed fibrils, we showed that the emergence of α-syn pathology was followed by delayed meningeal lymphatic drainage, loss of tight junctions among meningeal lymphatic endothelial cells and increased inflammation of the meninges. Finally, blocking flow through the mLVs in mice treated with α-syn preformed fibrils increased α-syn pathology and exacerbated motor and memory deficits. These results suggest that meningeal lymphatic drainage dysfunction aggravates α-syn pathology and contributes to the progression of PD.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Employing a systematic approach to biobanking and analyzing clinical and genetic data for advancing COVID-19 research",
        "link": "https://www.nature.com/articles/s41431-020-00793-7",
        "publication_date": "17 Jan 2021",
        "abstract": "Within the GEN-COVID Multicenter Study, biospecimens from more than 1000 SARS-CoV-2 positive individuals have thus far been collected in the GEN-COVID Biobank (GCB). Sample types include whole blood, plasma, serum, leukocytes, and DNA. The GCB links samples to detailed clinical data available in the GEN-COVID Patient Registry (GCPR). It includes hospitalized patients (74.25%), broken down into intubated, treated by CPAP-biPAP, treated with O2 supplementation, and without respiratory support (9.5%, 18.4%, 31.55% and 14.8, respectively); and non-hospitalized subjects (25.75%), either pauci- or asymptomatic. More than 150 clinical patient-level data fields have been collected and binarized for further statistics according to the organs/systems primarily affected by COVID-19: heart, liver, pancreas, kidney, chemosensors, innate or adaptive immunity, and clotting system. Hierarchical clustering analysis identified five main clinical categories: (1) severe multisystemic failure with either thromboembolic or pancreatic variant; (2) cytokine storm type, either severe with liver involvement or moderate; (3) moderate heart type, either with or without liver damage; (4) moderate multisystemic involvement, either with or without liver damage; (5) mild, either with or without hyposmia. GCB and GCPR are further linked to the GCGDR, which includes data from whole-exome sequencing and high-density SNP genotyping. The data are available for sharing through the Network for Italian Genomes, found within the COVID-19 dedicated section. The study objective is to systematize this comprehensive data collection and begin identifying multi-organ involvement in COVID-19, defining genetic parameters for infection susceptibility within the population, and mapping genetically COVID-19 severity and clinical complexity among patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A machine learning-based predictor for the identification of the recurrence of patients with gastric cancer after operation",
        "link": "https://www.nature.com/articles/s41598-021-81188-6",
        "publication_date": "15 Jan 2021",
        "abstract": "To explore the predictive performance of machine learning on the recurrence of patients with gastric cancer after the operation. The available data is divided into two parts. In particular, the first part is used as a training set (such as 80% of the original data), and the second part is used as a test set (the remaining 20% of the data). And we use fivefold cross-validation. The weight of recurrence factors shows the top four factors are BMI, Operation time, WGT and age in order. In training group:among the 5 machine learning models, the accuracy of gbm was 0.891, followed by gbm algorithm was 0.876; The AUC values of the five machine learning algorithms are from high to low as forest (0.962), gbm (0.922), GradientBoosting (0.898), DecisionTree (0.790) and Logistic (0.748). And the precision of the forest is the highest 0.957, followed by the GradientBoosting algorithm (0.878). At the same time, in the test group is as follows: the highest accuracy of Logistic was 0.801, followed by forest algorithm and gbm; the AUC values of the five algorithms are forest (0.795), GradientBoosting (0.774), DecisionTree (0.773), Logistic (0.771) and gbm (0.771), from high to low. Among the five machine learning algorithms, the highest precision rate of Logistic is 1.000, followed by the gbm (0.487). Machine learning can predict the recurrence of gastric cancer patients after an operation. Besides, the first four factors affecting postoperative recurrence of gastric cancer were BMI, Operation time, WGT and age.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The Feature Ambiguity Mitigate Operator model helps improve bone fracture detection on X-ray radiograph",
        "link": "https://www.nature.com/articles/s41598-021-81236-1",
        "publication_date": "15 Jan 2021",
        "abstract": "This study was performed to propose a method, the Feature Ambiguity Mitigate Operator (FAMO) model, to mitigate feature ambiguity in bone fracture detection on radiographs of various body parts. A total of 9040 radiographic studies were extracted. These images were classified into several body part types including 1651 hand, 1302 wrist, 406 elbow, 696 shoulder, 1580 pelvic, 948 knee, 1180 ankle, and 1277 foot images. Instance segmentation was annotated by radiologists. The ResNext-101+FPN was employed as the baseline network structure and the FAMO model for processing. The proposed FAMO model and other ablative models were tested on a test set of 20% total radiographs in a balanced body part distribution. To the per-fracture extent, an AP (average precision) analysis was performed. For per-image and per-case, the sensitivity, specificity, and AUC (area under the receiver operating characteristic curve) were analyzed. At the per-fracture level, the controlled experiment set the baseline AP to 76.8% (95% CI: 76.1%, 77.4%), and the major experiment using FAMO as a preprocessor improved the AP to 77.4% (95% CI: 76.6%, 78.2%). At the per-image level, the sensitivity, specificity, and AUC were 61.9% (95% CI: 58.7%, 65.0%), 91.5% (95% CI: 89.5%, 93.3%), and 74.9% (95% CI: 74.1%, 75.7%), respectively, for the controlled experiment, and 64.5% (95% CI: 61.3%, 67.5%), 92.9% (95% CI: 91.0%, 94.5%), and 77.5% (95% CI: 76.5%, 78.5%), respectively, for the experiment with FAMO. At the per-case level, the sensitivity, specificity, and AUC were 74.9% (95% CI: 70.6%, 78.7%), 91.7%% (95% CI: 88.8%, 93.9%), and 85.7% (95% CI: 84.8%, 86.5%), respectively, for the controlled experiment, and 77.5% (95% CI: 73.3%, 81.1%), 93.4% (95% CI: 90.7%, 95.4%), and 86.5% (95% CI: 85.6%, 87.4%), respectively, for the experiment with FAMO. In conclusion, in bone fracture detection, FAMO is an effective preprocessor to enhance model performance by mitigating feature ambiguity in the network.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of short-term antidepressant response using probabilistic graphical models with replication across multiple drugs and treatment settings",
        "link": "https://www.nature.com/articles/s41386-020-00943-x",
        "publication_date": "15 Jan 2021",
        "abstract": "Heterogeneity in the clinical presentation of major depressive disorder and response to antidepressants limits clinicians’ ability to accurately predict a specific patient’s eventual response to therapy. Validated depressive symptom profiles may be an important tool for identifying poor outcomes early in the course of treatment. To derive these symptom profiles, we first examined data from 947 depressed subjects treated with selective serotonin reuptake inhibitors (SSRIs) to delineate the heterogeneity of antidepressant response using probabilistic graphical models (PGMs). We then used unsupervised machine learning to identify specific depressive symptoms and thresholds of improvement that were predictive of antidepressant response by 4 weeks for a patient to achieve remission, response, or nonresponse by 8 weeks. Four depressive symptoms (depressed mood, guilt feelings and delusion, work and activities and psychic anxiety) and specific thresholds of change in each at 4 weeks predicted eventual outcome at 8 weeks to SSRI therapy with an average accuracy of 77% (p = 5.5E-08). The same four symptoms and prognostic thresholds derived from patients treated with SSRIs correctly predicted outcomes in 72% (p = 1.25E-05) of 1996 patients treated with other antidepressants in both inpatient and outpatient settings in independent publicly-available datasets. These predictive accuracies were higher than the accuracy of 53% for predicting SSRI response achieved using approaches that (i) incorporated only baseline clinical and sociodemographic factors, or (ii) used 4-week nonresponse status to predict likely outcomes at 8 weeks. The present findings suggest that PGMs providing interpretable predictions have the potential to enhance clinical treatment of depression and reduce the time burden associated with trials of ineffective antidepressants. Prospective trials examining this approach are forthcoming.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Fall predictors beyond fall risk assessment tool items for acute hospitalized older adults: a matched case–control study",
        "link": "https://www.nature.com/articles/s41598-021-81034-9",
        "publication_date": "15 Jan 2021",
        "abstract": "We investigated whether clinical factors including comorbidities, medications, and laboratory results predict inpatient fall risk in older adults. The participants in this case–control study included hospitalized older adults with acute conditions who had falls during their hospital stay (case group) and 410 hospitalized older adults who did not experience falls (control group). Data on medical history, fall risk assessment (Morse Fall Scale; MFS), medications, and laboratory results were obtained. Conditional logistic regression analysis was performed to estimate the association between clinical factors and falls. Receiver operating characteristic curves and area under the curve (AUC) were used to determine whether clinical factors could discriminate between fallers and controls. We evaluated three models: (M1) MFS, (M2) M1 plus age, sex, ward, and polypharmacy, and (M3) M2 plus clinical factors. Patients with diabetes mellitus or MFS scores ≥ 45 had the highest risk of falls. Calcium channel blockers, diuretics, anticonvulsants, and benzodiazepines were associated with high fall risk. The AUC of the three models was 0.615, 0.646, and 0.725, respectively (M1 vs. M2, P = 0.042 and M2 vs. M3, P < .001). Examining clinical factors led to significant improvements in fall prediction beyond that of the MFS in hospitalized older adults.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning predicts lymph node metastasis of poorly differentiated-type intramucosal gastric cancer",
        "link": "https://www.nature.com/articles/s41598-020-80582-w",
        "publication_date": "14 Jan 2021",
        "abstract": "To construct a machine learning algorithm model of lymph node metastasis (LNM) in patients with poorly differentiated-type intramucosal gastric cancer. 1169 patients with postoperative gastric cancer were divided into a training group and a test group at a ratio of 7:3. The model for lymph node metastasis was established with python machine learning. The Gbdt algorithm in the machine learning results finds that number of resected nodes, lymphovascular invasion and tumor size are the primary 3 factors that account for the weight of LNM. Effect of the LNM model of PDC gastric cancer patients in the training group: Among the 7 algorithm models, the highest accuracy rate was that of GBDT (0.955); The AUC values for the 7 algorithms were, from high to low, XGB (0.881), RF (0.802), GBDT (0.798), LR (0.778), XGB + LR (0.739), RF + LR (0.691) and GBDT + LR (0.626). Results of the LNM model of PDC gastric cancer patients in test group : Among the 7 algorithmic models, XGB had the highest accuracy rate (0.952); Among the 7 algorithms, the AUC values, from high to low, were GBDT (0.788), RF (0.765), XGB (0.762), LR (0.750), RF + LR (0.678), GBDT + LR (0.650) and XGB + LR (0.619). Single machine learning algorithm can predict LNM in poorly differentiated-type intramucosal gastric cancer, but fusion algorithm can not improve the effect of machine learning in predicting LNM.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "G-computation and machine learning for estimating the causal effects of binary exposure statuses on binary outcomes",
        "link": "https://www.nature.com/articles/s41598-021-81110-0",
        "publication_date": "14 Jan 2021",
        "abstract": "In clinical research, there is a growing interest in the use of propensity score-based methods to estimate causal effects. G-computation is an alternative because of its high statistical power. Machine learning is also increasingly used because of its possible robustness to model misspecification. In this paper, we aimed to propose an approach that combines machine learning and G-computation when both the outcome and the exposure status are binary and is able to deal with small samples. We evaluated the performances of several methods, including penalized logistic regressions, a neural network, a support vector machine, boosted classification and regression trees, and a super learner through simulations. We proposed six different scenarios characterised by various sample sizes, numbers of covariates and relationships between covariates, exposure statuses, and outcomes. We have also illustrated the application of these methods, in which they were used to estimate the efficacy of barbiturates prescribed during the first 24 h of an episode of intracranial hypertension. In the context of GC, for estimating the individual outcome probabilities in two counterfactual worlds, we reported that the super learner tended to outperform the other approaches in terms of both bias and variance, especially for small sample sizes. The support vector machine performed well, but its mean bias was slightly higher than that of the super learner. In the investigated scenarios, G-computation associated with the super learner was a performant method for drawing causal inferences, even from small sample sizes.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Inferred retinal sensitivity in recessive Stargardt disease using machine learning",
        "link": "https://www.nature.com/articles/s41598-020-80766-4",
        "publication_date": "14 Jan 2021",
        "abstract": "Spatially-resolved retinal function can be measured by psychophysical testing like fundus-controlled perimetry (FCP or ‘microperimetry’). It may serve as a performance outcome measure in emerging interventional clinical trials for macular diseases as requested by regulatory agencies. As FCP constitute laborious examinations, we have evaluated a machine-learning-based approach to predict spatially-resolved retinal function (’inferred sensitivity’) based on microstructural imaging (obtained by spectral domain optical coherence tomography) and patient data in recessive Stargardt disease. Using nested cross-validation, prediction accuracies of (mean absolute error, MAE [95% CI]) 4.74 dB [4.48–4.99] were achieved. After additional inclusion of limited FCP data, the latter reached 3.89 dB [3.67–4.10] comparable to the test–retest MAE estimate of 3.51 dB [3.11–3.91]. Analysis of the permutation importance revealed, that the IS&OS and RPE thickness were the most important features for the prediction of retinal sensitivity. ’Inferred sensitivity’, herein, enables to accurately estimate differential effects of retinal microstructure on spatially-resolved function in Stargardt disease, and might be used as quasi-functional surrogate marker for a refined and time-efficient investigation of possible functionally relevant treatment effects or disease progression.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Multi-scale image analysis and prediction of visual field defects after selective amygdalohippocampectomy",
        "link": "https://www.nature.com/articles/s41598-020-80751-x",
        "publication_date": "14 Jan 2021",
        "abstract": "Selective amygdalohippocampectomy is an effective treatment for patients with therapy-refractory temporal lobe epilepsy but may cause visual field defect (VFD). Here, we aimed to describe tissue-specific pre- and postoperative imaging correlates of the VFD severity using whole-brain analyses from voxel- to network-level. Twenty-eight patients with temporal lobe epilepsy underwent pre- and postoperative MRI (T1-MPRAGE and Diffusion Tensor Imaging) as well as kinetic perimetry according to Goldmann standard. We probed for whole-brain gray matter (GM) and white matter (WM) correlates of VFD using voxel-based morphometry and tract-based spatial statistics, respectively. We furthermore reconstructed individual structural connectomes and conducted local and global network analyses. Two clusters in the bihemispheric middle temporal gyri indicated a postsurgical GM volume decrease with increasing VFD severity (FWE-corrected p < 0.05). A single WM cluster showed a fractional anisotropy decrease with increasing severity of VFD in the ipsilesional optic radiation (FWE-corrected p < 0.05). Furthermore, patients with (vs. without) VFD showed a higher number of postoperative local connectivity changes. Neither in the GM, WM, nor in network metrics we found preoperative correlates of VFD severity. Still, in an explorative analysis, an artificial neural network meta-classifier could predict the occurrence of VFD based on presurgical connectomes above chance level.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development of a machine learning model for predicting pediatric mortality in the early stages of intensive care unit admission",
        "link": "https://www.nature.com/articles/s41598-020-80474-z",
        "publication_date": "13 Jan 2021",
        "abstract": "The aim of this study was to develop a predictive model of pediatric mortality in the early stages of intensive care unit (ICU) admission using machine learning. Patients less than 18 years old who were admitted to ICUs at four tertiary referral hospitals were enrolled. Three hospitals were designated as the derivation cohort for machine learning model development and internal validation, and the other hospital was designated as the validation cohort for external validation. We developed a random forest (RF) model that predicts pediatric mortality within 72 h of ICU admission, evaluated its performance, and compared it with the Pediatric Index of Mortality 3 (PIM 3). The area under the receiver operating characteristic curve (AUROC) of RF model was 0.942 (95% confidence interval [CI] = 0.912–0.972) in the derivation cohort and 0.906 (95% CI = 0.900–0.912) in the validation cohort. In contrast, the AUROC of PIM 3 was 0.892 (95% CI = 0.878–0.906) in the derivation cohort and 0.845 (95% CI = 0.817–0.873) in the validation cohort. The RF model in our study showed improved predictive performance in terms of both internal and external validation and was superior even when compared to PIM 3.",
        "conclusions": "The RF model in our study showed excellent performance in predicting pediatric mortality in the early stages (within 72 h) of ICU admission, which was demonstrated by both internal and external validation. Well-designed future studies are needed overcome the limitations of this study and further contribute to patient safety.",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Personalized treatment options for chronic diseases using precision cohort analytics",
        "link": "https://www.nature.com/articles/s41598-021-80967-5",
        "publication_date": "13 Jan 2021",
        "abstract": "To support point-of-care decision making by presenting outcomes of past treatment choices for cohorts of similar patients based on observational data from electronic health records (EHRs), a machine-learning precision cohort treatment option (PCTO) workflow consisting of (1) data extraction, (2) similarity model training, (3) precision cohort identification, and (4) treatment options analysis was developed. The similarity model is used to dynamically create a cohort of similar patients, to inform clinical decisions about an individual patient. The workflow was implemented using EHR data from a large health care provider for three different highly prevalent chronic diseases: hypertension (HTN), type 2 diabetes mellitus (T2DM), and hyperlipidemia (HL). A retrospective analysis demonstrated that treatment options with better outcomes were available for a majority of cases (75%, 74%, 85% for HTN, T2DM, HL, respectively). The models for HTN and T2DM were deployed in a pilot study with primary care physicians using it during clinic visits. A novel data-analytic workflow was developed to create patient-similarity models that dynamically generate personalized treatment insights at the point-of-care. By leveraging both knowledge-driven treatment guidelines and data-driven EHR data, physicians can incorporate real-world evidence in their medical decision-making process when considering treatment options for individual patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Age-group determination of living individuals using first molar images based on artificial intelligence",
        "link": "https://www.nature.com/articles/s41598-020-80182-8",
        "publication_date": "13 Jan 2021",
        "abstract": "Dental age estimation of living individuals is difficult and challenging, and there is no consensus method in adults with permanent dentition. Thus, we aimed to provide an accurate and robust artificial intelligence (AI)-based diagnostic system for age-group estimation by incorporating a convolutional neural network (CNN) using dental X-ray image patches of the first molars extracted via panoramic radiography. The data set consisted of four first molar images from the right and left sides of the maxilla and mandible of each of 1586 individuals across all age groups, which were extracted from their panoramic radiographs. The accuracy of the tooth-wise estimation was 89.05 to 90.27%. Performance accuracy was evaluated mainly using a majority voting system and area under curve (AUC) scores. The AUC scores ranged from 0.94 to 0.98 for all age groups, which indicates outstanding capacity. The learned features of CNNs were visualized as a heatmap, and revealed that CNNs focus on differentiated anatomical parameters, including tooth pulp, alveolar bone level, or interdental space, depending on the age and location of the tooth. With this, we provided a deeper understanding of the most informative regions distinguished by age groups. The prediction accuracy and heat map analyses support that this AI-based age-group determination model is plausible and useful.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of lithium response using genomic data",
        "link": "https://www.nature.com/articles/s41598-020-80814-z",
        "publication_date": "13 Jan 2021",
        "abstract": "Predicting lithium response prior to treatment could both expedite therapy and avoid exposure to side effects. Since lithium responsiveness may be heritable, its predictability based on genomic data is of interest. We thus evaluate the degree to which lithium response can be predicted with a machine learning (ML) approach using genomic data. Using the largest existing genomic dataset in the lithium response literature (n = 2210 across 14 international sites; 29% responders), we evaluated the degree to which lithium response could be predicted based on 47,465 genotyped single nucleotide polymorphisms using a supervised ML approach. Under appropriate cross-validation procedures, lithium response could be predicted to above-chance levels in two constituent sites (Halifax, Cohen’s kappa 0.15, 95% confidence interval, CI [0.07, 0.24]; and Würzburg, kappa 0.2 [0.1, 0.3]). Variants with shared importance in these models showed over-representation of postsynaptic membrane related genes. Lithium response was not predictable in the pooled dataset (kappa 0.02 [− 0.01, 0.04]), although non-trivial performance was achieved within a restricted dataset including only those patients followed prospectively (kappa 0.09 [0.04, 0.14]). Genomic classification of lithium response remains a promising but difficult task. Classification performance could potentially be improved by further harmonization of data collection procedures.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Pro-inflammatory cytokine polymorphisms and interactions with dietary alcohol and estrogen, risk factors for invasive breast cancer using a post genome-wide analysis for gene–gene and gene–lifestyle interaction",
        "link": "https://www.nature.com/articles/s41598-020-80197-1",
        "publication_date": "13 Jan 2021",
        "abstract": "Molecular and genetic immune-related pathways connected to breast cancer and lifestyles in postmenopausal women are not fully characterized. In this study, we explored the role of pro-inflammatory cytokines such as C-reactive protein (CRP) and interleukin-6 (IL-6) in those pathways at the genome-wide level. With single-nucleotide polymorphisms (SNPs) in the biomarkers and lifestyles together, we further constructed risk profiles to improve predictability for breast cancer. Our earlier genome-wide association gene-environment interaction study used large cohort data from the Women’s Health Initiative Database for Genotypes and Phenotypes Study and identified 88 SNPs associated with CRP and IL-6. For this study, we added an additional 68 SNPs from previous GWA studies, and together with 48 selected lifestyles, evaluated for the association with breast cancer risk via a 2-stage multimodal random survival forest and generalized multifactor dimensionality reduction methods. Overall and in obesity strata (by body mass index, waist, waist-to-hip ratio, exercise, and dietary fat intake), we identified the most predictive genetic and lifestyle variables. Two SNPs (SALL1 rs10521222 and HLA-DQA1 rs9271608) and lifestyles, including alcohol intake, lifetime cumulative exposure to estrogen, and overall and visceral obesity, are the most common and strongest predictive markers for breast cancer across the analyses. The risk profile that combined those variables presented their synergistic effect on the increased breast cancer risk in a gene–lifestyle dose-dependent manner. Our study may contribute to improved predictability for breast cancer and suggest potential interventions for the women with the risk genotypes and lifestyles to reduce their breast cancer risk.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "On the information hidden in a classifier distribution",
        "link": "https://www.nature.com/articles/s41598-020-79548-9",
        "publication_date": "13 Jan 2021",
        "abstract": "Classification tasks are a common challenge to every field of science. To correctly interpret the results provided by a classifier, we need to know the performance indices of the classifier including its sensitivity, specificity, the most appropriate cut-off value (for continuous classifiers), etc. Typically, several studies should be conducted to find all these indices. Herein, we show that they already exist, hidden in the distribution of the variable used to classify, and can readily be harvested. An educated guess about the distribution of the variable used to classify in each class would help us to decompose the frequency distribution of the variable in population into its components—the probability density function of the variable in each class. Based on the harvested parameters, we can then calculate the performance indices of the classifier. As a case study, we applied the technique to the relative frequency distribution of prostate-specific antigen, a biomarker commonly used in medicine for the diagnosis of prostate cancer. We used nonlinear curve fitting to decompose the variable relative frequency distribution into the probability density functions of the non-diseased and diseased people. The functions were then used to determine the performance indices of the classifier. Sensitivity, specificity, the most appropriate cut-off value, and likelihood ratios were calculated. The reference range of the biomarker and the prevalence of prostate cancer for various age groups were also calculated. The indices obtained were in good agreement with the values reported in previous studies. All these were done without being aware of the real health status of the individuals studied. The method is even applicable for conditions with no definite definitions (e.g., hypertension). We believe the method has a wide range of applications in many scientific fields.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The association of Coronavirus Disease-19 mortality and prior bacille Calmette-Guerin vaccination: a robust ecological analysis using unsupervised machine learning",
        "link": "https://www.nature.com/articles/s41598-020-80787-z",
        "publication_date": "12 Jan 2021",
        "abstract": "Population-level data have suggested that bacille Calmette-Guerin (BCG) vaccination may lessen the severity of Coronavirus Disease-19 (COVID-19) prompting clinical trials in this area. Some reports have demonstrated conflicting results. We performed a robust, ecologic analysis comparing COVID-19 related mortality (CRM) between strictly selected countries based on BCG vaccination program status utilizing publicly available databases and machine learning methods to define the association between active BCG vaccination programs and CRM. Validation was performed using linear regression and country-specific modeling. CRM was lower for the majority of countries with a BCG vaccination policy for at least the preceding 15 years (BCG15). CRM increased significantly for each increase in the percent population over age 65. A higher total population of a country and BCG15 were significantly associated with improved CRM. There was a consistent association between countries with a BCG vaccination for the preceding 15 years, but not other vaccination programs, and CRM. BCG vaccination programs continued to be associated with decreased CRM even for populations < 40 years old where CRM events are less frequent.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Evaluation of wavelength ranges and tissue depth probed by diffuse reflectance spectroscopy for colorectal cancer detection",
        "link": "https://www.nature.com/articles/s41598-020-79517-2",
        "publication_date": "12 Jan 2021",
        "abstract": "Colorectal cancer (CRC) is the third most common type of cancer worldwide and the second most deadly. Recent research efforts have focused on developing non-invasive techniques for CRC detection. In this study, we evaluated the diagnostic capabilities of diffuse reflectance spectroscopy (DRS) for CRC detection by building 6 classification models based on support vector machines (SVMs). Our dataset consists of 2889 diffuse reflectance spectra collected from freshly excised ex vivo tissues of 47 patients over wavelengths ranging from 350 and 1919 nm with source-detector distances of 630-µm and 2500-µm to probe different depths. Quadratic SVMs were used and performance was evaluated using twofold cross-validation on 10 iterations of randomized training and test sets. We achieved (93.5 ± 2.4)% sensitivity, (94.0 ± 1.7)% specificity AUC by probing the superficial colorectal tissue and (96.1 ± 1.8)% sensitivity, (95.7 ± 0.6)% specificity AUC by sampling deeper tissue layers. To the best of our knowledge, this is the first DRS study to investigate the potential of probing deeper tissue layers using larger SDD probes for CRC detection in the luminal wall. The data analysis showed that using a broader spectrum and longer near-infrared wavelengths can improve the diagnostic accuracy of CRC as well as probing deeper tissue layers.",
        "conclusions": "In this study, we evaluated the usefulness of the extended wavelength range for improving CRC detection using DRS and compared results achieved in this study with previous research. By using probing the superficial tissue, we obtained (93.5 ± 2.4)% sensitivity, (94.0 ± 1.7)% specificity and 0.971 ± 0.014 AUROC, whereas (96.1 ± 1.8)% sensitivity, (95.7 ± 0.6)% specificity and 0.987 ± 0.005 AUROC was achieved by sampling deeper tissue layers. To the best of our knowledge, this is the first DRS study to investigate the potential of probing deeper tissue layers using larger SDD probes for CRC detection in the luminal wall. Our study was conducted in ex vivo tissues, while it is straight forward to extend this methodology to an in vivo examination during endoscopy. Future studies employing diffuse reflectance spectroscopy, elastic scattering spectroscopy, near-infrared spectroscopy, hyperspectral imaging and spatial frequency domain imaging can exploit enhanced tumor detection due to the use of large SDD probes and the broadband wavelength range illustrated in this study. In a practical perspective, this study could potentially be used to develop a probe for CRC detection during colonoscopy. Real-time tissue classification is enabled by automated SVM model coupled with a DRS instrument capable of displaying the result of a single reading in about 2–3 s. By integrating this capability into a flexible fiberoptic probe which could be passed down a scope working channel, optical spectroscopy can obviate the need for multiple biopsies or polypectomies of normal mucosa as well as identify more subtle mucosal abnormalities such as sessile serrated polyps for example, which may be difficult to recognize during colonoscopy.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Anti-senescent drug screening by deep learning-based morphology senescence scoring",
        "link": "https://www.nature.com/articles/s41467-020-20213-0",
        "publication_date": "11 Jan 2021",
        "abstract": "Advances in deep learning technology have enabled complex task solutions. The accuracy of image classification tasks has improved owing to the establishment of convolutional neural networks (CNN). Cellular senescence is a hallmark of ageing and is important for the pathogenesis of ageing-related diseases. Furthermore, it is a potential therapeutic target. Specific molecular markers are used to identify senescent cells. Moreover senescent cells show unique morphology, which can be identified. We develop a successful morphology-based CNN system to identify senescent cells and a quantitative scoring system to evaluate the state of endothelial cells by senescence probability output from pre-trained CNN optimised for the classification of cellular senescence, Deep Learning-Based Senescence Scoring System by Morphology (Deep-SeSMo). Deep-SeSMo correctly evaluates the effects of well-known anti-senescent reagents. We screen for drugs that control cellular senescence using a kinase inhibitor library by Deep-SeSMo-based drug screening and identify four anti-senescent drugs. RNA sequence analysis reveals that these compounds commonly suppress senescent phenotypes through inhibition of the inflammatory response pathway. Thus, morphology-based CNN system can be a powerful tool for anti-senescent drug screening.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Auditory cues reveal intended movement information in middle frontal gyrus neuronal ensemble activity of a person with tetraplegia",
        "link": "https://www.nature.com/articles/s41598-020-77616-8",
        "publication_date": "11 Jan 2021",
        "abstract": "Intracortical brain-computer interfaces (iBCIs) allow people with paralysis to directly control assistive devices using neural activity associated with the intent to move. Realizing the full potential of iBCIs critically depends on continued progress in understanding how different cortical areas contribute to movement control. Here we present the first comparison between neuronal ensemble recordings from the left middle frontal gyrus (MFG) and precentral gyrus (PCG) of a person with tetraplegia using an iBCI. As expected, PCG was more engaged in selecting and generating intended movements than in earlier perceptual stages of action planning. By contrast, MFG displayed movement-related information during the sensorimotor processing steps preceding the appearance of the action plan in PCG, but only when the actions were instructed using auditory cues. These results describe a previously unreported function for neurons in the human left MFG in auditory processing contributing to motor control.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Sleep classification from wrist-worn accelerometer data using random forests",
        "link": "https://www.nature.com/articles/s41598-020-79217-x",
        "publication_date": "08 Jan 2021",
        "abstract": "Accurate and low-cost sleep measurement tools are needed in both clinical and epidemiological research. To this end, wearable accelerometers are widely used as they are both low in price and provide reasonably accurate estimates of movement. Techniques to classify sleep from the high-resolution accelerometer data primarily rely on heuristic algorithms. In this paper, we explore the potential of detecting sleep using Random forests. Models were trained using data from three different studies where 134 adult participants (70 with sleep disorder and 64 good healthy sleepers) wore an accelerometer on their wrist during a one-night polysomnography recording in the clinic. The Random forests were able to distinguish sleep-wake states with an F1 score of 73.93% on a previously unseen test set of 24 participants. Detecting when the accelerometer is not worn was also successful using machine learning (\\(\\hbox {F1-score} > 93.31\\%\\)), and when combined with our sleep detection models on day-time data provide a sleep estimate that is correlated with self-reported habitual nap behaviour (\\(\\hbox {r}=.60\\)). These Random forest models have been made open-source to aid further research. In line with literature, sleep stage classification turned out to be difficult using only accelerometer data.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development and validation of an interpretable neural network for prediction of postoperative in-hospital mortality",
        "link": "https://www.nature.com/articles/s41746-020-00377-1",
        "publication_date": "08 Jan 2021",
        "abstract": "While deep neural networks (DNNs) and other machine learning models often have higher accuracy than simpler models like logistic regression (LR), they are often considered to be “black box” models and this lack of interpretability and transparency is considered a challenge for clinical adoption. In healthcare, intelligible models not only help clinicians to understand the problem and create more targeted action plans, but also help to gain the clinicians’ trust. One method of overcoming the limited interpretability of more complex models is to use Generalized Additive Models (GAMs). Standard GAMs simply model the target response as a sum of univariate models. Inspired by GAMs, the same idea can be applied to neural networks through an architecture referred to as Generalized Additive Models with Neural Networks (GAM-NNs). In this manuscript, we present the development and validation of a model applying the concept of GAM-NNs to allow for interpretability by visualizing the learned feature patterns related to risk of in-hospital mortality for patients undergoing surgery under general anesthesia. The data consists of 59,985 patients with a feature set of 46 features extracted at the end of surgery to which we added previously not included features: total anesthesia case time (1 feature); the time in minutes spent with mean arterial pressure (MAP) below 40, 45, 50, 55, 60, and 65 mmHg during surgery (6 features); and Healthcare Cost and Utilization Project (HCUP) Code Descriptions of the Primary current procedure terminology (CPT) codes (33 features) for a total of 86 features. All data were randomly split into 80% for training (n = 47,988) and 20% for testing (n = 11,997) prior to model development. Model performance was compared to a standard LR model using the same features as the GAM-NN. The data consisted of 59,985 surgical records, and the occurrence of in-hospital mortality was 0.81% in the training set and 0.72% in the testing set. The GAM-NN model with HCUP features had the highest area under the curve (AUC) 0.921 (0.895–0.95). Overall, both GAM-NN models had higher AUCs than LR models, however, had lower average precisions. The LR model without HCUP features had the highest average precision 0.217 (0.136–0.31). To assess the interpretability of the GAM-NNs, we then visualized the learned contributions of the GAM-NNs and compared against the learned contributions of the LRs for the models with HCUP features. Overall, we were able to demonstrate that our proposed generalized additive neural network (GAM-NN) architecture is able to (1) leverage a neural network’s ability to learn nonlinear patterns in the data, which is more clinically intuitive, (2) be interpreted easily, making it more clinically useful, and (3) maintain model performance as compared to previously published DNNs.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Additional SNPs improve risk stratification of a polygenic hazard score for prostate cancer",
        "link": "https://www.nature.com/articles/s41391-020-00311-2",
        "publication_date": "08 Jan 2021",
        "abstract": "Polygenic hazard scores (PHS) can identify individuals with increased risk of prostate cancer. We estimated the benefit of additional SNPs on performance of a previously validated PHS (PHS46).",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A novel simple risk model to predict the prognosis of patients with paraquat poisoning",
        "link": "https://www.nature.com/articles/s41598-020-80371-5",
        "publication_date": "08 Jan 2021",
        "abstract": "To identify risk factors and develop a simple model to predict early prognosis of acute paraquat (PQ) poisoning patients, we performed a retrospective cohort study of acute PQ poisoning patients (n = 1199). Patients (n = 913) with PQ poisoning from 2011 to 2018 were randomly divided into training (n = 609) and test (n = 304) samples. Another two independent cohorts were used as validation samples for a different time (n = 207) and site (n = 79). Risk factors were identified using a logistic model with Markov Chain Monte Carlo (MCMC) simulation and further evaluated using a latent class analysis. The prediction score was developed based on the training sample and was evaluated using the testing and validation samples. Eight factors, including age, ingestion volume, creatine kinase-MB [CK-MB], platelet [PLT], white blood cell [WBC], neutrophil counts [N], gamma-glutamyl transferase [GGT], and serum creatinine [Cr] were identified as independent risk indicators of in-hospital death events. The risk model had C statistics of 0.895 (95% CI 0.855–0.928), 0.891 (95% CI 0.848–0.932), and 0.829 (95% CI 0.455–1.000), and predictive ranges of 4.6–98.2%, 2.3–94.9%, and 0–12.5% for the test, validation_time, and validation_site samples, respectively. In the training sample, the risk model classified 18.4%, 59.9%, and 21.7% of patients into the high-, average-, and low-risk groups, with corresponding probabilities of 0.985, 0.365, and 0.03 for in-hospital death events. We developed and evaluated a simple risk model to predict the prognosis of patients with acute PQ poisoning. This risk scoring system could be helpful for identifying high-risk patients and reducing mortality due to PQ poisoning.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [
                "poisoning"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Gene expression profiling-based risk prediction and profiles of immune infiltration in diffuse large B-cell lymphoma",
        "link": "https://www.nature.com/articles/s41408-020-00404-0",
        "publication_date": "07 Jan 2021",
        "abstract": "The clinical risk stratification of diffuse large B-cell lymphoma (DLBCL) relies on the International Prognostic Index (IPI) for the identification of high-risk disease. Recent studies suggest that the immune microenvironment plays a role in treatment response prediction and survival in DLBCL. This study developed a risk prediction model and evaluated the model’s biological implications in association with the estimated profiles of immune infiltration. Gene-expression profiling of 718 patients with DLBCL was done, for which RNA sequencing data and clinical covariates were obtained from Reddy et al. (2017). Using unsupervised and supervised machine learning methods to identify survival-associated gene signatures, a multivariable model of survival was constructed. Tumor-infiltrating immune cell compositions were enumerated using CIBERSORT deconvolution analysis. A four gene-signature-based score was developed that separated patients into high- and low-risk groups. The combination of the gene-expression-based score with the IPI improved the discrimination on the validation and complete sets. The gene signatures were successfully validated with the deconvolution output. Correlating the deconvolution findings with the gene signatures and risk score, CD8+ T-cells and naïve CD4+ T-cells were associated with favorable prognosis. By analyzing the gene-expression data with a systematic approach, a risk prediction model that outperforms the existing risk assessment methods was developed and validated.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [
                "evasion"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "‘CTRL’: an online, Dynamic Consent and participant engagement platform working towards solving the complexities of consent in genomic research",
        "link": "https://www.nature.com/articles/s41431-020-00782-w",
        "publication_date": "06 Jan 2021",
        "abstract": "The complexities of the informed consent process for participating in research in genomic medicine are well-documented. Inspired by the potential for Dynamic Consent to increase participant choice and autonomy in decision-making, as well as the opportunities for ongoing participant engagement it affords, we wanted to trial Dynamic Consent and to do so developed our own web-based application (web app) called CTRL (control). This paper documents the design and development of CTRL, for use in the Australian Genomics study: a health services research project building evidence to inform the integration of genomic medicine into mainstream healthcare. Australian Genomics brought together a multi-disciplinary team to develop CTRL. The design and development process considered user experience; security and privacy; the application of international standards in data sharing; IT, operational and ethical issues. The CTRL tool is now being offered to participants in the study, who can use CTRL to keep personal and contact details up to date; make consent choices (including indicate preferences for return of results and future research use of biological samples, genomic and health data); follow their progress through the study; complete surveys, contact the researchers and access study news and information. While there are remaining challenges to implementing Dynamic Consent in genomic research, this study demonstrates the feasibility of building such a tool, and its ongoing use will provide evidence about the value of Dynamic Consent in large-scale genomic research programs.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning-based prediction of COVID-19 diagnosis based on symptoms",
        "link": "https://www.nature.com/articles/s41746-020-00372-6",
        "publication_date": "04 Jan 2021",
        "abstract": "Effective screening of SARS-CoV-2 enables quick and efficient diagnosis of COVID-19 and can mitigate the burden on healthcare systems. Prediction models that combine several features to estimate the risk of infection have been developed. These aim to assist medical staff worldwide in triaging patients, especially in the context of limited healthcare resources. We established a machine-learning approach that trained on records from 51,831 tested individuals (of whom 4769 were confirmed to have COVID-19). The test set contained data from the subsequent week (47,401 tested individuals of whom 3624 were confirmed to have COVID-19). Our model predicted COVID-19 test results with high accuracy using only eight binary features: sex, age ≥60 years, known contact with an infected individual, and the appearance of five initial clinical symptoms. Overall, based on the nationwide data publicly reported by the Israeli Ministry of Health, we developed a model that detects COVID-19 cases by simple features accessed by asking basic questions. Our framework can be used, among other considerations, to prioritize testing for COVID-19 when testing resources are limited.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A deep learning framework for drug repurposing via emulating clinical trials on real-world patient data",
        "link": "https://www.nature.com/articles/s42256-020-00276-w",
        "publication_date": "04 Jan 2021",
        "abstract": "Drug repurposing is an effective strategy to identify new uses for existing drugs, providing the quickest possible transition from bench to bedside. Real-world data, such as electronic health records and insurance claims, provide information on large cohorts of users for many drugs. Here we present an efficient and easily customized framework for generating and testing multiple candidates for drug repurposing using a retrospective analysis of real-world data. Building upon well-established causal inference and deep learning methods, our framework emulates randomized clinical trials for drugs present in a large-scale medical claims database. We demonstrate our framework on a coronary artery disease cohort of millions of patients. We successfully identify drugs and drug combinations that substantially improve the coronary artery disease outcomes but haven’t been indicated for treating coronary artery disease, paving the way for drug repurposing.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [
                "backdoor"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Distinct trajectories of response to prefrontal tDCS in major depression: results from a 3-arm randomized controlled trial",
        "link": "https://www.nature.com/articles/s41386-020-00935-x",
        "publication_date": "21 Dec 2020",
        "abstract": "Transcranial direct current stimulation (tDCS) is a safe, effective treatment for major depressive disorder (MDD). While antidepressant effects are heterogeneous, no studies have investigated trajectories of tDCS response. We characterized distinct improvement trajectories and associated baseline characteristics for patients treated with prefrontal tDCS, an active pharmacotherapy (escitalopram), and placebo. This is a secondary analysis of a randomized, non-inferiority, double-blinded trial (ELECT-TDCS, N = 245). Participants were diagnosed with an acute unipolar, nonpsychotic, depressive episode, and presented Hamilton Depression Rating Scale (17-items, HAM-D) scores ≥17. Latent trajectory modeling was used to identify HAM-D response trajectories over a 10-week treatment. Top-down (hypothesis-driven) and bottom-up (data-driven) methods were employed to explore potential predictive features using, respectively, conservatively corrected regression models and a cross-validated stability ranking procedure combined with elastic net regularization. Three trajectory classes that were distinct in response speed and intensity (rapid, slow, and no/minimal improvement) were identified for escitalopram, tDCS, and placebo. Differences in response and remission rates were significant early for all groups. Depression severity, use of benzodiazepines, and age were associated with no/minimal improvement. No significant differences in trajectory assignment were found in tDCS vs. placebo comparisons (38.3, 34, and 27.6%; vs. 23.3, 43.3, and 33.3% for rapid, slow, and no/minimal trajectories, respectively). Additional features are suggested in bottom-up analyses. Summarily, groups treated with tDCS, escitalopram, and placebo differed in trajectory class distributions and baseline predictors of response. Our results might be relevant for designing further studies.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Dynamic survival prediction in intensive care units from heterogeneous time series without the need for variable selection or curation",
        "link": "https://www.nature.com/articles/s41598-020-79142-z",
        "publication_date": "17 Dec 2020",
        "abstract": "Extensive monitoring in intensive care units (ICUs) generates large quantities of data which contain numerous trends that are difficult for clinicians to systematically evaluate. Current approaches to such heterogeneity in electronic health records (EHRs) discard pertinent information. We present a deep learning pipeline that uses all uncurated chart, lab, and output events for prediction of in-hospital mortality without variable selection. Over 21,000 ICU patients and tens of thousands of variables derived from the MIMIC-III database were used to train and validate our model. Recordings in the first few hours of a patient’s stay were found to be strongly predictive of mortality, outperforming models using SAPS II and OASIS scores, AUROC 0.72 and 0.76 at 24 h respectively, within just 12 h of ICU admission. Our model achieves a very strong predictive performance of AUROC 0.85 (95% CI 0.83–0.86) after 48 h. Predictive performance increases over the first 48 h, but suffers from diminishing returns, providing rationale for time-limited trials of critical care and suggesting that the timing of decision making can be optimised and individualised.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Impact of data on generalization of AI for surgical intelligence applications",
        "link": "https://www.nature.com/articles/s41598-020-79173-6",
        "publication_date": "17 Dec 2020",
        "abstract": "AI is becoming ubiquitous, revolutionizing many aspects of our lives. In surgery, it is still a promise. AI has the potential to improve surgeon performance and impact patient care, from post-operative debrief to real-time decision support. But, how much data is needed by an AI-based system to learn surgical context with high fidelity? To answer this question, we leveraged a large-scale, diverse, cholecystectomy video dataset. We assessed surgical workflow recognition and report a deep learning system, that not only detects surgical phases, but does so with high accuracy and is able to generalize to new settings and unseen medical centers. Our findings provide a solid foundation for translating AI applications from research to practice, ushering in a new era of surgical intelligence.",
        "conclusions": "In this work, we follow previously suggested guidelines for ML to overcome “barriers to deployment” and have an actual impact on healthcare34. Our study aims to support the transition from bench to bedside and help translate research into tools that aid surgeons, practically, in their daily routine. The viewpoint by Wang et al.35 discusses the challenges of integrating deep learning applications into the clinician’s workflow. Challenges such as data quantity and quality and model generalizability are addressed in this study. Since our dataset is more than an order of magnitude larger than any previous study it provides in-depth knowledge of surgical workflow characteristics. In addition, as ML systems are often considered as a “black-box”, we train our approach based on predefined phase mapping, agreed to by a group of experts in the field. This ensures that healthcare professionals understand and can interpret the results.In summary, the contributions of this work are threefold. First, we leverage a large and diverse surgical video dataset and apply state-of-the-art methods for video analysis to introduce a deep learning system that achieves more than 90% accuracy in detecting the correct surgical phase. In order to support future research in this field, we report the set of hyperparameters learned and optimized with our dataset, allowing to train models on smaller but publicly available datasets. Second, we report a comprehensive analysis, assessing the likely asymptotic performance of our phase detection system and evaluating the generalization of our approach to different medical centers and a diverse surgeon population. Third, given a set of unseen videos from a new medical center, we demonstrate that by fine-tuning on a relatively small number of new samples, our model can converge to a similar high performance.Examining the number of videos needed in order to learn the surgical workflow shows high return in performance when going from tens to hundreds of training videos, where a diminishing effect in accuracy is starting to appear. We do note that our performance assessment was done using a fixed model capacity. Increasing the available data to thousands or even tens of thousands of videos may offer additional improvements by also increasing the model capacity.As opposed to elite athletes who can review performance and analyze every roll, pitch and yaw post-competition, surgeons lack objective tools to routinely debrief and analyze performance. The current level of accuracy allows for the creation of surgical highlight reels that can be returned to a surgeon quickly after exiting the operating room. Higher levels of accuracy will be required in order to leverage such capabilities for real-time decision support.The results in this report are limited to one specific surgical procedure, laparoscopic cholecystectomy, which has a relatively linear phase progression. Further analysis is needed in order to ensure the transferability of the ideas presented here to less structured or lengthy procedures. In addition, both modules do not assume any causality constraints and design to operate offline on the entire surgical video. However, enforcing such constraints can easily be done by adjusting the models to “look” at past inputs only. The evaluation of such models is not within the scope of this work. Although procedures from MC1 were curated over decades and capture high surgical variability, the dataset is still skewed towards this single center. Our generalization exploration focuses on high-level biases, which might occur due to different medical centers, surgeons and techniques. Once sufficiently labeled, future exploration should be done to assess both patient-level bias factors such as age, BMI, ethnicity, sex, anatomy variance, etc. and medical-center-level bias, e.g. by grouping procedures based on visualization hardware, instruments, or on the period or date of performing the surgery. Our models are also limited in handling outliers, such as very low video quality or in case a new surgical tool, never seen before, is used.The hyperparameters described for the short- and long-term approach enable training robust models on relatively small, but publicly available, datasets such as Cholec8011 and EndoTube36. The ability to detect surgical phases with high accuracy can promote the development of other surgical applications and support continuous research in this field. In addition, robust phase detection models can be the catalyst for studies of intraoperative event detection or applying transfer learning on other types of laparoscopic procedures.There are many opportunities for ML-based AI in the operating room10. Regardless of the use case, a foundational step in integrating AI systems into routine surgeon workflow is the ability to analyze and successfully discern between different surgical phases. Thus, surgical phase detection is a key benchmark problem to assess the ability of AI to successfully learn surgical context.We believe our analysis can further accelerate computer vision-based research and applications for laparoscopic surgery to the point of integrating AI systems in the surgical workflow routine, assisting in the decision-making processes and ultimately improving surgeon experience and patient care.",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Differential diagnosis of vergence and saccade disorders in dyslexia",
        "link": "https://www.nature.com/articles/s41598-020-79089-1",
        "publication_date": "17 Dec 2020",
        "abstract": "Previous studies suggest vergence and saccade abnormalities in dyslexic adolescents. However, these studies are mainly clinically based and do not provide objective measurements of eye movements, but rather subjectively evaluate vergence using haplosopic conditions in which the two eyes are dissociated (via polarizers, prisms, or intermittent spectacles). Other studies have identified deficits with binocular coordination during reading in dyslexics. Yet, there are few studies that provide objective measurements of eye movements in the dyslexic population to help provide more information regarding if these deficits could be due to an intrinsic motor problem or if they are the consequence of poor reading. 47 dyslexic adolescents (18 female, 29 male; mean age 15.5) and 44 non-dyslexic adolescents (22 female, 22 male; mean age 14.8) wore a head-based eye tracker (PupilCore, Pupil Labs, Berlin) which recorded wide angle saccade and vergence eye movements at 200 Hz. Tests were run using the REMOBI device, which produced a saccade or vergence audiovisual target. Analysis of eye movements was performed with lab-developed software, AIDEAL. The results showed statistically significant abnormalities in vergence and saccades. In vergence, dyslexics displayed a reduced amplitude of the visually driven portion of convergence and a longer duration in the initial phase of divergence. In saccades, dyslexic adolescents demonstrated slower saccades in both directions. They also had an increased disconjugate drift in the first 80 or 160 ms following saccades to the right, suggesting poor binocular coordination. For both vergence and saccades, the peak velocity and time to peak velocity was higher and earlier, respectively, in non-dyslexics compared to dyslexics; yet the average velocity of both movements was lower in dyslexics. Thus, these results indicate peculiar velocity profiles in dyslexics, particularly a slow deceleration phase in both vergence and saccades. The study provides an objective method to diagnose vergence and saccade abnormalities while viewing targets in the real three-dimensional space in a dyslexic population. Vergence abnormalities are demonstrated to be a problem in dyslexics, occurring independently from reading. We hypothesize these disconjugate drifts following saccades are the result of slow vergence capacity. Rehabilitation programs, such as those using REMOBI, should aim to target these deficits in vergence velocity, as this has been shown to improve binocular control.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A flexible computational pipeline for research analyses of unsolved clinical exome cases",
        "link": "https://www.nature.com/articles/s41525-020-00161-w",
        "publication_date": "10 Dec 2020",
        "abstract": "Exome sequencing has enabled molecular diagnoses for rare disease patients but often with initial diagnostic rates of ~25−30%. Here we develop a robust computational pipeline to rank variants for reassessment of unsolved rare disease patients. A comprehensive web-based patient report is generated in which all deleterious variants can be filtered by gene, variant characteristics, OMIM disease and Phenolyzer scores, and all are annotated with an ACMG classification and links to ClinVar. The pipeline ranked 21/34 previously diagnosed variants as top, with 26 in total ranked ≤7th, 3 ranked ≥13th; 5 failed the pipeline filters. Pathogenic/likely pathogenic variants by ACMG criteria were identified for 22/145 unsolved cases, and a previously undefined candidate disease variant for 27/145. This open access pipeline supports the partnership between clinical and research laboratories to improve the diagnosis of unsolved exomes. It provides a flexible framework for iterative developments to further improve diagnosis.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Dysgraphia detection through machine learning",
        "link": "https://www.nature.com/articles/s41598-020-78611-9",
        "publication_date": "09 Dec 2020",
        "abstract": "Dysgraphia, a disorder affecting the written expression of symbols and words, negatively impacts the academic results of pupils as well as their overall well-being. The use of automated procedures can make dysgraphia testing available to larger populations, thereby facilitating early intervention for those who need it. In this paper, we employed a machine learning approach to identify handwriting deteriorated by dysgraphia. To achieve this goal, we collected a new handwriting dataset consisting of several handwriting tasks and extracted a broad range of features to capture different aspects of handwriting. These were fed to a machine learning algorithm to predict whether handwriting is affected by dysgraphia. We compared several machine learning algorithms and discovered that the best results were achieved by the adaptive boosting (AdaBoost) algorithm. The results show that machine learning can be used to detect dysgraphia with almost 80% accuracy, even when dealing with a heterogeneous set of subjects differing in age, sex and handedness.",
        "conclusions": "Our study provides new data, a new orthography and an algorithm not previously used for dysgraphia recognition. We introduced several new features that have not previously been used to evaluate handwriting and dysgraphia. These features proved relevant for diagnosis and, moreover, offer a high level of interpretability. Features such as maximum segment vertical length, minimum segment height, and difference between maximum y-positions of the second and penultimate segments can be directly related to changes in handwriting due to dysgraphia. In conclusion, the proposed approach was able to recognize dysgraphic handwriting with almost 80% accuracy; however, the dataset includes subjects aged 8–15 years. This is a relatively wide age range, especially for handwriting, since handwriting is still developing and changing during these years. This makes classification tasks more challenging than in more focused datasets.The proposed model can be employed as part of a decision support system to assist professionals in occupational therapy to provide more objective diagnosis. Some commercially available conventional tablets now offer the possibility of capturing handwriting, which would allow a whole decision support system to be implemented on a tablet device at relatively low cost, thus opening possibilities for extensive screening of children for dysgraphia in schools.The limitations of our study lie in the fact that we used only Slovak orthography and tested children in a relatively broad age range with fewer cases in separate age groups, so we could not pinpoint differences between children of different ages. Additional studies are necessary to identify whether the features proposed by us and others9,18 are valid for other orthographies and other age cohorts.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Vital signs assessed in initial clinical encounters predict COVID-19 mortality in an NYC hospital system",
        "link": "https://www.nature.com/articles/s41598-020-78392-1",
        "publication_date": "09 Dec 2020",
        "abstract": "Timely and effective clinical decision-making for COVID-19 requires rapid identification of risk factors for disease outcomes. Our objective was to identify characteristics available immediately upon first clinical evaluation related COVID-19 mortality. We conducted a retrospective study of 8770 laboratory-confirmed cases of SARS-CoV-2 from a network of 53 facilities in New-York City. We analysed 3 classes of variables; demographic, clinical, and comorbid factors, in a two-tiered analysis that included traditional regression strategies and machine learning. COVID-19 mortality was 12.7%. Logistic regression identified older age (OR, 1.69 [95% CI 1.66–1.92]), male sex (OR, 1.57 [95% CI 1.30–1.90]), higher BMI (OR, 1.03 [95% CI 1.102–1.05]), higher heart rate (OR, 1.01 [95% CI 1.00–1.01]), higher respiratory rate (OR, 1.05 [95% CI 1.03–1.07]), lower oxygen saturation (OR, 0.94 [95% CI 0.93–0.96]), and chronic kidney disease (OR, 1.53 [95% CI 1.20–1.95]) were associated with COVID-19 mortality. Using gradient-boosting machine learning, these factors predicted COVID-19 related mortality (AUC = 0.86) following cross-validation in a training set. Immediate, objective and culturally generalizable measures accessible upon clinical presentation are effective predictors of COVID-19 outcome. These findings may inform rapid response strategies to optimize health care delivery in parts of the world who have not yet confronted this epidemic, as well as in those forecasting a possible second outbreak.",
        "conclusions": "In this retrospective observational study focusing on demographic and clinical characteristics of confirmed COVID-19 patients in a large NYC hospital system, older age, being a male, higher BMI, presenting vitals of higher heart rate, higher respiratory rate and lower O2 saturation as well as having CKD, were identified as risk factors for COVID-19 mortality. We found that these factors could be combined in a gradient-boosting machine learning model to create an effective predictor of mortality with an AUC of 0.86. Notably, our results show that immediate, objective measures collected at the time of clinical presentation, independently of patient level of consciousness, can be effective predictors of mortality. Reliance on results from hematologic and biochemical laboratory tests or extensive medical history review may create a critical lag in response time. These findings may inform rapid response strategies to optimize health care delivery in parts of the world who have yet confronted this epidemic, as well as in those forecasting a possible second outbreak.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    }
]