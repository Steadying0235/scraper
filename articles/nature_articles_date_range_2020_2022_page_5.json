[
    {
        "title": "Prediction algorithm for ICU mortality and length of stay using machine learning",
        "link": "https://www.nature.com/articles/s41598-022-17091-5",
        "publication_date": "28 Jul 2022",
        "abstract": "Machine learning can predict outcomes and determine variables contributing to precise prediction, and can thus classify patients with different risk factors of outcomes. This study aimed to investigate the predictive accuracy for mortality and length of stay in intensive care unit (ICU) patients using machine learning, and to identify the variables contributing to the precise prediction or classification of patients. Patients (n = 12,747) admitted to the ICU at Chiba University Hospital were randomly assigned to the training and test cohorts. After learning using the variables on admission in the training cohort, the area under the curve (AUC) was analyzed in the test cohort to evaluate the predictive accuracy of the supervised machine learning classifiers, including random forest (RF) for outcomes (primary outcome, mortality; secondary outcome, length of ICU stay). The rank of the variables that contributed to the machine learning prediction was confirmed, and cluster analysis of the patients with risk factors of mortality was performed to identify the important variables associated with patient outcomes. Machine learning using RF revealed a high predictive value for mortality, with an AUC of 0.945 (95% confidence interval [CI] 0.922–0.977). In addition, RF showed high predictive value for short and long ICU stays, with AUCs of 0.881 (95% CI 0.876–0.908) and 0.889 (95% CI 0.849–0.936), respectively. Lactate dehydrogenase (LDH) was identified as a variable contributing to the precise prediction in machine learning for both mortality and length of ICU stay. LDH was also identified as a contributing variable to classify patients into sub-populations based on different risk factors of mortality. The machine learning algorithm could predict mortality and length of stay in ICU patients with high accuracy. LDH was identified as a contributing variable in mortality and length of ICU stay prediction and could be used to classify patients based on mortality risk.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Construction of a new automatic grading system for jaw bone mineral density level based on deep learning using cone beam computed tomography",
        "link": "https://www.nature.com/articles/s41598-022-16074-w",
        "publication_date": "27 Jul 2022",
        "abstract": "To develop and verify an automatic classification method using artificial intelligence deep learning to determine the bone mineral density level of the implant site in oral implant surgery from radiographic data obtained from cone beam computed tomography (CBCT) images. Seventy patients with mandibular dentition defects were scanned using CBCT. These Digital Imaging and Communications in Medicine data were cut into 605 training sets, and then the data were processed with data standardization, and the Hounsfiled Unit (HU) value level was determined as follows: Type 1, 1000–2000; type 2, 700–1000; type 3, 400–700; type 4, 100–400; and type 5, − 200–100. Four trained dental implant physicians manually identified and classified the area of the jaw bone density level in the image using the software LabelMe. Then, with the assistance of the HU value generated by LabelMe, a physician with 20 years of clinical experience confirmed the labeling level. Finally, the HU mean values of various categories marked by dental implant physicians were compared to the mean values detected by the artificial intelligence model to assess the accuracy of artificial intelligence classification. After the model was trained on 605 training sets, the statistical results of the HU mean values of various categories in the dataset detected by the model were almost the same as the HU grading interval on the data annotation. This new classification provides a more detailed solution to guide surgeons to adjust the drilling rate and tool selection during preoperative decision-making and intraoperative hole preparation for oral implant surgery.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Automatic scoring of COVID-19 severity in X-ray imaging based on a novel deep learning workflow",
        "link": "https://www.nature.com/articles/s41598-022-15013-z",
        "publication_date": "27 Jul 2022",
        "abstract": "In this study, we propose a two-stage workflow used for the segmentation and scoring of lung diseases. The workflow inherits quantification, qualification, and visual assessment of lung diseases on X-ray images estimated by radiologists and clinicians. It requires the fulfillment of two core stages devoted to lung and disease segmentation as well as an additional post-processing stage devoted to scoring. The latter integrated block is utilized, mainly, for the estimation of segment scores and computes the overall severity score of a patient. The models of the proposed workflow were trained and tested on four publicly available X-ray datasets of COVID-19 patients and two X-ray datasets of patients with no pulmonary pathology. Based on a combined dataset consisting of 580 COVID-19 patients and 784 patients with no disorders, our best-performing algorithm is based on a combination of DeepLabV3 + , for lung segmentation, and MA-Net, for disease segmentation. The proposed algorithms’ mean absolute error (MAE) of 0.30 is significantly reduced in comparison to established COVID-19 algorithms; BS-net and COVID-Net-S, possessing MAEs of 2.52 and 1.83 respectively. Moreover, the proposed two-stage workflow was not only more accurate but also computationally efficient, it was approximately 11 times faster than the mentioned methods. In summary, we proposed an accurate, time-efficient, and versatile approach for segmentation and scoring of lung diseases illustrated for COVID-19 and with broader future applications for pneumonia, tuberculosis, pneumothorax, amongst others.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Identification of robust deep neural network models of longitudinal clinical measurements",
        "link": "https://www.nature.com/articles/s41746-022-00651-4",
        "publication_date": "27 Jul 2022",
        "abstract": "Deep learning (DL) from electronic health records holds promise for disease prediction, but systematic methods for learning from simulated longitudinal clinical measurements have yet to be reported. We compared nine DL frameworks using simulated body mass index (BMI), glucose, and systolic blood pressure trajectories, independently isolated shape and magnitude changes, and evaluated model performance across various parameters (e.g., irregularity, missingness). Overall, discrimination based on variation in shape was more challenging than magnitude. Time-series forest-convolutional neural networks (TSF-CNN) and Gramian angular field(GAF)-CNN outperformed other approaches (P < 0.05) with overall area-under-the-curve (AUCs) of 0.93 for both models, and 0.92 and 0.89 for variation in magnitude and shape with up to 50% missing data. Furthermore, in a real-world assessment, the TSF-CNN model predicted T2D with AUCs reaching 0.72 using only BMI trajectories. In conclusion, we performed an extensive evaluation of DL approaches and identified robust modeling frameworks for disease prediction based on longitudinal clinical measurements.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Diffuse correlation spectroscopy blood flow monitoring for intraventricular hemorrhage vulnerability in extremely low gestational age newborns",
        "link": "https://www.nature.com/articles/s41598-022-16499-3",
        "publication_date": "27 Jul 2022",
        "abstract": "In premature infants with an extremely low gestational age (ELGA, < 29 weeks GA), dysregulated changes in cerebral blood flow (CBF) are among the major pathogenic factors leading to germinal matrix/intraventricular hemorrhage (GM/IVH). Continuous monitoring of CBF can guide interventions to minimize the risk of brain injury, but there are no clinically standard techniques or tools for its measurement. We report the feasibility of the continuous monitoring of CBF, including measures of autoregulation, via diffuse correlation spectroscopy (DCS) in ELGA infants using CBF variability and correlation with scalp blood flow (SBF, served as a surrogate measure of systemic perturbations). In nineteen ELGA infants (with 9 cases of GM/IVH) monitored for 6–24 h between days 2–5 of life, we found a strong correlation between CBF and SBF in severe IVH (Grade III or IV) and IVH diagnosed within 72 h of life, while CBF variability alone was not associated with IVH. The proposed method is potentially useful at the bedside for the prompt assessment of cerebral autoregulation and early identification of infants vulnerable to GM/IVH.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Applying machine learning and predictive modeling to retention and viral suppression in South African HIV treatment cohorts",
        "link": "https://www.nature.com/articles/s41598-022-16062-0",
        "publication_date": "26 Jul 2022",
        "abstract": "HIV treatment programs face challenges in identifying patients at risk for loss-to-follow-up and uncontrolled viremia. We applied predictive machine learning algorithms to anonymised, patient-level HIV programmatic data from two districts in South Africa, 2016–2018. We developed patient risk scores for two outcomes: (1) visit attendance ≤ 28 days of the next scheduled clinic visit and (2) suppression of the next HIV viral load (VL). Demographic, clinical, behavioral and laboratory data were investigated in multiple models as predictor variables of attending the next scheduled visit and VL results at the next test. Three classification algorithms (logistical regression, random forest and AdaBoost) were evaluated for building predictive models. Data were randomly sampled on a 70/30 split into a training and test set. The training set included a balanced set of positive and negative examples from which the classification algorithm could learn. The predictor variable data from the unseen test set were given to the model, and each predicted outcome was scored against known outcomes. Finally, we estimated performance metrics for each model in terms of sensitivity, specificity, positive and negative predictive value and area under the curve (AUC). In total, 445,636 patients were included in the retention model and 363,977 in the VL model. The predictive metric (AUC) ranged from 0.69 for attendance at the next scheduled visit to 0.76 for VL suppression, suggesting that the model correctly classified whether a scheduled visit would be attended in 2 of 3 patients and whether the VL result at the next test would be suppressed in approximately 3 of 4 patients. Variables that were important predictors of both outcomes included prior late visits, number of prior VL tests, time since their last visit, number of visits on their current regimen, age, and treatment duration. For retention, the number of visits at the current facility and the details of the next appointment date were also predictors, while for VL suppression, other predictors included the range of the previous VL value. Machine learning can identify HIV patients at risk for disengagement and unsuppressed VL. Predictive modeling can improve the targeting of interventions through differentiated models of care before patients disengage from treatment programmes, increasing cost-effectiveness and improving patient outcomes.",
        "conclusions": "Predictive models and machine learning can identify and target HIV patients at risk for disengaging from care and not being virally suppressed. Our approach could enable anticipation of future outcomes before any visible signs and/or poor outcomes occur (e.g., an unsuppressed VL) and, most importantly, while the patient is still engaged in care. This affords the opportunity to take a proactive approach to patient management—specific targeted interventions can be designed on identified subsets of the treatment cohorts, allowing for cost-effective differentiated models on care and treatment to be applied across the cascade. This approach could also be extended to other key HIV outcomes, allowing for the use of a cost-effective and precision programming approach.",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning for real-time aggregated prediction of hospital admission for emergency patients",
        "link": "https://www.nature.com/articles/s41746-022-00649-y",
        "publication_date": "26 Jul 2022",
        "abstract": "Machine learning for hospital operations is under-studied. We present a prediction pipeline that uses live electronic health-records for patients in a UK teaching hospital’s emergency department (ED) to generate short-term, probabilistic forecasts of emergency admissions. A set of XGBoost classifiers applied to 109,465 ED visits yielded AUROCs from 0.82 to 0.90 depending on elapsed visit-time at the point of prediction. Patient-level probabilities of admission were aggregated to forecast the number of admissions among current ED patients and, incorporating patients yet to arrive, total emergency admissions within specified time-windows. The pipeline gave a mean absolute error (MAE) of 4.0 admissions (mean percentage error of 17%) versus 6.5 (32%) for a benchmark metric. Models developed with 104,504 later visits during the Covid-19 pandemic gave AUROCs of 0.68–0.90 and MAE of 4.2 (30%) versus a 4.9 (33%) benchmark. We discuss how we surmounted challenges of designing and implementing models for real-time use, including temporal framing, data preparation, and changing operational conditions.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Ultrasound-based radiomics technology in fetal lung texture analysis prediction of neonatal respiratory morbidity",
        "link": "https://www.nature.com/articles/s41598-022-17129-8",
        "publication_date": "26 Jul 2022",
        "abstract": "To develop a novel method for predicting neonatal respiratory morbidity (NRM) by ultrasound-based radiomics technology. In this retrospective study, 430 high-throughput features per fetal-lung image were extracted from 295 fetal lung ultrasound images (four-chamber view) in 295 single pregnancies. Images had been obtained between 28+3 and 37+6 weeks of gestation within 72 h before delivery. A machine-learning model built by RUSBoost (Random under-sampling with AdaBoost) architecture was created using 20 radiomics features extracted from the images and 2 clinical features (gestational age and pregnancy complications) to predict the possibility of NRM. Of the 295 standard fetal lung ultrasound images included, 210 in the training set and 85 in the testing set. The overall performance of the neonatal respiratory morbidity prediction model achieved AUC of 0.88 (95% CI 0.83–0.92) in the training set and 0.83 (95% CI 0.79–0.97) in the testing set, sensitivity of 84.31% (95% CI 79.06–89.44%) in the training set and 77.78% (95% CI 68.30–87.43%) in the testing set, specificity of 81.13% (95% CI 78.16–84.07%) in the training set and 82.09% (95% CI 77.65–86.62%) in the testing set, and accuracy of 81.90% (95% CI 79.34–84.41%) in the training set and 81.18% (95% CI 77.33–85.12%) in the testing set. Ultrasound-based radiomics technology can be used to predict NRM. The results of this study may provide a novel method for non-invasive approaches for the prenatal prediction of NRM.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A methodology for evaluating digital contact tracing apps based on the COVID-19 experience",
        "link": "https://www.nature.com/articles/s41598-022-17024-2",
        "publication_date": "26 Jul 2022",
        "abstract": "Controlling the spreading of infectious diseases has been shown crucial in the COVID-19 pandemic. Traditional contact tracing is used to detect newly infected individuals by tracing their previous contacts, and by selectively checking and isolating any individuals likely to have been infected. Digital contact tracing with the utilisation of smartphones was contrived as a technological aid to improve this manual, slow and tedious process. Nevertheless, despite the high hopes raised when smartphone-based contact tracing apps were introduced as a measure to reduce the spread of the COVID-19, their efficiency has been moderately low. In this paper, we propose a methodology for evaluating digital contact tracing apps, based on an epidemic model, which will be used not only to evaluate the deployed Apps against the COVID-19 but also to determine how they can be improved for future pandemics. Firstly, the model confirms the moderate effectiveness of the deployed digital contact tracing, confirming the fact that it could not be used as the unique measure to fight against the COVID-19, and had to be combined with additional measures. Secondly, several improvements are proposed (and evaluated) to increase the efficiency of digital control tracing to become a more useful tool in the future.",
        "conclusions": "The key (and regretful) issue is why digital technology has failed to stem the worst pandemic in a century. The causes are not only technical; in fact, lack of coordination between countries and states, test shortages, and mistrust of technology are cited among the main social and political causes.Summing up, based on the evaluations performed using our proposed model, we can derive the following conclusions:\n\nThe efficacy of the deployed digital contact tracing applications, with an adoption ratio of around 20% (in countries where they were not mandatory), was quite limited. Therefore, it was necessary to use other measures.\n\n\nAdoption ratio is the critical factor in improving its effectiveness. Although it is not specifically a technical factor, this adoption ratio can be increased by installing and activating the app by default (known as the opt-out strategy) or by using it only for cohorts (subsets of the population).\n\n\nA higher accuracy in detecting the risky contacts is required to avoid false alerts and an excessive number of quarantined individuals. This accuracy plays a key role, as false alerts can undermine users’ confidence in digital contact tracing, thus reducing its adoption ratio.\n\n\nThe implemented decentralised approach penalised the performance of digital contact tracing. Thus, a centralised approach provides faster contact tracing, which is essential to detect and quarantine possible newly infected individuals.\n\n\nFortunately, with these technical improvements, and when combined with other mitigation measures, digital contact tracing can avert a reasonable number of infected individuals and deaths, even with adoption ratios around 20%, and high reproductive ratios.",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Solution structure of recombinant Pvfp-5β reveals insights into mussel adhesion",
        "link": "https://www.nature.com/articles/s42003-022-03699-w",
        "publication_date": "25 Jul 2022",
        "abstract": "Some marine organisms can resist to aqueous tidal environments and adhere tightly on wet surface. This behavior has raised increasing attention for potential applications in medicine, biomaterials, and tissue engineering. In mussels, adhesive forces to the rock are the resultant of proteinic fibrous formations called byssus. We present the solution structure of Pvfp-5β, one of the three byssal plaque proteins secreted by the Asian green mussel Perna viridis, and the component responsible for initiating interactions with the substrate. We demonstrate that Pvfp-5β has a stably folded structure in agreement with the presence in the sequence of two EGF motifs. The structure is highly rigid except for a few residues affected by slow local motions in the µs-ms time scale, and differs from the model calculated by artificial intelligence methods for the relative orientation of the EGF modules, which is something where computational methods still underperform. We also show that Pvfp-5β is able to coacervate even with no DOPA modification, giving thus insights both for understanding the adhesion mechanism of adhesive mussel proteins, and developing of biomaterials.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Avoiding loss of native individuals in birth certificate data",
        "link": "https://www.nature.com/articles/s41372-022-01469-4",
        "publication_date": "23 Jul 2022",
        "abstract": "American Indian or Alaskan Native (AIAN) families are disproportionately affected by preterm birth compared to non-Hispanic White families (11.6 vs. 9.1% in 2020) [1]. Persistent inequities across the lifespan result in shorter life expectancies among AIAN individuals than any other racial group in the United States [2]. One challenge to improving health and healthcare of AIAN families is the lack of representation in research [3]. This is partly due to the small proportion of AIAN individuals in the US population (constituting roughly two percent). While the gold standard in analyses of racial disparities in health is to use self-identified race [4], advanced statistical models often cannot accommodate very small sample sizes [5]. As such, AIAN individuals often are absorbed into an “other” category when analyzing health outcomes, including preterm birth. Such aggregation can mask actionable disparities.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Human–machine teaming is key to AI adoption: clinicians’ experiences with a deployed machine learning system",
        "link": "https://www.nature.com/articles/s41746-022-00597-7",
        "publication_date": "21 Jul 2022",
        "abstract": "While a growing number of machine learning (ML) systems have been deployed in clinical settings with the promise of improving patient care, many have struggled to gain adoption and realize this promise. Based on a qualitative analysis of coded interviews with clinicians who use an ML-based system for sepsis, we found that, rather than viewing the system as a surrogate for their clinical judgment, clinicians perceived themselves as partnering with the technology. Our findings suggest that, even without a deep understanding of machine learning, clinicians can build trust with an ML system through experience, expert endorsement and validation, and systems designed to accommodate clinicians’ autonomy and support them across their entire workflow.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Decision effect of a deep-learning model to assist a head computed tomography order for pediatric traumatic brain injury",
        "link": "https://www.nature.com/articles/s41598-022-16313-0",
        "publication_date": "21 Jul 2022",
        "abstract": "The study aims to measure the effectiveness of an AI-based traumatic intracranial hemorrhage prediction model in the decisions of emergency physicians regarding ordering head computed tomography (CT) scans. We developed a deep-learning model for predicting traumatic intracranial hemorrhages (DEEPTICH) using a national trauma registry with 1.8 million cases. For simulation, 24 cases were selected from previous emergency department cases. For each case, physicians made decisions on ordering a head CT twice: initially without the DEEPTICH assistance, and subsequently with the DEEPTICH assistance. Of the 528 responses from 22 participants, 201 initial decisions were different from the DEEPTICH recommendations. Of these 201 initial decisions, 94 were changed after DEEPTICH assistance (46.8%). For the cases in which CT was initially not ordered, 71.4% of the decisions were changed (p < 0.001), and for the cases in which CT was initially ordered, 37.2% (p < 0.001) of the decisions were changed after DEEPTICH assistance. When using DEEPTICH, 46 (11.6%) unnecessary CTs were avoided (p < 0.001) and 10 (11.4%) traumatic intracranial hemorrhages (ICHs) that would have been otherwise missed were found (p = 0.039). We found that emergency physicians were likely to accept AI based on how they perceived its safety.",
        "conclusions": "DEEPTICH affects decisions of emergency physicians to order head CTs, as demonstrated by the decision simulation study. The effectiveness of the model is more significant when the model recommends ordering of head CTs.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Dynamic prediction of mortality after traumatic brain injury using a machine learning algorithm",
        "link": "https://www.nature.com/articles/s41746-022-00652-3",
        "publication_date": "18 Jul 2022",
        "abstract": "Intensive care for patients with traumatic brain injury (TBI) aims to optimize intracranial pressure (ICP) and cerebral perfusion pressure (CPP). The transformation of ICP and CPP time-series data into a dynamic prediction model could aid clinicians to make more data-driven treatment decisions. We retrained and externally validated a machine learning model to dynamically predict the risk of mortality in patients with TBI. Retraining was done in 686 patients with 62,000 h of data and validation was done in two international cohorts including 638 patients with 60,000 h of data. The area under the receiver operating characteristic curve increased with time to 0.79 and 0.73 and the precision recall curve increased with time to 0.57 and 0.64 in the Swedish and American validation cohorts, respectively. The rate of false positives decreased to ≤2.5%. The algorithm provides dynamic mortality predictions during intensive care that improved with increasing data and may have a role as a clinical decision support tool.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Multisite implementation of a workflow-integrated machine learning system to optimize COVID-19 hospital admission decisions",
        "link": "https://www.nature.com/articles/s41746-022-00646-1",
        "publication_date": "16 Jul 2022",
        "abstract": "Demand has outstripped healthcare supply during the coronavirus disease 2019 (COVID-19) pandemic. Emergency departments (EDs) are tasked with distinguishing patients who require hospital resources from those who may be safely discharged to the community. The novelty and high variability of COVID-19 have made these determinations challenging. In this study, we developed, implemented and evaluated an electronic health record (EHR) embedded clinical decision support (CDS) system that leverages machine learning (ML) to estimate short-term risk for clinical deterioration in patients with or under investigation for COVID-19. The system translates model-generated risk for critical care needs within 24 h and inpatient care needs within 72 h into rapidly interpretable COVID-19 Deterioration Risk Levels made viewable within ED clinician workflow. ML models were derived in a retrospective cohort of 21,452 ED patients who visited one of five ED study sites and were prospectively validated in 15,670 ED visits that occurred before (n = 4322) or after (n = 11,348) CDS implementation; model performance and numerous patient-oriented outcomes including in-hospital mortality were measured across study periods. Incidence of critical care needs within 24 h and inpatient care needs within 72 h were 10.7% and 22.5%, respectively and were similar across study periods. ML model performance was excellent under all conditions, with AUC ranging from 0.85 to 0.91 for prediction of critical care needs and 0.80–0.90 for inpatient care needs. Total mortality was unchanged across study periods but was reduced among high-risk patients after CDS implementation.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The B-Score is a novel metric for measuring the true performance of blood pressure estimation models",
        "link": "https://www.nature.com/articles/s41598-022-16527-2",
        "publication_date": "16 Jul 2022",
        "abstract": "We aimed to develop and test a novel metric for the relative performance of blood pressure estimation systems (B-Score). The B-Score sets absolute blood pressure estimation model performance in contrast to the dataset the model is tested upon. We calculate the B-Score based on inter- and intrapersonal variabilities within the dataset. To test the B-Score for reliable results and desired properties, we designed generic datasets with differing inter- and intrapersonal blood pressure variability. We then tested the B-Score’s real-world functionality with a small, published dataset and the largest available blood pressure dataset (MIMIC IV). The B-Score demonstrated reliable and desired properties. The real-world test provided allowed the direct comparison of different datasets and revealed insights hidden from absolute performance measures. The B-Score is a functional, novel, and easy to interpret measure of relative blood pressure estimation system performance. It is easily calculated for any dataset and enables the direct comparison of various systems tested on different datasets. We created a metric for direct blood pressure estimation system performance. The B-Score allows researchers to detect promising trends quickly and reliably in the scientific literature. It further allows researchers and engineers to quickly assess and compare performances of various systems and algorithms, even when tested on different datasets.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The Medical Segmentation Decathlon",
        "link": "https://www.nature.com/articles/s41467-022-30695-9",
        "publication_date": "15 Jul 2022",
        "abstract": "International challenges have become the de facto standard for comparative assessment of image analysis algorithms. Although segmentation is the most widely investigated medical image processing task, the various challenges have been organized to focus only on specific clinical tasks. We organized the Medical Segmentation Decathlon (MSD)—a biomedical image analysis challenge, in which algorithms compete in a multitude of both tasks and modalities to investigate the hypothesis that a method capable of performing well on multiple tasks will generalize well to a previously unseen task and potentially outperform a custom-designed solution. MSD results confirmed this hypothesis, moreover, MSD winner continued generalizing well to a wide range of other clinical problems for the next two years. Three main conclusions can be drawn from this study: (1) state-of-the-art image segmentation algorithms generalize well when retrained on unseen tasks; (2) consistent algorithmic performance across multiple tasks is a strong surrogate of algorithmic generalizability; (3) the training of accurate AI segmentation models is now commoditized to scientists that are not versed in AI model training.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Partial freezing of rat livers extends preservation time by 5-fold",
        "link": "https://www.nature.com/articles/s41467-022-31490-2",
        "publication_date": "15 Jul 2022",
        "abstract": "The limited preservation duration of organs has contributed to the shortage of organs for transplantation. Recently, a tripling of the storage duration was achieved with supercooling, which relies on temperatures between −4 and −6 °C. However, to achieve deeper metabolic stasis, lower temperatures are required. Inspired by freeze-tolerant animals, we entered high-subzero temperatures (−10 to −15 °C) using ice nucleators to control ice and cryoprotective agents (CPAs) to maintain an unfrozen liquid fraction. We present this approach, termed partial freezing, by testing gradual (un)loading and different CPAs, holding temperatures, and storage durations. Results indicate that propylene glycol outperforms glycerol and injury is largely influenced by storage temperatures. Subsequently, we demonstrate that machine perfusion enhancements improve the recovery of livers after freezing. Ultimately, livers that were partially frozen for 5-fold longer showed favorable outcomes as compared to viable controls, although frozen livers had lower cumulative bile and higher liver enzymes.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Neural network-based method for diagnosis and severity assessment of Graves’ orbitopathy using orbital computed tomography",
        "link": "https://www.nature.com/articles/s41598-022-16217-z",
        "publication_date": "15 Jul 2022",
        "abstract": "Computed tomography (CT) has been widely used to diagnose Graves’ orbitopathy, and the utility is gradually increasing. To develop a neural network (NN)-based method for diagnosis and severity assessment of Graves’ orbitopathy (GO) using orbital CT, a specific type of NN optimized for diagnosing GO was developed and trained using 288 orbital CT scans obtained from patients with mild and moderate-to-severe GO and normal controls. The developed NN was compared with three conventional NNs [GoogleNet Inception v1 (GoogLeNet), 50-layer Deep Residual Learning (ResNet-50), and 16-layer Very Deep Convolutional Network from Visual Geometry group (VGG-16)]. The diagnostic performance was also compared with that of three oculoplastic specialists. The developed NN had an area under receiver operating curve (AUC) of 0.979 for diagnosing patients with moderate-to-severe GO. Receiver operating curve (ROC) analysis yielded AUCs of 0.827 for GoogLeNet, 0.611 for ResNet-50, 0.540 for VGG-16, and 0.975 for the oculoplastic specialists for diagnosing moderate-to-severe GO. For the diagnosis of mild GO, the developed NN yielded an AUC of 0.895, which is better than the performances of the other NNs and oculoplastic specialists. This study may contribute to NN-based interpretation of orbital CTs for diagnosing various orbital diseases",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Clustering analysis and prognostic signature of lung adenocarcinoma based on the tumor microenvironment",
        "link": "https://www.nature.com/articles/s41598-022-15971-4",
        "publication_date": "14 Jul 2022",
        "abstract": "Because of immunotherapy failure in lung adenocarcinoma, we have tried to find new potential biomarkers for differentiating different tumor subtypes and predicting prognosis. We identified two subtypes based on tumor microenvironment-related genes in this study. We used seven methods to analyze the immune cell infiltration between subgroups. Further analysis of tumor mutation load and immune checkpoint expression among different subgroups was performed. The least absolute shrinkage and selection operator Cox regression was applied for further selection. The selected genes were used to construct a prognostic 14-gene signature for LUAD. Next, a survival analysis and time-dependent receiver operating characteristics were performed to verify and evaluate the model. Gene set enrichment analyses and immune analysis in risk groups was also performed. According to the expression of genes related to the tumor microenvironment, lung adenocarcinoma can be divided into cold tumors and hot tumors. The signature we built was able to predict prognosis more accurately than previously known models. The signature-based tumor microenvironment provides further insight into the prediction of lung adenocarcinoma prognosis and may guide individualized treatment.",
        "conclusions": "In conclusion, LUAD patients could be divided into two subgroups according to TME-related genes. Their immune status is different and may guide patients to personalized treatment. Our study proposes a TME-related signature that could be implemented in assessing LUAD patients and might improve prognostic accuracy.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Preoperative prediction of the need for arterial and central venous catheterization using machine learning techniques",
        "link": "https://www.nature.com/articles/s41598-022-16144-z",
        "publication_date": "13 Jul 2022",
        "abstract": "Some surgical patients require an arterial or central venous catheterization intraoperatively. This decision relied solely on the experience of individual anesthesiologists; however, these decisions are not easy for clinicians who are in an emergency or inexperienced. Therefore, applying recent artificial intelligence techniques to automatically extractable data from electronic medical record (EMR) could create a very clinically useful model in this situation. This study aimed to develop a model that is easy to apply in real clinical settings by implementing a prediction model for the preoperative decision to insert an arterial and central venous catheter and that can be automatically linked to the EMR. We collected and retrospectively analyzed data from 66,522 patients, > 18 years of age, who underwent non-cardiac surgeries from March 2019 to April 2021 at the single tertiary medical center. Data included demographics, pre-operative laboratory tests, surgical information, and catheterization information. When compared with other machine learning methods, the DNN model showed the best predictive performance in terms of the area under receiver operating characteristic curve and area under the precision-recall curve. Operation code information accounted for the largest portion of the prediction. This can be applied to clinical fields using operation code and minimal preoperative clinical information.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Application of machine learning methods for the prediction of true fasting status in patients performing blood tests",
        "link": "https://www.nature.com/articles/s41598-022-15161-2",
        "publication_date": "13 Jul 2022",
        "abstract": "The fasting blood glucose (FBG) values extracted from electronic medical records (EMR) are assumed valid in existing research, which may cause diagnostic bias due to misclassification of fasting status. We proposed a machine learning (ML) algorithm to predict the fasting status of blood samples. This cross-sectional study was conducted using the EMR of a medical center from 2003 to 2018 and a total of 2,196,833 ontological FBGs from the outpatient service were enrolled. The theoretical true fasting status are identified by comparing the values of ontological FBG with average glucose levels derived from concomitant tested HbA1c based on multi-criteria. In addition to multiple logistic regression, we extracted 67 features to predict the fasting status by eXtreme Gradient Boosting (XGBoost). The discrimination and calibration of the prediction models were also assessed. Real-world performance was gauged by the prevalence of ineffective glucose measurement (IGM). Of the 784,340 ontologically labeled fasting samples, 77.1% were considered theoretical FBGs. The median (IQR) glucose and HbA1c level of ontological and theoretical fasting samples in patients without diabetes mellitus (DM) were 94.0 (87.0, 102.0) mg/dL and 5.6 (5.4, 5.9)%, and 92.0 (86.0, 99.0) mg/dL and 5.6 (5.4, 5.9)%, respectively. The XGBoost showed comparable calibration and AUROC of 0.887 than that of 0.868 in multiple logistic regression in the parsimonious approach and identified important predictors of glucose level, home-to-hospital distance, age, and concomitantly serum creatinine and lipid testing. The prevalence of IGM dropped from 27.8% based on ontological FBGs to 0.48% by using algorithm-verified FBGs. The proposed ML algorithm or multiple logistic regression model aids in verification of the fasting status.",
        "conclusions": "To the best of our knowledge, this is the first attempt at using a ML approach to evaluate the reliability of fasting samples in a large tertiary hospital. Only 65.3% of ontologically AC samples could be classified as algorithm-verified fasting status. Despite its moderate performance in predicting the fasting status among outpatients, our algorithms provide an innovative approach to clean medical data and facilitate true fasting BG detection. Notably, this study has introduced an essential step towards establishing automated phenotyping in EMR for effective diabetic screening and more accurate estimation of the global and local epidemiology of DM.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Exploratory analysis using machine learning of predictive factors for falls in type 2 diabetes",
        "link": "https://www.nature.com/articles/s41598-022-15224-4",
        "publication_date": "13 Jul 2022",
        "abstract": "We aimed to investigate the status of falls and to identify important risk factors for falls in persons with type 2 diabetes (T2D) including the non-elderly. Participants were 316 persons with T2D who were assessed for medical history, laboratory data and physical capabilities during hospitalization and given a questionnaire on falls one year after discharge. Two different statistical models, logistic regression and random forest classifier, were used to identify the important predictors of falls. The response rate to the survey was 72%; of the 226 respondents, there were 129 males and 97 females (median age 62 years). The fall rate during the first year after discharge was 19%. Logistic regression revealed that knee extension strength, fasting C-peptide (F-CPR) level and dorsiflexion strength were independent predictors of falls. The random forest classifier placed grip strength, F-CPR, knee extension strength, dorsiflexion strength and proliferative diabetic retinopathy among the 5 most important variables for falls. Lower extremity muscle weakness, elevated F-CPR levels and reduced grip strength were shown to be important risk factors for falls in T2D. Analysis by random forest can identify new risk factors for falls in addition to logistic regression.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "MRI based radiomics enhances prediction of neurodevelopmental outcome in very preterm neonates",
        "link": "https://www.nature.com/articles/s41598-022-16066-w",
        "publication_date": "13 Jul 2022",
        "abstract": "To predict adverse neurodevelopmental outcome of very preterm neonates. A total of 166 preterm neonates born between 24–32 weeks’ gestation underwent brain MRI early in life. Radiomics features were extracted from T1- and T2- weighted images. Motor, cognitive, and language outcomes were assessed at a corrected age of 18 and 33 months and 4.5 years. Elastic Net was implemented to select the clinical and radiomic features that best predicted outcome. The area under the receiver operating characteristic (AUROC) curve was used to determine the predictive ability of each feature set. Clinical variables predicted cognitive outcome at 18 months with AUROC 0.76 and motor outcome at 4.5 years with AUROC 0.78. T1-radiomics features showed better prediction than T2-radiomics on the total motor outcome at 18 months and gross motor outcome at 33 months (AUROC: 0.81 vs 0.66 and 0.77 vs 0.7). T2-radiomics features were superior in two 4.5-year motor outcomes (AUROC: 0.78 vs 0.64 and 0.8 vs 0.57). Combining clinical parameters and radiomics features improved model performance in motor outcome at 4.5 years (AUROC: 0.84 vs 0.8). Radiomic features outperformed clinical variables for the prediction of adverse motor outcomes. Adding clinical variables to the radiomics model enhanced predictive performance.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Multi-center validation of machine learning model for preoperative prediction of postoperative mortality",
        "link": "https://www.nature.com/articles/s41746-022-00625-6",
        "publication_date": "12 Jul 2022",
        "abstract": "Accurate prediction of postoperative mortality is important for not only successful postoperative patient care but also for information-based shared decision-making with patients and efficient allocation of medical resources. This study aimed to create a machine-learning prediction model for 30-day mortality after a non-cardiac surgery that adapts to the manageable amount of clinical information as input features and is validated against multi-centered rather than single-centered data. Data were collected from 454,404 patients over 18 years of age who underwent non-cardiac surgeries from four independent institutions. We performed a retrospective analysis of the retrieved data. Only 12–18 clinical variables were used for model training. Logistic regression, random forest classifier, extreme gradient boosting (XGBoost), and deep neural network methods were applied to compare the prediction performances. To reduce overfitting and create a robust model, bootstrapping and grid search with tenfold cross-validation were performed. The XGBoost method in Seoul National University Hospital (SNUH) data delivers the best performance in terms of the area under receiver operating characteristic curve (AUROC) (0.9376) and the area under the precision-recall curve (0.1593). The predictive performance was the best when the SNUH model was validated with Ewha Womans University Medical Center data (AUROC, 0.941). Preoperative albumin, prothrombin time, and age were the most important features in the model for each hospital. It is possible to create a robust artificial intelligence prediction model applicable to multiple institutions through a light predictive model using only minimal preoperative information that can be automatically extracted from each hospital.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Gait analysis dataset of healthy volunteers and patients before and 6 months after total hip arthroplasty",
        "link": "https://www.nature.com/articles/s41597-022-01483-3",
        "publication_date": "12 Jul 2022",
        "abstract": "Clinical gait analysis is a promising approach for quantifying gait deviations and assessing the impairments altering gait in patients with osteoarthritis. There is a lack of consensus on the identification of kinematic outcomes that could be used for the diagnosis and follow up in patients. The proposed dataset has been established on 80 asymptomatic participants and 106 patients with unilateral hip osteoarthritis before and 6 months after arthroplasty. All volunteers walked along a 6 meters straight line at their self-selected speed. Three dimensional trajectories of 35 reflective markers were simultaneously recorded and Plugin Gait Bones, angles, Center of Mass trajectories and ground reaction forces were computed. Gait video recordings, when available, anthropometric and demographic descriptions are also available. A minimum of 10 trials have been made available in the weka file format and C3D file to enhance the use of machine learning algorithms. We aim to share this dataset to facilitate the identification of new movement-related kinematic outcomes for improving the diagnosis and follow up in patients with hip OA.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning-based quantitative prediction of drug exposure in drug-drug interactions using drug label information",
        "link": "https://www.nature.com/articles/s41746-022-00639-0",
        "publication_date": "11 Jul 2022",
        "abstract": "Many machine learning techniques provide a simple prediction for drug-drug interactions (DDIs). However, a systematically constructed database with pharmacokinetic (PK) DDI information does not exist, nor is there a machine learning model that numerically predicts PK fold change (FC) with it. Therefore, we propose a PK DDI prediction (PK-DDIP) model for quantitative DDI prediction with high accuracy, while constructing a highly reliable PK-DDI database. Reliable information of 3,627 PK DDIs was constructed from 3,587 drugs using 38,711 Food and Drug Administration (FDA) drug labels. This PK-DDIP model predicted the FC of the area under the time-concentration curve (AUC) within ± 0.5959. The prediction proportions within 0.8–1.25-fold, 0.67–1.5-fold, and 0.5–2-fold of the AUC were 75.77, 86.68, and 94.76%, respectively. Two external validations confirmed good prediction performance for newly updated FDA labels and FC from patients’. This model enables potential DDI evaluation before clinical trials, which will save time and cost.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Explainable machine learning for real-time deterioration alert prediction to guide pre-emptive treatment",
        "link": "https://www.nature.com/articles/s41598-022-15877-1",
        "publication_date": "11 Jul 2022",
        "abstract": "The Electronic Medical Record (EMR) provides an opportunity to manage patient care efficiently and accurately. This includes clinical decision support tools for the timely identification of adverse events or acute illnesses preceded by deterioration. This paper presents a machine learning-driven tool developed using real-time EMR data for identifying patients at high risk of reaching critical conditions that may demand immediate interventions. This tool provides a pre-emptive solution that can help busy clinicians to prioritize their efforts while evaluating the individual patient risk of deterioration. The tool also provides visualized explanation of the main contributing factors to its decisions, which can guide the choice of intervention. When applied to a test cohort of 18,648 patient records, the tool achieved 100% sensitivity for prediction windows 2–8 h in advance for patients that were identified at 95%, 85% and 70% risk of deterioration.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Age group prediction with panoramic radiomorphometric parameters using machine learning algorithms",
        "link": "https://www.nature.com/articles/s41598-022-15691-9",
        "publication_date": "09 Jul 2022",
        "abstract": "The aim of this study is to investigate the relationship of 18 radiomorphometric parameters of panoramic radiographs based on age, and to estimate the age group of people with permanent dentition in a non-invasive, comprehensive, and accurate manner using five machine learning algorithms. For the study population (209 men and 262 women; mean age, 32.12 ± 18.71 years), 471 digital panoramic radiographs of Korean individuals were applied. The participants were divided into three groups (with a 20-year age gap) and six groups (with a 10-year age gap), and each age group was estimated using the following five machine learning models: a linear discriminant analysis, logistic regression, kernelized support vector machines, multilayer perceptron, and extreme gradient boosting. Finally, a Fisher discriminant analysis was used to visualize the data configuration. In the prediction of the three age-group classification, the areas under the curve (AUCs) obtained for classifying young ages (10–19 years) ranged from 0.85 to 0.88 for five different machine learning models. The AUC values of the older age group (50–69 years) ranged from 0.82 to 0.88, and those of adults (20–49 years) were approximately 0.73. In the six age-group classification, the best scores were also found in age groups 1 (10–19 years) and 6 (60–69 years), with mean AUCs ranging from 0.85 to 0.87 and 80 to 0.90, respectively. A feature analysis based on LDA weights showed that the L-Pulp Area was important for discriminating young ages (10–49 years), and L-Crown, U-Crown, L-Implant, U-Implant, and Periodontitis were used as predictors for discriminating older ages (50–69 years). We established acceptable linear and nonlinear machine learning models for a dental age group estimation using multiple maxillary and mandibular radiomorphometric parameters. Since certain radiomorphological characteristics of young and the elderly were linearly related to age, young and old groups could be easily distinguished from other age groups with automated machine learning models.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Dental anomaly detection using intraoral photos via deep learning",
        "link": "https://www.nature.com/articles/s41598-022-15788-1",
        "publication_date": "08 Jul 2022",
        "abstract": "Children with orofacial clefting (OFC) present with a wide range of dental anomalies. Identifying these anomalies is vital to understand their etiology and to discern the complex phenotypic spectrum of OFC. Such anomalies are currently identified using intra-oral exams by dentists, a costly and time-consuming process. We claim that automating the process of anomaly detection using deep neural networks (DNNs) could increase efficiency and provide reliable anomaly detection while potentially increasing the speed of research discovery. This study characterizes the use of` DNNs to identify dental anomalies by training a DNN model using intraoral photographs from the largest international cohort to date of children with nonsyndromic OFC and controls (OFC1). In this project, the intraoral images were submitted to a Convolutional Neural Network model to perform multi-label multi-class classification of 10 dental anomalies. The network predicts whether an individual exhibits any of the 10 anomalies and can do so significantly faster than a human rater can. For all but three anomalies, F1 scores suggest that our model performs competitively at anomaly detection when compared to a dentist with 8 years of clinical experience. In addition, we use saliency maps to provide a post-hoc interpretation for our model’s predictions. This enables dentists to examine and verify our model’s predictions.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "CovidPubGraph: A FAIR Knowledge Graph of COVID-19 Publications",
        "link": "https://www.nature.com/articles/s41597-022-01298-2",
        "publication_date": "08 Jul 2022",
        "abstract": "The rapid generation of large amounts of information about the coronavirus SARS-CoV-2 and the disease COVID-19 makes it increasingly difficult to gain a comprehensive overview of current insights related to the disease. With this work, we aim to support the rapid access to a comprehensive data source on COVID-19 targeted especially at researchers. Our knowledge graph, CovidPubGraph, an RDF knowledge graph of scientific publications, abides by the Linked Data and FAIR principles. The base dataset for the extraction is CORD-19, a dataset of COVID-19-related publications, which is updated regularly. Consequently, CovidPubGraph is updated biweekly. Our generation pipeline applies named entity recognition, entity linking and link discovery approaches to the original data. The current version of CovidPubGraph contains 268,108,670 triples and is linked to 9 other datasets by over 1 million links. In our use case studies, we demonstrate the usefulness of our knowledge graph for different applications. CovidPubGraph is publicly available under the Creative Commons Attribution 4.0 International license.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "HistoML, a markup language for representation and exchange of histopathological features in pathology images",
        "link": "https://www.nature.com/articles/s41597-022-01505-0",
        "publication_date": "08 Jul 2022",
        "abstract": "The study of histopathological phenotypes is vital for cancer research and medicine as it links molecular mechanisms to disease prognosis. It typically involves integration of heterogenous histopathological features in whole-slide images (WSI) to objectively characterize a histopathological phenotype. However, the large-scale implementation of phenotype characterization has been hindered by the fragmentation of histopathological features, resulting from the lack of a standardized format and a controlled vocabulary for structured and unambiguous representation of semantics in WSIs. To fill this gap, we propose the Histopathology Markup Language (HistoML), a representation language along with a controlled vocabulary (Histopathology Ontology) based on Semantic Web technologies. Multiscale features within a WSI, from single-cell features to mesoscopic features, could be represented using HistoML which is a crucial step towards the goal of making WSIs findable, accessible, interoperable and reusable (FAIR). We pilot HistoML in representing WSIs of kidney cancer as well as thyroid carcinoma and exemplify the uses of HistoML representations in semantic queries to demonstrate the potential of HistoML-powered applications for phenotype characterization.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Peptidome profiling for the immunological stratification in sepsis: a proof of concept study",
        "link": "https://www.nature.com/articles/s41598-022-15792-5",
        "publication_date": "06 Jul 2022",
        "abstract": "Sepsis has been called the graveyard of pharmaceutical companies due to the numerous failed clinical trials. The lack of tools to monitor the immunological status in sepsis constrains the development of therapies. Here, we evaluated a test based on whole plasma peptidome acquired by MALDI-TOF-mass spectrometer and machine-learning algorithms to discriminate two lipopolysaccharide-(LPS) induced murine models emulating the pro- and anti-inflammatory/immunosuppression environments that can be found during sepsis. The LPS group was inoculated with a single high dose of LPS and the IS group was subjected to increasing doses of LPS, to induce proinflammatory and anti-inflammatory/immunosuppression profiles respectively. The LPS group showed leukopenia and higher levels of cytokines and tissue damage markers, and the IS group showed neutrophilia, lymphopenia and decreased humoral response. Principal component analysis of the plasma peptidomes formed discrete clusters that mostly coincided with the experimental groups. In addition, machine-learning algorithms discriminated the different experimental groups with a sensitivity of 95.7% and specificity of 90.9%. Data reveal the potential of plasma fingerprints analysis by MALDI-TOF-mass spectrometry as a simple, speedy and readily transferrable method for sepsis patient stratification that would contribute to therapeutic decision-making based on their immunological status.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Advantages of deep learning with convolutional neural network in detecting disc displacement of the temporomandibular joint in magnetic resonance imaging",
        "link": "https://www.nature.com/articles/s41598-022-15231-5",
        "publication_date": "05 Jul 2022",
        "abstract": "This study investigated the usefulness of deep learning-based automatic detection of anterior disc displacement (ADD) from magnetic resonance imaging (MRI) of patients with temporomandibular joint disorder (TMD). Sagittal MRI images of 2520 TMJs were collected from 861 men and 399 women (average age 37.33 ± 18.83 years). A deep learning algorithm with a convolutional neural network was developed. Data augmentation and the Adam optimizer were applied to reduce the risk of overfitting the deep-learning model. The prediction performances were compared between the models and human experts based on areas under the curve (AUCs). The fine-tuning model showed excellent prediction performance (AUC = 0.8775) and acceptable accuracy (approximately 77%). Comparing the AUC values of the from-scratch (0.8269) and freeze models (0.5858) showed lower performances of the other models compared to the fine-tuning model. In Grad-CAM visualizations, the fine-tuning scheme focused more on the TMJ disc when judging ADD, and the sparsity was higher than that of the from-scratch scheme (84.69% vs. 55.61%, p < 0.05). The three fine-tuned ensemble models using different data augmentation techniques showed a prediction accuracy of 83%. Moreover, the AUC values of ADD were higher when patients with TMD were divided by age (0.8549–0.9275) and sex (male: 0.8483, female: 0.9276). While the accuracy of the ensemble model was higher than that of human experts, the difference was not significant (p = 0.1987–0.0671). Learning from pre-trained weights allowed the fine-tuning model to outperform the from-scratch model. Another benefit of the fine-tuning model for diagnosing ADD of TMJ in Grad-CAM analysis was the deactivation of unwanted gradient values to provide clearer visualizations compared to the from-scratch model. The Grad-CAM visualizations also agreed with the model learned through important features in the joint disc area. The accuracy was further improved by an ensemble of three fine-tuning models using diversified data. The main benefits of this model were the higher specificity compared to human experts, which may be useful for preventing true negative cases, and the maintenance of its prediction accuracy across sexes and ages, suggesting a generalized prediction.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development and implementation of patient-level prediction models of end-stage renal disease for type 2 diabetes patients using fast healthcare interoperability resources",
        "link": "https://www.nature.com/articles/s41598-022-15036-6",
        "publication_date": "04 Jul 2022",
        "abstract": "This study aimed to develop a model to predict the 5-year risk of developing end-stage renal disease (ESRD) in patients with type 2 diabetes mellitus (T2DM) using machine learning (ML). It also aimed to implement the developed algorithms into electronic medical records (EMR) system using Health Level Seven (HL7) Fast Healthcare Interoperability Resources (FHIR). The final dataset used for modeling included 19,159 patients. The medical data were engineered to generate various types of features that were input into the various ML classifiers. The classifier with the best performance was XGBoost, with an area under the receiver operator characteristics curve (AUROC) of 0.95 and area under the precision recall curve (AUPRC) of 0.79 using three-fold cross-validation, compared to other models such as logistic regression, random forest, and support vector machine (AUROC range, 0.929–0.943; AUPRC 0.765–0.792). Serum creatinine, serum albumin, the urine albumin-to-creatinine ratio, Charlson comorbidity index, estimated GFR, and medication days of insulin were features that were ranked high for the ESRD risk prediction. The algorithm was implemented in the EMR system using HL7 FHIR through an ML-dedicated server that preprocessed unstructured data and trained updated data.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "An ML prediction model based on clinical parameters and automated CT scan features for COVID-19 patients",
        "link": "https://www.nature.com/articles/s41598-022-15327-y",
        "publication_date": "04 Jul 2022",
        "abstract": "Outcome prediction for individual patient groups is of paramount importance in terms of selection of appropriate therapeutic options, risk communication to patients and families, and allocating resource through optimum triage. This has become even more necessary in the context of the current COVID-19 pandemic. Widening the spectrum of predictor variables by including radiological parameters alongside the usually utilized demographic, clinical and biochemical ones can facilitate building a comprehensive prediction model. Automation has the potential to build such models with applications to time-critical environments so that a clinician will be able to utilize the model outcomes in real-time decision making at bedside. We show that amalgamation of computed tomogram (CT) data with clinical parameters (CP) in generating a Machine Learning model from 302 COVID-19 patients presenting to an acute care hospital in India could prognosticate the need for invasive mechanical ventilation. Models developed from CP alone, CP and radiologist derived CT severity score and CP with automated lesion-to-lung ratio had AUC of 0.87 (95% CI 0.85–0.88), 0.89 (95% CI 0.87–0.91), and 0.91 (95% CI 0.89–0.93), respectively. We show that an operating point on the ROC can be chosen to aid clinicians in risk characterization according to the resource availability and ethical considerations. This approach can be deployed in more general settings, with appropriate calibrations, to predict outcomes of severe COVID-19 patients effectively.",
        "conclusions": "In conclusion, a clinicoradiological model, developed by amalgamation of radiological and clinical parameters, produced in line with the current study design, can predict important clinical outcome of need for invasive mechanical ventilation efficiently and safely. Every setting or region can use this technique to predict the outcome of severe COVID-19 patients effectively.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Gestational age-specific serum creatinine can predict adverse pregnancy outcomes",
        "link": "https://www.nature.com/articles/s41598-022-15450-w",
        "publication_date": "02 Jul 2022",
        "abstract": "Serum creatinine level (SCr) typically decreases during pregnancy due to physiologic glomerular hyperfiltration. Therefore, the clinical practice of estimated glomerular filtration rate (eGFR) based on SCr concentrations might be inapplicable to pregnant women with kidney disease since it does not take into account of the pregnancy-related biological changes. We integrated the Wonju Severance Christian Hospital (WSCH)-based findings and prior knowledge from big data to reveal the relationship between the abnormal but hidden SCr level and adverse pregnancy outcomes. We analyzed 4004 pregnant women who visited in WSCH. Adverse pregnancy outcomes included preterm birth, preeclampsia, fetal growth retardation, and intrauterine fetal demise. We categorized the pregnant women into four groups based on the gestational age (GA)-unadjusted raw distribution (Q1–4raw), and then GA-specific (Q1–4adj) SCr distribution. Linear regression analysis revealed that Q1-4adj groups had better predictive outcomes than the Q1–4raw groups. In logistic regression model, the Q1–4adj groups exhibited a robust non-linear U-shaped relationship with the risk of adverse pregnancy outcomes, compared to the Q1–4raw groups. The integrative analysis on SCr with respect to GA-specific distribution could be used to screen out pregnant women with a normal SCr coupled with a decreased renal function.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Utilization of dielectric properties for assessment of liver ischemia-reperfusion injury in vivo and during machine perfusion",
        "link": "https://www.nature.com/articles/s41598-022-14817-3",
        "publication_date": "01 Jul 2022",
        "abstract": "There is a shortage of donor livers and patients consequently die on waiting lists worldwide. Livers are discarded if they are clinically judged to have a high risk of non-function following transplantation. With the aim of extending the pool of available donor livers, we assessed the condition of porcine livers by monitoring the microwave dielectric properties. A total of 21 livers were divided into three groups: control with no injury (CON), biliary injury by hepatic artery occlusion (AHEP), and overall hepatic injury by static cold storage (SCS). All were monitored for four hours in vivo, followed by ex vivo plurithermic machine perfusion (PMP). Permittivity data was modeled with a two-pole Cole–Cole equation, and dielectric properties from one-hour intervals were analyzed during in vivo and normothermic machine perfusion (NMP). A clear increasing trend in the conductivity was observed in vivo in the AHEP livers compared to the control livers. After four hours of NMP, separations in the conductivity were observed between the three groups. Our results indicate that dielectric relaxation spectroscopy (DRS) can be used to detect and differentiate liver injuries, opening for a standardized and reliable point of evaluation for livers prior to transplantation.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Design, fabrication and testing of 3D printed smartphone-based device for collection of intrinsic fluorescence from human cervix",
        "link": "https://www.nature.com/articles/s41598-022-15007-x",
        "publication_date": "01 Jul 2022",
        "abstract": "Fluorescence spectroscopy has the potential to identify discriminatory signatures, crucial for early diagnosis of cervical cancer. We demonstrate here the design, fabrication and testing of a 3D printed smartphone based spectroscopic device. Polarized fluorescence and elastic scattering spectra are captured through the device using a 405 nm laser and a white LED source respectively. The device has been calibrated by comparison of spectra of standard fluorophores (Flavin adenine dinucleotide, fluorescein, rhodamine, and porphyrin) with the corresponding spectra collected from a commercial spectrometer. A few cervical tissue spectra have also been captured for proof of its applicability as a portable, standalone device for the collection of intrinsic fluorescence spectra from human cervix.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Spectral organ fingerprints for machine learning-based intraoperative tissue classification with hyperspectral imaging in a porcine model",
        "link": "https://www.nature.com/articles/s41598-022-15040-w",
        "publication_date": "30 Jun 2022",
        "abstract": "Visual discrimination of tissue during surgery can be challenging since different tissues appear similar to the human eye. Hyperspectral imaging (HSI) removes this limitation by associating each pixel with high-dimensional spectral information. While previous work has shown its general potential to discriminate tissue, clinical translation has been limited due to the method’s current lack of robustness and generalizability. Specifically, the scientific community is lacking a comprehensive spectral tissue atlas, and it is unknown whether variability in spectral reflectance is primarily explained by tissue type rather than the recorded individual or specific acquisition conditions. The contribution of this work is threefold: (1) Based on an annotated medical HSI data set (9059 images from 46 pigs), we present a tissue atlas featuring spectral fingerprints of 20 different porcine organs and tissue types. (2) Using the principle of mixed model analysis, we show that the greatest source of variability related to HSI images is the organ under observation. (3) We show that HSI-based fully-automatic tissue differentiation of 20 organ classes with deep neural networks is possible with high accuracy (> 95%). We conclude from our study that automatic tissue discrimination based on HSI data is feasible and could thus aid in intraoperative decisionmaking and pave the way for context-aware computer-assisted surgery systems and autonomous robotics.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Multisite learning of high-dimensional heterogeneous data with applications to opioid use disorder study of 15,000 patients across 5 clinical sites",
        "link": "https://www.nature.com/articles/s41598-022-14029-9",
        "publication_date": "30 Jun 2022",
        "abstract": "Integrating data across institutions can improve learning efficiency. To integrate data efficiently while protecting privacy, we propose A one-shot, summary-statistics-based, Distributed Algorithm for fitting Penalized (ADAP) regression models across multiple datasets. ADAP utilizes patient-level data from a lead site and incorporates the first-order (ADAP1) and second-order gradients (ADAP2) of the objective function from collaborating sites to construct a surrogate objective function at the lead site, where model fitting is then completed with proper regularizations applied. We evaluate the performance of the proposed method using both simulation and a real-world application to study risk factors for opioid use disorder (OUD) using 15,000 patient data from the OneFlorida Clinical Research Consortium. Our results show that ADAP performs nearly the same as the pooled estimator but achieves higher estimation accuracy and better variable selection than the local and average estimators. Moreover, ADAP2 successfully handles heterogeneity in covariate distributions.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Unsupervised-learning-based method for chest MRI–CT transformation using structure constrained unsupervised generative attention networks",
        "link": "https://www.nature.com/articles/s41598-022-14677-x",
        "publication_date": "30 Jun 2022",
        "abstract": "The integrated positron emission tomography/magnetic resonance imaging (PET/MRI) scanner simultaneously acquires metabolic information via PET and morphological information using MRI. However, attenuation correction, which is necessary for quantitative PET evaluation, is difficult as it requires the generation of attenuation-correction maps from MRI, which has no direct relationship with the gamma-ray attenuation information. MRI-based bone tissue segmentation is potentially available for attenuation correction in relatively rigid and fixed organs such as the head and pelvis regions. However, this is challenging for the chest region because of respiratory and cardiac motions in the chest, its anatomically complicated structure, and the thin bone cortex. We propose a new method using unsupervised generative attentional networks with adaptive layer-instance normalisation for image-to-image translation (U-GAT-IT), which specialised in unpaired image transformation based on attention maps for image transformation. We added the modality-independent neighbourhood descriptor (MIND) to the loss of U-GAT-IT to guarantee anatomical consistency in the image transformation between different domains. Our proposed method obtained a synthesised computed tomography of the chest. Experimental results showed that our method outperforms current approaches. The study findings suggest the possibility of synthesising clinically acceptable computed tomography images from chest MRI with minimal changes in anatomical structures without human annotation.",
        "conclusions": "The combination of U-GAT-IT and MIND was effective in preventing anatomical inconsistencies between ZTE and synthesised CT and enabled the generation of clinically acceptable synthesised CT images. Our method also enables inter-modality image conversion in the chest region, which has been challenging to accomplish up until now without using human annotations.",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Smartphone camera based assessment of adiposity: a validation study",
        "link": "https://www.nature.com/articles/s41746-022-00628-3",
        "publication_date": "29 Jun 2022",
        "abstract": "Body composition is a key component of health in both individuals and populations, and excess adiposity is associated with an increased risk of developing chronic diseases. Body mass index (BMI) and other clinical or commercially available tools for quantifying body fat (BF) such as DXA, MRI, CT, and photonic scanners (3DPS) are often inaccurate, cost prohibitive, or cumbersome to use. The aim of the current study was to evaluate the performance of a novel automated computer vision method, visual body composition (VBC), that uses two-dimensional photographs captured via a conventional smartphone camera to estimate percentage total body fat (%BF). The VBC algorithm is based on a state-of-the-art convolutional neural network (CNN). The hypothesis is that VBC yields better accuracy than other consumer-grade fat measurements devices. 134 healthy adults ranging in age (21–76 years), sex (61.2% women), race (60.4% White; 23.9% Black), and body mass index (BMI, 18.5–51.6 kg/m2) were evaluated at two clinical sites (N = 64 at MGH, N = 70 at PBRC). Each participant had %BF measured with VBC, three consumer and two professional bioimpedance analysis (BIA) systems. The PBRC participants also had air displacement plethysmography (ADP) measured. %BF measured by dual-energy x-ray absorptiometry (DXA) was set as the reference against which all other %BF measurements were compared. To test our scientific hypothesis we run multiple, pair-wise Wilcoxon signed rank tests where we compare each competing measurement tool (VBC, BIA, …) with respect to the same ground-truth (DXA). Relative to DXA, VBC had the lowest mean absolute error and standard deviation (2.16 ± 1.54%) compared to all of the other evaluated methods (p < 0.05 for all comparisons). %BF measured by VBC also had good concordance with DXA (Lin’s concordance correlation coefficient, CCC: all 0.96; women 0.93; men 0.94), whereas BMI had very poor concordance (CCC: all 0.45; women 0.40; men 0.74). Bland-Altman analysis of VBC revealed the tightest limits of agreement (LOA) and absence of significant bias relative to DXA (bias −0.42%, R2 = 0.03; p = 0.062; LOA −5.5% to +4.7%), whereas all other evaluated methods had significant (p < 0.01) bias and wider limits of agreement. Bias in Bland-Altman analyses is defined as the discordance between the y = 0 axis and the regressed line computed from the data in the plot. In this first validation study of a novel, accessible, and easy-to-use system, VBC body fat estimates were accurate and without significant bias compared to DXA as the reference; VBC performance exceeded those of all other BIA and ADP methods evaluated. The wide availability of smartphones suggests that the VBC method for evaluating %BF could play an important role in quantifying adiposity levels in a wide range of settings.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Impact on outcomes of mixed chimerism of bone marrow CD34+ sorted cells after matched or haploidentical allogeneic stem cell transplantation for myeloid malignancies",
        "link": "https://www.nature.com/articles/s41409-022-01747-x",
        "publication_date": "28 Jun 2022",
        "abstract": "Allogeneic hematopoietic stem cell transplantation (Allo-HSCT), proposed to patients with high-risk myeloid malignancies, may ultimately fail because of disease relapse. Bone marrow (BM) CD34+ cells in Allo-HSCT recipients can be either re-emerging recipient malignant cells or donor cells attesting of hematopoietic reconstitution. In this context, investigating donor/recipient chimerism in the population of BM CD34+ sorted cells (BM-CD34+SC) was performed in 261 Allo-HSCT recipients (matched n = 145, haploidentical n = 65, matched unrelated n = 51) with myeloid malignancies. BM-CD34+SC chimerism was compared to that of whole peripheral blood (PB) cells as well as other Allo-HSCT-related parameters, and impact on relapse and survival was assessed. Thresholds of 98% donor cells for PB and 90% for BM-CD34+SC were found to allow relapse prediction. This was completed by the application of machine learning tools to explore the predictive value of these parameters in multidimensional models with repeated iterations. BM-CD34+SC mixed chimerism stood out with all these methods as the most robust predictor of relapse with a significant impact on disease-free and overall survivals even after haploidentical Allo-HSCT and/or PTCY administration. This marker therefore appears to be of great interest for the decision of preemptive treatment to avoid post-transplant relapse.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The influence of HLA genotype on the development of metal hypersensitivity following joint replacement",
        "link": "https://www.nature.com/articles/s43856-022-00137-0",
        "publication_date": "24 Jun 2022",
        "abstract": "Over five million joint replacements are performed across the world each year. Cobalt chrome (CoCr) components are used in most of these procedures. Some patients develop delayed-type hypersensitivity (DTH) responses to CoCr implants, resulting in tissue damage and revision surgery. DTH is unpredictable and genetic links have yet to be definitively established.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Dynamic changes in heparin-binding protein as a prognostic biomarker for 30-day mortality in sepsis patients in the intensive care unit",
        "link": "https://www.nature.com/articles/s41598-022-14827-1",
        "publication_date": "24 Jun 2022",
        "abstract": "Heparin-binding protein (HBP) has been shown to be a robust predictor of the progression to organ dysfunction from sepsis, and we hypothesized that dynamic changes in HBP may reflect the severity of sepsis. We therefore aim to investigate the predictive value of baseline HBP, 24-h, and 48-h HBP change for prediction of 30-day mortality in adult patients with sepsis. This is a prospective observational study in an intensive care unit of a tertiary center. Patients aged 20 years or older who met SEPSIS-3 criteria were prospectively enrolled from August 2019 to January 2020. Plasma levels of HBP were measured at admission, 24 h, and 48 h and dynamic changes in HBP were calculated. The Primary endpoint was 30-day mortality. We tested whether the biomarkers could enhance the predictive accuracy of a multivariable predictive model. A total of 206 patients were included in the final analysis. 48-h HBP change (HBPc-48 h) had greater predictive accuracy of area under the curve (AUC: 0.82), followed by baseline HBP (0.79), PCT (0.72), lactate (0.71), and CRP (0.65), and HBPc-24 h (0.62). Incorporation of HBPc-48 h into a clinical prediction model significantly improved the AUC from 0.85 to 0.93. HBPc-48 h may assist clinicians with clinical outcome prediction in critically ill patients with sepsis and can improve the performance of a prediction model including age, SOFA score and Charlson comorbidity index.",
        "conclusions": "In our single center prospective observational trial, we found that 48-h HBP change was more accurate than CRP, PCT, lactate or initial HBP level in predicting in-hospital mortality. We observed that our patients with a 48-h HBP decrease greater than 50% had a greater than 90% chance of survival, while patients with a 48-h HBP decrease less than 4% had a nearly 90% 30-day all-cause mortality rate. The HBPc-48 h can be used to enhance the predictive accuracy of a clinical prediction model. Further studies are needed to better understand the pathophysiology of elevated HBP in septic patients and how HBP measurement may potentially inform clinical care.",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning methods to predict attrition in a population-based cohort of very preterm infants",
        "link": "https://www.nature.com/articles/s41598-022-13946-z",
        "publication_date": "22 Jun 2022",
        "abstract": "The timely identification of cohort participants at higher risk for attrition is important to earlier interventions and efficient use of research resources. Machine learning may have advantages over the conventional approaches to improve discrimination by analysing complex interactions among predictors. We developed predictive models of attrition applying a conventional regression model and different machine learning methods. A total of 542 very preterm (< 32 gestational weeks) infants born in Portugal as part of the European Effective Perinatal Intensive Care in Europe (EPICE) cohort were included. We tested a model with a fixed number of predictors (Baseline) and a second with a dynamic number of variables added from each follow-up (Incremental). Eight classification methods were applied: AdaBoost, Artificial Neural Networks, Functional Trees, J48, J48Consolidated, K-Nearest Neighbours, Random Forest and Logistic Regression. Performance was compared using AUC- PR (Area Under the Curve—Precision Recall), Accuracy, Sensitivity and F-measure. Attrition at the four follow-ups were, respectively: 16%, 25%, 13% and 17%. Both models demonstrated good predictive performance, AUC-PR ranging between 69 and 94.1 in Baseline and from 72.5 to 97.1 in Incremental model. Of the whole set of methods, Random Forest presented the best performance at all follow-ups [AUC-PR1: 94.1 (2.0); AUC-PR2: 91.2 (1.2); AUC-PR3: 97.1 (1.0); AUC-PR4: 96.5 (1.7)]. Logistic Regression performed well below Random Forest. The top-ranked predictors were common for both models in all follow-ups: birthweight, gestational age, maternal age, and length of hospital stay. Random Forest presented the highest capacity for prediction and provided interpretable predictors. Researchers involved in cohorts can benefit from our robust models to prepare for and prevent loss to follow-up by directing efforts toward individuals at higher risk.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Assessment of image quality on color fundus retinal images using the automatic retinal image analysis",
        "link": "https://www.nature.com/articles/s41598-022-13919-2",
        "publication_date": "21 Jun 2022",
        "abstract": "Image quality assessment is essential for retinopathy detection on color fundus retinal image. However, most studies focused on the classification of good and poor quality without considering the different types of poor quality. This study developed an automatic retinal image analysis (ARIA) method, incorporating transfer net ResNet50 deep network with the automatic features generation approach to automatically assess image quality, and distinguish eye-abnormality-associated-poor-quality from artefact-associated-poor-quality on color fundus retinal images. A total of 2434 retinal images, including 1439 good quality and 995 poor quality (483 eye-abnormality-associated-poor-quality and 512 artefact-associated-poor-quality), were used for training, testing, and 10-ford cross-validation. We also analyzed the external validation with the clinical diagnosis of eye abnormality as the reference standard to evaluate the performance of the method. The sensitivity, specificity, and accuracy for testing good quality against poor quality were 98.0%, 99.1%, and 98.6%, and for differentiating between eye-abnormality-associated-poor-quality and artefact-associated-poor-quality were 92.2%, 93.8%, and 93.0%, respectively. In external validation, our method achieved an area under the ROC curve of 0.997 for the overall quality classification and 0.915 for the classification of two types of poor quality. The proposed approach, ARIA, showed good performance in testing, 10-fold cross validation and external validation. This study provides a novel angle for image quality screening based on the different poor quality types and corresponding dealing methods. It suggested that the ARIA can be used as a screening tool in the preliminary stage of retinopathy grading by telemedicine or artificial intelligence analysis.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Increasing trend of radiographic features of knee osteoarthritis in rheumatoid arthritis patients before total knee arthroplasty",
        "link": "https://www.nature.com/articles/s41598-022-14440-2",
        "publication_date": "21 Jun 2022",
        "abstract": "To investigate the trend and factors related to the occurrence of osteoarthritis (OA)-like features on knee radiographs of rheumatoid arthritis (RA) patients undergoing total knee arthroplasty (TKA) in the recent decades. To classify antero-posterior knee radiographs into ‘RA’ and ‘OA-like RA’ groups, a deep learning model was developed by training the network using knee radiographs of end-stage arthropathy in RA patients obtained during 2002–2005 and in primary OA patients obtained during 2007–2009. We used this model to categorize 796 knee radiographs, which were recorded in RA patients before TKA during 2006–2020, into ‘OA-like RA’ and ‘RA’ groups. The annual ratio of ‘OA-like RA’ was investigated. Moreover, univariate and multivariate analyses were performed to identify the factors associated with the classification as OA-like RA using clinical data from 240 patients. The percentage of ‘OA-like RA’ had significant increasing trend from 20.9% in 2006 to 67.7% in 2020. Higher body mass index, use of biologics, and lower level of C-reactive protein were identified as independent factors for ‘OA-like RA’. An increasing trend of knee radiographs with OA-like features was observed in RA patients in the recent decades, which might be attributed to recent advances in pharmacotherapy.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Measuring collagen injury depth for burn severity determination using polarization sensitive optical coherence tomography",
        "link": "https://www.nature.com/articles/s41598-022-14326-3",
        "publication_date": "21 Jun 2022",
        "abstract": "Determining the optimal treatment course for a dermatologic burn wound requires knowledge of the wound’s severity, as quantified by the depth of thermal damage. In current clinical practice, burn depth is inferred based exclusively on superficial visual assessment, a method which is subject to substantial error rates in the classification of partial thickness (second degree) burns. Here, we present methods for direct, quantitative determination of the depth extent of injury to the dermal collagen matrix using polarization-sensitive optical coherence tomography (PS-OCT). By visualizing the depth-dependence of the degree of polarization of light in the tissue, rather than cumulative retardation, we enable direct and volumetric assessment of local collagen status. We further augment our PS-OCT measurements by visualizing adnexal structures such as hair follicles to relay overall dermal viability in the wounded region. Our methods, which we have validated ex vivo with matched histology, offer an information-rich tool for precise interrogation of burn wound severity and healing potential in both research and clinical settings.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    }
]