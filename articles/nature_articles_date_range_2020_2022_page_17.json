[
    {
        "title": "Personalized quantification of facial normality: a machine learning approach",
        "link": "https://www.nature.com/articles/s41598-020-78180-x",
        "publication_date": "07 Dec 2020",
        "abstract": "What is a normal face? A fundamental task for the facial reconstructive surgeon is to answer that question as it pertains to any given individual. Accordingly, it would be important to be able to place the facial appearance of a patient with congenital or acquired deformity numerically along their own continuum of normality, and to measure any surgical changes against such a personalized benchmark. This has not previously been possible. We have solved this problem by designing a computerized model that produces realistic, normalized versions of any given facial image, and objectively measures the perceptual distance between the raw and normalized facial image pair. The model is able to faithfully predict human scoring of facial normality. We believe this work represents a paradigm shift in the assessment of the human face, holding great promise for development as an objective tool for surgical planning, patient education, and as a means for clinical outcome measurement.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation",
        "link": "https://www.nature.com/articles/s41592-020-01008-z",
        "publication_date": "07 Dec 2020",
        "abstract": "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Feature replacement methods enable reliable home video analysis for machine learning detection of autism",
        "link": "https://www.nature.com/articles/s41598-020-76874-w",
        "publication_date": "04 Dec 2020",
        "abstract": "Autism Spectrum Disorder is a neuropsychiatric condition affecting 53 million children worldwide and for which early diagnosis is critical to the outcome of behavior therapies. Machine learning applied to features manually extracted from readily accessible videos (e.g., from smartphones) has the potential to scale this diagnostic process. However, nearly unavoidable variability in video quality can lead to missing features that degrade algorithm performance. To manage this uncertainty, we evaluated the impact of missing values and feature imputation methods on two previously published autism detection classifiers, trained on standard-of-care instrument scoresheets and tested on ratings of 140 children videos from YouTube. We compare the baseline method of listwise deletion to classic univariate and multivariate techniques. We also introduce a feature replacement method that, based on a score, selects a feature from an expanded dataset to fill-in the missing value. The replacement feature selected can be identical for all records (general) or automatically adjusted to the record considered (dynamic). Our results show that general and dynamic feature replacement methods achieve a higher performance than classic univariate and multivariate methods, supporting the hypothesis that algorithmic management can maintain the fidelity of video-based diagnostics in the face of missing values and variable video quality.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Saturation transfer properties of tumour xenografts derived from prostate cancer cell lines 22Rv1 and DU145",
        "link": "https://www.nature.com/articles/s41598-020-78353-8",
        "publication_date": "04 Dec 2020",
        "abstract": "Histopathology is currently the most reliable tool in assessing the aggressiveness and prognosis of solid tumours. However, developing non-invasive modalities for tumour evaluation remains crucial due to the side effects and complications caused by biopsy procedures. In this study, saturation transfer MRI was used to investigate the microstructural and metabolic properties of tumour xenografts in mice derived from the prostate cancer cell lines 22Rv1 and DU145, which express different aggressiveness. The magnetization transfer (MT) and chemical exchange saturation transfer (CEST) effects, which are associated with the microstructural and metabolic properties in biological tissue, respectively, were analyzed quantitatively and compared amongst different tumour types and regions. Histopathological staining was performed as a reference. Higher cellular density and metabolism expressed in more aggressive tumours (22Rv1) were associated with larger MT and CEST effects. High collagen content in the necrotic regions might explain their higher MT effects compared to tumour regions.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Forecasting the long-term trend of COVID-19 epidemic using a dynamic model",
        "link": "https://www.nature.com/articles/s41598-020-78084-w",
        "publication_date": "03 Dec 2020",
        "abstract": "The current outbreak of coronavirus disease 2019 (COVID-19) has recently been declared as a pandemic and spread over 200 countries and territories. Forecasting the long-term trend of the COVID-19 epidemic can help health authorities determine the transmission characteristics of the virus and take appropriate prevention and control strategies beforehand. Previous studies that solely applied traditional epidemic models or machine learning models were subject to underfitting or overfitting problems. We propose a new model named Dynamic-Susceptible-Exposed-Infective-Quarantined (D-SEIQ), by making appropriate modifications of the Susceptible-Exposed-Infective-Recovered (SEIR) model and integrating machine learning based parameter optimization under epidemiological rational constraints. We used the model to predict the long-term reported cumulative numbers of COVID-19 cases in China from January 27, 2020. We evaluated our model on officially reported confirmed cases from three different regions in China, and the results proved the effectiveness of our model in terms of simulating and predicting the trend of the COVID-19 outbreak. In China-Excluding-Hubei area within 7 days after the first public report, our model successfully and accurately predicted the long trend up to 40 days and the exact date of the outbreak peak. The predicted cumulative number (12,506) by March 10, 2020, was only 3·8% different from the actual number (13,005). The parameters obtained by our model proved the effectiveness of prevention and intervention strategies on epidemic control in China. The prediction results for five other countries suggested the external validity of our model. The integrated approach of epidemic and machine learning models could accurately forecast the long-term trend of the COVID-19 outbreak. The model parameters also provided insights into the analysis of COVID-19 transmission and the effectiveness of interventions in China.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Early prediction of neoadjuvant chemotherapy response for advanced breast cancer using PET/MRI image deep learning",
        "link": "https://www.nature.com/articles/s41598-020-77875-5",
        "publication_date": "03 Dec 2020",
        "abstract": "This study aimed to investigate the predictive efficacy of positron emission tomography/computed tomography (PET/CT) and magnetic resonance imaging (MRI) for the pathological response of advanced breast cancer to neoadjuvant chemotherapy (NAC). The breast PET/MRI image deep learning model was introduced and compared with the conventional methods. PET/CT and MRI parameters were evaluated before and after the first NAC cycle in patients with advanced breast cancer [n = 56; all women; median age, 49 (range 26–66) years]. The maximum standardized uptake value (SUVmax), metabolic tumor volume (MTV), and total lesion glycolysis (TLG) were obtained with the corresponding baseline values (SUV0, MTV0, and TLG0, respectively) and interim PET images (SUV1, MTV1, and TLG1, respectively). Mean apparent diffusion coefficients were obtained from baseline and interim diffusion MR images (ADC0 and ADC1, respectively). The differences between the baseline and interim parameters were measured (ΔSUV, ΔMTV, ΔTLG, and ΔADC). Subgroup analysis was performed for the HER2-negative and triple-negative groups. Datasets for convolutional neural network (CNN), assigned as training (80%) and test datasets (20%), were cropped from the baseline (PET0, MRI0) and interim (PET1, MRI1) images. Histopathologic responses were assessed using the Miller and Payne system, after three cycles of chemotherapy. Receiver operating characteristic curve analysis was used to assess the performance of the differentiating responders and non-responders. There were six responders (11%) and 50 non-responders (89%). The area under the curve (AUC) was the highest for ΔSUV at 0.805 (95% CI 0.677–0.899). The AUC was the highest for ΔSUV at 0.879 (95% CI 0.722–0.965) for the HER2-negative subtype. AUC improved following CNN application (SUV0:PET0 = 0.652:0.886, SUV1:PET1 = 0.687:0.980, and ADC1:MRI1 = 0.537:0.701), except for ADC0 (ADC0:MRI0 = 0.703:0.602). PET/MRI image deep learning model can predict pathological responses to NAC in patients with advanced breast cancer.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A residual dense network assisted sparse view reconstruction for breast computed tomography",
        "link": "https://www.nature.com/articles/s41598-020-77923-0",
        "publication_date": "03 Dec 2020",
        "abstract": "To develop and investigate a deep learning approach that uses sparse-view acquisition in dedicated breast computed tomography for radiation dose reduction, we propose a framework that combines 3D sparse-view cone-beam acquisition with a multi-slice residual dense network (MS-RDN) reconstruction. Projection datasets (300 views, full-scan) from 34 women were reconstructed using the FDK algorithm and served as reference. Sparse-view (100 views, full-scan) projection data were reconstructed using the FDK algorithm. The proposed MS-RDN uses the sparse-view and reference FDK reconstructions as input and label, respectively. Our MS-RDN evaluated with respect to fully sampled FDK reference yields superior performance, quantitatively and visually, compared to conventional compressed sensing methods and state-of-the-art deep learning based methods. The proposed deep learning driven framework can potentially enable low dose breast CT imaging.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Using machine learning tools to predict outcomes for emergency department intensive care unit patients",
        "link": "https://www.nature.com/articles/s41598-020-77548-3",
        "publication_date": "01 Dec 2020",
        "abstract": "The number of critically ill patients has increased globally along with the rise in emergency visits. Mortality prediction for critical patients is vital for emergency care, which affects the distribution of emergency resources. Traditional scoring systems are designed for all emergency patients using a classic mathematical method, but risk factors in critically ill patients have complex interactions, so traditional scoring cannot as readily apply to them. As an accurate model for predicting the mortality of emergency department critically ill patients is lacking, this study’s objective was to develop a scoring system using machine learning optimized for the unique case of critical patients in emergency departments. We conducted a retrospective cohort study in a tertiary medical center in Beijing, China. Patients over 16 years old were included if they were alive when they entered the emergency department intensive care unit system from February 2015 and December 2015. Mortality up to 7 days after admission into the emergency department was considered as the primary outcome, and 1624 cases were included to derive the models. Prospective factors included previous diseases, physiologic parameters, and laboratory results. Several machine learning tools were built for 7-day mortality using these factors, for which their predictive accuracy (sensitivity and specificity) was evaluated by area under the curve (AUC). The AUCs were 0.794, 0.840, 0.849 and 0.822 respectively, for the SVM, GBDT, XGBoost and logistic regression model. In comparison with the SAPS 3 model (AUC = 0.826), the discriminatory capability of the newer machine learning methods, XGBoost in particular, is demonstrated to be more reliable for predicting outcomes for emergency department intensive care unit patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting the need for intubation in the first 24 h after critical care admission using machine learning approaches",
        "link": "https://www.nature.com/articles/s41598-020-77893-3",
        "publication_date": "01 Dec 2020",
        "abstract": "Early and accurate prediction of the need for intubation may provide more time for preparation and increase safety margins by avoiding high risk late intubation. This study evaluates whether machine learning can predict the need for intubation within 24 h using commonly available bedside and laboratory parameters taken at critical care admission. We extracted data from 2 large critical care databases (MIMIC-III and eICU-CRD). Missing variables were imputed using autoencoder. Machine learning classifiers using logistic regression and random forest were trained using 60% of the data and tested using the remaining 40% of the data. We compared the performance of logistic regression and random forest models to predict intubation in critically ill patients. After excluding patients with limitations of therapy and missing data, we included 17,616 critically ill patients in this retrospective cohort. Within 24 h of admission, 2,292 patients required intubation, whilst 15,324 patients were not intubated. Blood gas parameters (PaO2, PaCO2, HCO3−), Glasgow Coma Score, respiratory variables (respiratory rate, SpO2), temperature, age, and oxygen therapy were used to predict intubation. Random forest had AUC 0.86 (95% CI 0.85–0.87) and logistic regression had AUC 0.77 (95% CI 0.76–0.78) for intubation prediction performance. Random forest model had sensitivity of 0.88 (95% CI 0.86–0.90) and specificity of 0.66 (95% CI 0.63–0.69), with good calibration throughout the range of intubation risks. The results showed that machine learning could predict the need for intubation in critically ill patients using commonly collected bedside clinical parameters and laboratory results. It may be used in real-time to help clinicians predict the need for intubation within 24 h of intensive care unit admission.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [
                "poisoning"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Transfer learning with chest X-rays for ER patient classification",
        "link": "https://www.nature.com/articles/s41598-020-78060-4",
        "publication_date": "01 Dec 2020",
        "abstract": "One of the challenges with urgent evaluation of patients with acute respiratory distress syndrome (ARDS) in the emergency room (ER) is distinguishing between cardiac vs infectious etiologies for their pulmonary findings. We conducted a retrospective study with the collected data of 171 ER patients. ER patient classification for cardiac and infection causes was evaluated with clinical data and chest X-ray image data. We show that a deep-learning model trained with an external image data set can be used to extract image features and improve the classification accuracy of a data set that does not contain enough image data to train a deep-learning model. An analysis of clinical feature importance was performed to identify the most important clinical features for ER patient classification. The current model is publicly available with an interface at the web link: http://nbttranslationalresearch.org/.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Network and pathway expansion of genetic disease associations identifies successful drug targets",
        "link": "https://www.nature.com/articles/s41598-020-77847-9",
        "publication_date": "01 Dec 2020",
        "abstract": "Genetic evidence of disease association has often been used as a basis for selecting of drug targets for complex common diseases. Likewise, the propagation of genetic evidence through gene or protein interaction networks has been shown to accurately infer novel disease associations at genes for which no direct genetic evidence can be observed. However, an empirical test of the utility of combining these approaches for drug discovery has been lacking. In this study, we examine genetic associations arising from an analysis of 648 UK Biobank GWAS and evaluate whether targets identified as proxies of direct genetic hits are enriched for successful drug targets, as measured by historical clinical trial data. We find that protein networks formed from specific functional linkages such as protein complexes and ligand–receptor pairs are suitable for even naïve guilt-by-association network propagation approaches. In addition, more sophisticated approaches applied to global protein–protein interaction networks and pathway databases, also successfully retrieve targets enriched for clinically successful drug targets. We conclude that network propagation of genetic evidence can be used for drug target identification.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "A clinically applicable deep-learning model for detecting intracranial aneurysm in computed tomography angiography images",
        "link": "https://www.nature.com/articles/s41467-020-19527-w",
        "publication_date": "30 Nov 2020",
        "abstract": "Intracranial aneurysm is a common life-threatening disease. Computed tomography angiography is recommended as the standard diagnosis tool; yet, interpretation can be time-consuming and challenging. We present a specific deep-learning-based model trained on 1,177 digital subtraction angiography verified bone-removal computed tomography angiography cases. The model has good tolerance to image quality and is tested with different manufacturers. Simulated real-world studies are conducted in consecutive internal and external cohorts, in which it achieves an improved patient-level sensitivity and lesion-level sensitivity compared to that of radiologists and expert neurosurgeons. A specific cohort of suspected acute ischemic stroke is employed and it is found that 99.0% predicted-negative cases can be trusted with high confidence, leading to a potential reduction in human workload. A prospective study is warranted to determine whether the algorithm could improve patients’ care in comparison to clinicians’ assessment.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Assessment of metastatic lymph nodes in head and neck squamous cell carcinomas using simultaneous 18F-FDG-PET and MRI",
        "link": "https://www.nature.com/articles/s41598-020-77740-5",
        "publication_date": "27 Nov 2020",
        "abstract": "In this study, we investigate the feasibility of using dynamic contrast enhanced magnetic resonance imaging (DCE-MRI), diffusion weighted imaging (DWI), and dynamic positron emission tomography (PET) for detection of metastatic lymph nodes in head and neck squamous cell carcinoma (HNSCC) cases. Twenty HNSCC patients scheduled for lymph node dissection underwent DCE-MRI, dynamic PET, and DWI using a PET-MR scanner within one week prior to their planned surgery. During surgery, resected nodes were labeled to identify their nodal levels and sent for routine clinical pathology evaluation. Quantitative parameters of metastatic and normal nodes were calculated from DCE-MRI (ve, vp, PS, Fp, Ktrans), DWI (ADC) and PET (Ki, K1, k2, k3) to assess if an individual or a combination of parameters can classify normal and metastatic lymph nodes accurately. There were 38 normal and 11 metastatic nodes covered by all three imaging methods and confirmed by pathology. 34% of all normal nodes had volumes greater than or equal to the smallest metastatic node while 4 normal nodes had SUV > 4.5. Among the MRI parameters, the median vp, Fp, PS, and Ktrans values of the metastatic lymph nodes were significantly lower (p = <0.05) than those of normal nodes. ve and ADC did not show any statistical significance. For the dynamic PET parameters, the metastatic nodes had significantly higher k3 (p value = 8.8 × 10−8) and Ki (p value = 5.3 × 10−8) than normal nodes. K1 and k2 did not show any statistically significant difference. Ki had the best separation with accuracy = 0.96 (sensitivity = 1, specificity = 0.95) using a cutoff of Ki = 5.3 × 10−3 mL/cm3/min, while k3 and volume had accuracy of 0.94 (sensitivity = 0.82, specificity = 0.97) and 0.90 (sensitivity = 0.64, specificity = 0.97) respectively. 100% accuracy can be achieved using a multivariate logistic regression model of MRI parameters after thresholding the data with Ki < 5.3 × 10−3 mL/cm3/min. The results of this preliminary study suggest that quantitative MRI may provide additional value in distinguishing metastatic nodes, particularly among small nodes, when used together with FDG-PET.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prognostic value of texture analysis from cardiac magnetic resonance imaging in patients with Takotsubo syndrome: a machine learning based proof-of-principle approach",
        "link": "https://www.nature.com/articles/s41598-020-76432-4",
        "publication_date": "25 Nov 2020",
        "abstract": "Cardiac magnetic resonance (CMR) imaging has become an important technique for non-invasive diagnosis of takotsubo syndrome (TTS). The long-term prognostic value of CMR imaging in TTS has not been fully elucidated yet. This study sought to evaluate the prognostic value of texture analysis (TA) based on CMR images in patients with TTS using machine learning. In this multicenter study (InterTAK Registry), we investigated CMR imaging data of 58 patients (56 women, mean age 68 ± 12 years) with TTS. CMR imaging was performed in the acute to subacute phase (median time after symptom onset 4 days) of TTS. TA of the left ventricle was performed using free-hand regions-of-interest in short axis late gadolinium-enhanced and on T2-weighted (T2w) images. A total of 608 TA features adding the parameters age, gender, and body mass index were included. Dimension reduction was performed removing TA features with poor intra-class correlation coefficients (ICC ≤ 0.6) and those being redundant (correlation matrix with Pearson correlation coefficient r > 0.8). Five common machine-learning classifiers (artificial neural network Multilayer Perceptron, decision tree J48, NaïveBayes, RandomForest, and Sequential Minimal Optimization) with tenfold cross-validation were applied to assess 5-year outcome including major adverse cardiac and cerebrovascular events (MACCE). Dimension reduction yielded 10 TA features carrying prognostic information, which were all based on T2w images. The NaïveBayes machine learning classifier showed overall best performance with a sensitivity of 82.9% (confidence interval (CI) 80–86.2), specificity of 83.7% (CI 75.7–92), and an area-under-the receiver operating characteristics curve of 0.88 (CI 0.83–0.92). This proof-of-principle study is the first to identify unique T2w-derived TA features that predict long-term outcome in patients with TTS. These features might serve as imaging prognostic biomarkers in TTS patients.",
        "conclusions": "In the present proof-of-principle study, we demonstrated that selected TA features, exclusively derived from T2w CMR images and identified through machine learning, have potential prognostic long-term value in patients with TTS. Thus, they may serve as novel imaging biomarkers for risk stratification in patients with TTS (Fig. 4).Figure 4Improving risk stratification in patients with takotsubo syndrome. Cardiac magnetic resonance imaging-derived texture analysis features, identified through machine learning algorithms, have a prognostic value in patients with takotsubo syndrome. Thus, these features might serve as novel imaging biomarkers for risk stratification in takotsubo syndrome.Full size image",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Detection and classification of intracranial haemorrhage on CT images using a novel deep-learning algorithm",
        "link": "https://www.nature.com/articles/s41598-020-77441-z",
        "publication_date": "25 Nov 2020",
        "abstract": "A novel deep-learning algorithm for artificial neural networks (ANNs), completely different from the back-propagation method, was developed in a previous study. The purpose of this study was to assess the feasibility of using the algorithm for the detection of intracranial haemorrhage (ICH) and the classification of its subtypes, without employing the convolutional neural network (CNN). For the detection of ICH with the summation of all the computed tomography (CT) images for each case, the area under the ROC curve (AUC) was 0.859, and the sensitivity and the specificity were 78.0% and 80.0%, respectively. Regarding ICH localisation, CT images were divided into 10 subdivisions based on the intracranial height. With the subdivision of 41–50%, the best diagnostic performance for detecting ICH was obtained with AUC of 0.903, the sensitivity of 82.5%, and the specificity of 84.1%. For the classification of the ICH to subtypes, the accuracy rate for subarachnoid haemorrhage (SAH) was considerably excellent at 91.7%. This study revealed that our approach can greatly reduce the ICH diagnosis time in an actual emergency situation with a fairly good diagnostic performance.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Retinal and circumpapillary nerve fiber layer thickness and associated factors in children",
        "link": "https://www.nature.com/articles/s41433-020-01313-z",
        "publication_date": "25 Nov 2020",
        "abstract": "To evaluate the distribution of macula and circumpapillary retina nerve fiber layer (cpRNFL) thickness and other associated factors among grade-1 primary school children in Lhasa using spectral-domain optical coherence tomography (SD-OCT).",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A detailed open access model of the PubMed literature",
        "link": "https://www.nature.com/articles/s41597-020-00749-y",
        "publication_date": "20 Nov 2020",
        "abstract": "Portfolio analysis is a fundamental practice of organizational leadership and is a necessary precursor of strategic planning. Successful application requires a highly detailed model of research options. We have constructed a model, the first of its kind, that accurately characterizes these options for the biomedical literature. The model comprises over 18 million PubMed documents from 1996–2019. Document relatedness was measured using a hybrid citation analysis + text similarity approach. The resulting 606.6 million document-to-document links were used to create 28,743 document clusters and an associated visual map. Clusters are characterized using metadata (e.g., phrases, MeSH) and over 20 indicators (e.g., funding, patent activity). The map and cluster-level data are embedded in Tableau to provide an interactive model enabling in-depth exploration of a research portfolio. Two example usage cases are provided, one to identify specific research opportunities related to coronavirus, and the second to identify research strengths of a large cohort of African American and Native American researchers at the University of Michigan Medical School.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Full wave 3D inverse scattering transmission ultrasound tomography in the presence of high contrast",
        "link": "https://www.nature.com/articles/s41598-020-76754-3",
        "publication_date": "19 Nov 2020",
        "abstract": "We present here a quantitative ultrasound tomographic method yielding a sub-mm resolution, quantitative 3D representation of tissue characteristics in the presence of high contrast media. This result is a generalization of previous work where high impedance contrast was not present and may provide a clinically and laboratory relevant, relatively inexpensive, high resolution imaging method for imaging in the presence of bone. This allows tumor, muscle, tendon, ligament or cartilage disease monitoring for therapy and general laboratory or clinical settings. The method has proven useful in breast imaging and is generalized here to high-resolution quantitative imaging in the presence of bone. The laboratory data are acquired in ~ 12 min and the reconstruction in ~ 24 min—approximately 200 times faster than previously reported simulations in the literature. Such fast reconstructions with real data require careful calibration, adequate data redundancy from a 2D array of 2048 elements and a paraxial approximation. The imaging results show that tissue surrounding the high impedance region is artifact free and has correct speed of sound at sub-mm resolution.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Push Button Population Health: The SMART/HL7 FHIR Bulk Data Access Application Programming Interface",
        "link": "https://www.nature.com/articles/s41746-020-00358-4",
        "publication_date": "19 Nov 2020",
        "abstract": "The 21st Century Cures Act requires that certified health information technology have an application programming interface (API) giving access to all data elements of a patient’s electronic health record, “without special effort”. In the spring of 2020, the Office of the National Coordinator of Health Information Technology (ONC) published a rule—21st Century Cures Act Interoperability, Information Blocking, and the ONC Health IT Certification Program—regulating the API requirement along with protections against information blocking. The rule specifies the SMART/HL7 FHIR Bulk Data Access API, which enables access to patient-level data across a patient population, supporting myriad use cases across healthcare, research, and public health ecosystems. The API enables “push button population health” in that core data elements can readily and standardly be extracted from electronic health records, enabling local, regional, and national-scale data-driven innovation.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Convolutional neuronal networks combined with X-ray phase-contrast imaging for a fast and observer-independent discrimination of cartilage and liver diseases stages",
        "link": "https://www.nature.com/articles/s41598-020-76937-y",
        "publication_date": "17 Nov 2020",
        "abstract": "We applied transfer learning using Convolutional Neuronal Networks to high resolution X-ray phase contrast computed tomography datasets and tested the potential of the systems to accurately classify Computed Tomography images of different stages of two diseases, i.e. osteoarthritis and liver fibrosis. The purpose is to identify a time-effective and observer-independent methodology to identify pathological conditions. Propagation-based X-ray phase contrast imaging WAS used with polychromatic X-rays to obtain a 3D visualization of 4 human cartilage plugs and 6 rat liver samples with a voxel size of 0.7 × 0.7 × 0.7 µm3 and 2.2 × 2.2 × 2.2 µm3, respectively. Images with a size of 224 × 224 pixels are used to train three pre-trained convolutional neuronal networks for data classification, which are the VGG16, the Inception V3, and the Xception networks. We evaluated the performance of the three systems in terms of classification accuracy and studied the effect of the variation of the number of inputs, training images and of iterations. The VGG16 network provides the highest classification accuracy when the training and the validation-test of the network are performed using data from the same samples for both the cartilage (99.8%) and the liver (95.5%) datasets. The Inception V3 and Xception networks achieve an accuracy of 84.7% (43.1%) and of 72.6% (53.7%), respectively, for the cartilage (liver) images. By using data from different samples for the training and validation-test processes, the Xception network provided the highest test accuracy for the cartilage dataset (75.7%), while for the liver dataset the VGG16 network gave the best results (75.4%). By using convolutional neuronal networks we show that it is possible to classify large datasets of biomedical images in less than 25 min on a 8 CPU processor machine providing a precise, robust, fast and observer-independent method for the discrimination/classification of different stages of osteoarthritis and liver diseases.",
        "conclusions": "In this work, we have investigated the possibility of using convolutional neuronal networks for the classification of healthy and pathological biological tissues considering two different biomedical cases: osteoarthritic cartilage and liver fibrosis. The evaluation of the samples was carried out by two experienced pathologists on the basis of the histological results, which served as golden standard.We have applied three CNNs (VGG16, Inception V3, and Xception networks) and compared their performances in terms of accuracy in the classification and the time needed for this calculation. The VGG16 network provided the highest accuracy, compared to the Inception V3 and Xception network in the analyzed cases. In the VGG16, the entire image is convoluted, whereas in the Inception V3 and the Xception networks, the image to be analyzed is split into different regions. This process of subdividing the images can lead to overfitting that causes poor performances of the networks when applied to data in the validation and testing phase. This fact determines the discrepancy between the training and the validation/testing accuracy curves for the Inception V3 and Xception networks. Additionally, this explains the discrepancy of our results with respect to the LSVRC competition.We also tested the effect of training the network with images of two cartilage samples (one healthy and one degenerated) and validated and tested with images of another cartilage sample: the testing accuracy decreased in all of the three networks. However, the Xception network was the one with the highest testing accuracy. This last fact shows that the Xception network model is the best generalized model, when splitting the dataset by sample type.Many different ways, such as additional fully connected layers and drop out layers, changing the optimizer algorithm or adjusting the learning rate, were used to reduce overfitting in the Xception and Inception V3 networks. The results we presented here were obtained after this optimization procedure (best accuracy and lowest overfitting); instead, the results of these intermediate optimization procedures were not reported.In the case of the cartilage, other computer-aided diagnosis tools are available, like texture analysis. This kind of analysis on cartilage PCI images for characterizing osteoarthritis, gives good results for both 2D images49 and 3D volumes50.The Inception V3 network with its inception modules is much faster for training, validation and testing than the other two networks. For the cartilage dataset, the Inception was 56.7% faster than the VGG16 network and 47.4% than the Xception. For the liver dataset, the Inception was 26.6% and 29.5% faster than the VGG16 and Xception networks, respectively. The reason of its higher performances lies in its unique inception module structure, which reduces the number of trainable weights and therefore speeds up the computation.With the data augmentation of the liver dataset, we could show that the networks converged faster when the number of input images was increased and therefore we needed fewer epochs. For the VGG16 network, the testing accuracy stayed approximately the same 95.5% and but the computational time increased by 23.5% from 34 min and 21 s to 42 min and 11 s because of increasing the number of input images by a factor of 4. We can conclude that more input data leads to a better accuracy and a faster convergence of the VGG network, but this does not come with shorter computational times.When we used data from different liver samples for the training and the testing of the networks, we achieved a decreased testing accuracy of all the networks, whereas the training accuracy increased. This result shows that an overfitting occurs and the networks do not generalize enough; to overcome this limitation, a larger number of samples should be used. The network presenting the best testing accuracy is the VGG16 with 75.38%, as in the calculation without the split based on samples. Both the Inception V3 and Xception networks testing accuracies were for this test below 50%; for this test and both networks did not perform well on liver data, in contrast to the cartilage data, were both networks had a testing accuracy above 68%.The testing accuracy strongly depends on the data splitting method that is used. If the slices for training and testing the CNN are extracted from the same sample, the data used in the two processes may look very similar and an overfitting of the networks during training may occur. In this case, the generalization of the CNN on new samples is unsettled and may be severely hindered.This study shows that the combination of advanced high sensitive X-ray imaging techniques (PCI) with newly available algorithms for data classification based on the neuronal network concept, could significantly support the discrimination between healthy-normal and pathological-abnormal conditions of biological tissues. The proof of concept of this methodology was here performed on small tissue samples (cylindrical bone/cartilage plugs of 7 mm in diameter). This method could be an important asset in the direction of the automation of diagnostic procedures. The application of CNNs to our datasets showed that these tools (in the specific case we identified the VGG16 network as the most accurate one) make it possible to analyze and classify sets of 9616 images of 224 × 224 pixels in less than 25 min providing a robust, fast and observer-independent method of diagnosis.",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Artificial neural networks and pathologists recognize basal cell carcinomas based on different histological patterns",
        "link": "https://www.nature.com/articles/s41379-020-00712-7",
        "publication_date": "13 Nov 2020",
        "abstract": "Recent advances in artificial intelligence, particularly in the field of deep learning, have enabled researchers to create compelling algorithms for medical image analysis. Histological slides of basal cell carcinomas (BCCs), the most frequent skin tumor, are accessed by pathologists on a daily basis and are therefore well suited for automated prescreening by neural networks for the identification of cancerous regions and swift tumor classification.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Comparing distress of mouse models for liver damage",
        "link": "https://www.nature.com/articles/s41598-020-76391-w",
        "publication_date": "13 Nov 2020",
        "abstract": "In order to foster animal welfare as well as high quality of research, many countries regulate by law that the severity of animal experiments must be evaluated and considered when performing biomedical research. It is well accepted that multiple parameters rather than a single readout parameter should be applied to describe animal distress or suffering. However, since the performance of readout parameters for animal distress is rarely defined and methods for multivariate analysis have only in rare cases been used, it is not known which methodology is most appropriate to define animal distress. This study used receiver operating characteristic curve analysis to quantify the performance of burrowing activity, body weight change and a distress score of mice after induction of liver damage by bile duct ligation or carbon tetrachloride. In addition, Support Vector Machine classification was used to compare the distress of these mouse models. This approach demonstrated that bile duct ligation causes much more distress than carbon tetrachloride-induced liver damage. This study, therefore, provides a prototype how to compare two animal models by considering several readout parameters. In the future these or similar methods for multivariate analysis will be necessary, when assessing and comparing the severity of animal models.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Context aware deep learning for brain tumor segmentation, subtype classification, and survival prediction using radiology images",
        "link": "https://www.nature.com/articles/s41598-020-74419-9",
        "publication_date": "12 Nov 2020",
        "abstract": "A brain tumor is an uncontrolled growth of cancerous cells in the brain. Accurate segmentation and classification of tumors are critical for subsequent prognosis and treatment planning. This work proposes context aware deep learning for brain tumor segmentation, subtype classification, and overall survival prediction using structural multimodal magnetic resonance images (mMRI). We first propose a 3D context aware deep learning, that considers uncertainty of tumor location in the radiology mMRI image sub-regions, to obtain tumor segmentation. We then apply a regular 3D convolutional neural network (CNN) on the tumor segments to achieve tumor subtype classification. Finally, we perform survival prediction using a hybrid method of deep learning and machine learning. To evaluate the performance, we apply the proposed methods to the Multimodal Brain Tumor Segmentation Challenge 2019 (BraTS 2019) dataset for tumor segmentation and overall survival prediction, and to the dataset of the Computational Precision Medicine Radiology-Pathology (CPM-RadPath) Challenge on Brain Tumor Classification 2019 for tumor classification. We also perform an extensive performance evaluation based on popular evaluation metrics, such as Dice score coefficient, Hausdorff distance at percentile 95 (HD95), classification accuracy, and mean square error. The results suggest that the proposed method offers robust tumor segmentation and survival prediction, respectively. Furthermore, the tumor classification results in this work is ranked at second place in the testing phase of the 2019 CPM-RadPath global challenge.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "External validation demonstrates limited clinical utility of the interpretable mortality prediction model for patients with COVID-19",
        "link": "https://www.nature.com/articles/s42256-020-00254-2",
        "publication_date": "12 Nov 2020",
        "abstract": "arising from Yan et al. Nature Machine Intelligence https://doi.org/10.1038/s42256-020-0180-7 (2020)",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of vascular aging based on smartphone acquired PPG signals",
        "link": "https://www.nature.com/articles/s41598-020-76816-6",
        "publication_date": "12 Nov 2020",
        "abstract": "Photoplethysmography (PPG) measured by smartphone has the potential for a large scale, non-invasive, and easy-to-use screening tool. Vascular aging is linked to increased arterial stiffness, which can be measured by PPG. We investigate the feasibility of using PPG to predict healthy vascular aging (HVA) based on two approaches: machine learning (ML) and deep learning (DL). We performed data preprocessing, including detrending, demodulating, and denoising on the raw PPG signals. For ML, ridge penalized regression has been applied to 38 features extracted from PPG, whereas for DL several convolutional neural networks (CNNs) have been applied to the whole PPG signals as input. The analysis has been conducted using the crowd-sourced Heart for Heart data. The prediction performance of ML using two features (AUC of 94.7%) – the a wave of the second derivative PPG and tpr, including four covariates, sex, height, weight, and smoking – was similar to that of the best performing CNN, 12-layer ResNet (AUC of 95.3%). Without having the heavy computational cost of DL, ML might be advantageous in finding potential biomarkers for HVA prediction. The whole workflow of the procedure is clearly described, and open software has been made available to facilitate replication of the results.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Profile of circulating microRNAs in myalgic encephalomyelitis and their relation to symptom severity, and disease pathophysiology",
        "link": "https://www.nature.com/articles/s41598-020-76438-y",
        "publication_date": "12 Nov 2020",
        "abstract": "Myalgic encephalomyelitis/chronic fatigue syndrome (ME/CFS) is a complex chronic disease, rooted in multi-system dysfunctions characterized by unexplained debilitating fatigue. Post-exertional malaise (PEM), defined as the exacerbation of the patient's symptoms following minimal physical or mental stress, is a hallmark of ME/CFS. While multiple case definitions exist, there is currently no well-established biomarkers or laboratory tests to diagnose ME/CFS. Our study aimed to investigate circulating microRNA expression in severely ill ME/CFS patients before and after an innovative stress challenge that stimulates PEM. Our findings highlight the differential expression of eleven microRNAs associated with a physiological response to PEM. The present study uncovers specific microRNA expression signatures associated with ME/CFS in response to PEM induction and reports microRNA expression patterns associated to specific symptom severities. The identification of distinctive microRNA expression signatures for ME/CFS through a provocation challenge is essential for the elucidation of the ME/CFS pathophysiology, and lead to accurate diagnoses, prevention measures, and effective treatment options.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Management and outcomes of the small pupil in cataract surgery: iris hooks, Malyugin ring or phenylephrine?",
        "link": "https://www.nature.com/articles/s41433-020-01277-0",
        "publication_date": "12 Nov 2020",
        "abstract": "To investigate outcomes for small versus large pupils in cataract surgery using different pupil expansion techniques.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Intra-individual variability of eGFR trajectories in early diabetic kidney disease and lack of performance of prognostic biomarkers",
        "link": "https://www.nature.com/articles/s41598-020-76773-0",
        "publication_date": "12 Nov 2020",
        "abstract": "Studies reporting on biomarkers aiming to predict adverse renal outcomes in patients with type 2 diabetes and kidney disease (DKD) conventionally define a surrogate endpoint either as a percentage of decrease of eGFR (e.g. ≥ 30%) or an absolute decline (e.g. ≥ 5 ml/min/year). The application of those study results in clinical practise however relies on the assumption of a linear and intra-individually stable progression of DKD. We studied 860 patients of the PROVALID study and 178 of an independent population with a relatively preserved eGFR at baseline and at least 5 years of follow up. Individuals with a detrimental prognosis were identified using various thresholds of a percentage or absolute decline of eGFR after each year of follow up. Next, we determined how many of the patients met the same criteria at other points in time. Interindividual eGFR decline was highly variable but in addition intra-individual eGFR trajectories also were frequently non-linear. For example, of all subjects reaching an endpoint defined as a decrease of eGFR by ≥ 30% between baseline and 3 years of follow up, only 60.3 and 45.2% lost at least the same amount between baseline and year 4 or 5. The results were similar when only patients on stable medication or subpopulations based on baseline eGFR or albuminuria status were analyzed or an eGFR decline of ≥ 5 ml/min/1.73m2/year was used. Identification of reliable biomarkers predicting adverse prognosis is a strong clinical need given the large interindividual variability of DKD progression. However, it is conceptually challenging in early DKD because of non-linear intra-individual eGFR trajectories. As a result, the performance of a prognostic biomarker may be accurate after a specific time of follow-up in a single population only.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predictive modeling of proliferative vitreoretinopathy using automated machine learning by ophthalmologists without coding experience",
        "link": "https://www.nature.com/articles/s41598-020-76665-3",
        "publication_date": "11 Nov 2020",
        "abstract": "We aimed to assess the feasibility of machine learning (ML) algorithm design to predict proliferative vitreoretinopathy (PVR) by ophthalmologists without coding experience using automated ML (AutoML). The study was a retrospective cohort study of 506 eyes who underwent pars plana vitrectomy for rhegmatogenous retinal detachment (RRD) by a single surgeon at a tertiary-care hospital between 2012 and 2019. Two ophthalmologists without coding experience used an interactive application in MATLAB to build and evaluate ML algorithms for the prediction of postoperative PVR using clinical data from the electronic health records. The clinical features associated with postoperative PVR were determined by univariate feature selection. The area under the curve (AUC) for predicting postoperative PVR was better for models that included pre-existing PVR as an input. The quadratic support vector machine (SVM) model built using all selected clinical features had an AUC of 0.90, a sensitivity of 63.0%, and a specificity of 97.8%. An optimized Naïve Bayes algorithm that did not include pre-existing PVR as an input feature had an AUC of 0.81, a sensitivity of 54.3%, and a specificity of 92.4%. In conclusion, the development of ML models for the prediction of PVR by ophthalmologists without coding experience is feasible. Input from a data scientist might still be needed to tackle class imbalance—a common challenge in ML classification using real-world clinical data.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Radiomics features of hippocampal regions in magnetic resonance imaging can differentiate medial temporal lobe epilepsy patients from healthy controls",
        "link": "https://www.nature.com/articles/s41598-020-76283-z",
        "publication_date": "11 Nov 2020",
        "abstract": "To investigative whether radiomics features in bilateral hippocampi from MRI can identify temporal lobe epilepsy (TLE). A total of 131 subjects with MRI (66 TLE patients [35 right and 31 left TLE] and 65 healthy controls [HC]) were allocated to training (n = 90) and test (n = 41) sets. Radiomics features (n = 186) from the bilateral hippocampi were extracted from T1-weighted images. After feature selection, machine learning models were trained. The performance of the classifier was validated in the test set to differentiate TLE from HC and ipsilateral TLE from HC. Identical processes were performed to differentiate right TLE from HC (training set, n = 69; test set; n = 31) and left TLE from HC (training set, n = 66; test set, n = 30). The best-performing model for identifying TLE showed an AUC, accuracy, sensitivity, and specificity of 0.848, 84.8%, 76.2%, and 75.0% in the test set, respectively. The best-performing radiomics models for identifying right TLE and left TLE subgroups showed AUCs of 0.845 and 0.840 in the test set, respectively. In addition, multiple radiomics features significantly correlated with neuropsychological test scores (false discovery rate-corrected p-values < 0.05). The radiomics model from hippocampus can be a potential biomarker for identifying TLE.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Generating high-fidelity synthetic patient data for assessing machine learning healthcare software",
        "link": "https://www.nature.com/articles/s41746-020-00353-9",
        "publication_date": "09 Nov 2020",
        "abstract": "There is a growing demand for the uptake of modern artificial intelligence technologies within healthcare systems. Many of these technologies exploit historical patient health data to build powerful predictive models that can be used to improve diagnosis and understanding of disease. However, there are many issues concerning patient privacy that need to be accounted for in order to enable this data to be better harnessed by all sectors. One approach that could offer a method of circumventing privacy issues is the creation of realistic synthetic data sets that capture as many of the complexities of the original data set (distributions, non-linear relationships, and noise) but that does not actually include any real patient data. While previous research has explored models for generating synthetic data sets, here we explore the integration of resampling, probabilistic graphical modelling, latent variable identification, and outlier analysis for producing realistic synthetic data based on UK primary care patient data. In particular, we focus on handling missingness, complex interactions between variables, and the resulting sensitivity analysis statistics from machine learning classifiers, while quantifying the risks of patient re-identification from synthetic datapoints. We show that, through our approach of integrating outlier analysis with graphical modelling and resampling, we can achieve synthetic data sets that are not significantly different from original ground truth data in terms of feature distributions, feature dependencies, and sensitivity analysis statistics when inferring machine learning classifiers. What is more, the risk of generating synthetic data that is identical or very similar to real patients is shown to be low.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of age and brachial-ankle pulse-wave velocity using ultra-wide-field pseudo-color images by deep learning",
        "link": "https://www.nature.com/articles/s41598-020-76513-4",
        "publication_date": "09 Nov 2020",
        "abstract": "This study examined whether age and brachial-ankle pulse-wave velocity (baPWV) can be predicted with ultra-wide-field pseudo-color (UWPC) images using deep learning (DL). We examined 170 UWPC images of both eyes of 85 participants (40 men and 45 women, mean age: 57.5 ± 20.9 years). Three types of images were included (total, central, and peripheral) and analyzed by k-fold cross-validation (k = 5) using Visual Geometry Group-16. After bias was eliminated using the generalized linear mixed model, the standard regression coefficients (SRCs) between actual age and baPWV and predicted age and baPWV from the UWPC images by the neural network were calculated, and the prediction accuracies of the DL model for age and baPWV were examined. The SRC between actual age and predicted age by the neural network was 0.833 for all images, 0.818 for central images, and 0.649 for peripheral images (all P < 0.001) and between the actual baPWV and the predicted baPWV was 0.390 for total images, 0.419 for central images, and 0.312 for peripheral images (all P < 0.001). These results show the potential prediction capability of DL for age and vascular aging and could be useful for disease prevention and early treatment.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "MLL4-associated condensates counterbalance Polycomb-mediated nuclear mechanical stress in Kabuki syndrome",
        "link": "https://www.nature.com/articles/s41588-020-00724-8",
        "publication_date": "09 Nov 2020",
        "abstract": "The genetic elements required to tune gene expression are partitioned in active and repressive nuclear condensates. Chromatin compartments include transcriptional clusters whose dynamic establishment and functioning depend on multivalent interactions occurring among transcription factors, cofactors and basal transcriptional machinery. However, how chromatin players contribute to the assembly of transcriptional condensates is poorly understood. By interrogating the effect of KMT2D (also known as MLL4) haploinsufficiency in Kabuki syndrome, we found that mixed lineage leukemia 4 (MLL4) contributes to the assembly of transcriptional condensates through liquid–liquid phase separation. MLL4 loss of function impaired Polycomb-dependent chromatin compartmentalization, altering the nuclear architecture. By releasing the nuclear mechanical stress through inhibition of the mechanosensor ATR, we re-established the mechanosignaling of mesenchymal stem cells and their commitment towards chondrocytes both in vitro and in vivo. This study supports the notion that, in Kabuki syndrome, the haploinsufficiency of MLL4 causes an altered functional partitioning of chromatin, which determines the architecture and mechanical properties of the nucleus.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "MobiDetails: online DNA variants interpretation",
        "link": "https://www.nature.com/articles/s41431-020-00755-z",
        "publication_date": "07 Nov 2020",
        "abstract": "MobiDetails is an expert tool, online application which gathers useful data for the interpretation of DNA variants in the context of molecular diagnosis. It brings together in a single tool many sources of data, such as population genetics, various kinds of predictors, Human Genome Variation Society (HGVS) nomenclatures, curated databases, and access to various annotations. Accurate interpretation of DNA variants is crucial and can impact the patient care or have familial outcomes (prenatal diagnosis). Its importance will increase in the coming years with the expansion of the personalized medicine. MobiDetails is specifically designed to help with this task. Exonic or intronic substitutions and small insertions/deletions related to more than 18,000 human genes are easily submitted and annotated in real-time. It is a responsive website that can be accessed using mobiles or tablets during medical staff meetings. MobiDetails is based on publicly available resources, does not include any specific data on patients or phenotypes, and is freely available for academic use at https://mobidetails.iurc.montp.inserm.fr/MD/.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Clustering of Alzheimer’s and Parkinson’s disease based on genetic burden of shared molecular mechanisms",
        "link": "https://www.nature.com/articles/s41598-020-76200-4",
        "publication_date": "05 Nov 2020",
        "abstract": "One of the visions of precision medicine has been to re-define disease taxonomies based on molecular characteristics rather than on phenotypic evidence. However, achieving this goal is highly challenging, specifically in neurology. Our contribution is a machine-learning based joint molecular subtyping of Alzheimer’s (AD) and Parkinson’s Disease (PD), based on the genetic burden of 15 molecular mechanisms comprising 27 proteins (e.g. APOE) that have been described in both diseases. We demonstrate that our joint AD/PD clustering using a combination of sparse autoencoders and sparse non-negative matrix factorization is reproducible and can be associated with significant differences of AD and PD patient subgroups on a clinical, pathophysiological and molecular level. Hence, clusters are disease-associated. To our knowledge this work is the first demonstration of a mechanism based stratification in the field of neurodegenerative diseases. Overall, we thus see this work as an important step towards a molecular mechanism-based taxonomy of neurological disorders, which could help in developing better targeted therapies in the future by going beyond classical phenotype based disease definitions.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of mortality in severe acute malnutrition in hospitalized children by faecal volatile organic compound analysis: proof of concept",
        "link": "https://www.nature.com/articles/s41598-020-75515-6",
        "publication_date": "05 Nov 2020",
        "abstract": "Children with severe acute malnutrition (SAM) display immature, altered gut microbiota and have a high mortality risk. Faecal volatile organic compounds (VOCs) reflect the microbiota composition and may provide insight into metabolic dysfunction that occurs in SAM. Here we determine whether analysis of faecal VOCs could identify children with SAM with increased risk of mortality. VOC profiles from children who died within six days following admission were compared to those who were discharged alive using machine learning algorithms. VOC profiles of children who died could be separated from those who were discharged with fair accuracy (AUC) = 0.71; 95% CI 0.59–0.87; P = 0.004). We present the first study showing differences in faecal VOC profiles between children with SAM who survived and those who died. VOC analysis holds potential to help discover metabolic pathways within the intestinal microbiome with causal association with mortality and target treatments in children with SAM.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Mucosal microbiota and gene expression are associated with long-term remission after discontinuation of adalimumab in ulcerative colitis",
        "link": "https://www.nature.com/articles/s41598-020-76175-2",
        "publication_date": "05 Nov 2020",
        "abstract": "Given that sustained remission is the ultimate treatment goal in the management of patients with ulcerative colitis (UC), the decision to stop anti-tumor necrosis factor (anti-TNF) treatment in UC patients is difficult. The aim of this study was to evaluate mucosal microbiota and gene expression profiles associated with long-term remission after discontinuation of anti-TNF therapy. In nine UC patients who received anti-TNF therapy for 6 months, microbiota isolated from uninflamed mucosae and gene expression in inflamed and uninflamed mucosae were investigated at week 0 and at week 24. At treatment initiation, Fusobacterium sp. and Veillonella dispar were over-represented in the relapse group compared with the non-relapse group. After treatment, Dorea sp. and Lachnospira sp. were over-represented in the non-relapse group. In the relapse group only, a significant shift in gut bacterial community composition was found between week 0 and week 24. Gene expression of ALIX (PDCD6IP) and SLC9A3 was significantly higher in the non-relapse group than in the relapse group. Lastly, we used machine learning methods to identify relevant gene signatures associated with sustained remission. Statistical analyses of microbiota and expression profiles revealed differences between UC patients who did or did not keep remission after the discontinuation of TNF inhibitors.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Deep learning classification of early normal-tension glaucoma and glaucoma suspects using Bruch’s membrane opening-minimum rim width and RNFL",
        "link": "https://www.nature.com/articles/s41598-020-76154-7",
        "publication_date": "04 Nov 2020",
        "abstract": "We aimed to classify early normal-tension glaucoma (NTG) and glaucoma suspect (GS) using Bruch’s membrane opening-minimum rim width (BMO-MRW), peripapillary retinal nerve fiber layer (RNFL), and the color classification of RNFL based on a deep-learning model. Discriminating early-stage glaucoma and GS is challenging and a deep-learning model may be helpful to clinicians. NTG accounts for an average 77% of open-angle glaucoma in Asians. BMO-MRW is a new structural parameter that has advantages in assessing neuroretinal rim tissue more accurately than conventional parameters. A dataset consisted of 229 eyes out of 277 GS and 168 eyes of 285 patients with early NTG. A deep-learning algorithm was developed to discriminate between GS and early NTG using a training set, and its accuracy was validated in the testing dataset using the area under the curve (AUC) of the receiver operating characteristic curve (ROC). The deep neural network model (DNN) achieved highest diagnostic performance, with an AUC of 0.966 (95%confidence interval 0.929–1.000) in classifying either GS or early NTG, while AUCs of 0.927–0.947 were obtained by other machine-learning models. The performance of the DNN model considering all three OCT-based parameters was the highest (AUC 0.966) compared to the combinations of just two parameters. As a single parameter, BMO-MRW (0.959) performed better than RNFL alone (0.914).",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The study of automatic machine learning base on radiomics of non-focus area in the first chest CT of different clinical types of COVID-19 pneumonia",
        "link": "https://www.nature.com/articles/s41598-020-76141-y",
        "publication_date": "03 Nov 2020",
        "abstract": "To explore the possibility of predicting the clinical types of Corona-Virus-Disease-2019 (COVID-19) pneumonia by analyzing the non-focus area of the lung in the first chest CT image of patients with COVID-19 by using automatic machine learning (Auto-ML). 136 moderate and 83 severe patients were selected from the patients with COVID-19 pneumonia. The clinical and laboratory data were collected for statistical analysis. The texture features of the Non-focus area of the first chest CT of patients with COVID-19 pneumonia were extracted, and then the classification model of the first chest CT of COVID-19 pneumonia was constructed by using these texture features based on the Auto-ML method of radiomics, The area under curve(AUC), true positive rate(TPR), true negative rate (TNR), positive predictive value(PPV) and negative predictive value (NPV) of the operating characteristic curve (ROC) were used to evaluate the accuracy of the first chest CT image classification model in patients with COVID-19 pneumonia. The TPR, TNR, PPV, NPV and AUC of the training cohort and test cohort of the moderate group and the control group, the severe group and the control group, the moderate group and the severe group were all greater than 95% and 0.95 respectively. The non-focus area of the first CT image of COVID-19 pneumonia has obvious difference in different clinical types. The AUTO-ML classification model of Radiomics based on this difference can be used to predict the clinical types of COVID-19 pneumonia.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "The POLD1R689W variant increases the sensitivity of colorectal cancer cells to ATR and CHK1 inhibitors",
        "link": "https://www.nature.com/articles/s41598-020-76033-1",
        "publication_date": "03 Nov 2020",
        "abstract": "Error fetching abstract: 'NoneType' object has no attribute 'lower'",
        "conclusions": "Conclusions not available",
        "ml_techniques": [],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Use of machine learning to classify adult ADHD and other conditions based on the Conners’ Adult ADHD Rating Scales",
        "link": "https://www.nature.com/articles/s41598-020-75868-y",
        "publication_date": "02 Nov 2020",
        "abstract": "A reliable diagnosis of adult Attention Deficit/Hyperactivity Disorder (ADHD) is challenging as many of the symptoms of ADHD resemble symptoms of other disorders. ADHD is associated with gambling disorder and obesity, showing overlaps of about 20% with each diagnosis. It is important for clinical practice to differentiate between conditions displaying similar symptoms via established diagnostic instruments. Applying the LightGBM algorithm in machine learning, we were able to differentiate subjects with ADHD, obesity, problematic gambling, and a control group using all 26 items of the Conners’ Adult ADHD Rating Scales (CAARS-S: S) with a global accuracy of .80; precision (positive predictive value) ranged between .78 (gambling) and .92 (obesity), recall (sensitivity) between .58 for obesity and .87 for ADHD. Models with the best 5 and best 10 items resulted in less satisfactory fits. The CAARS-S seems to be a promising instrument to be applied in clinical practice also for multiclassifying disorders displaying symptoms resembling ADHD.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of amyloid β PET positivity using machine learning in patients with suspected cerebral amyloid angiopathy markers",
        "link": "https://www.nature.com/articles/s41598-020-75664-8",
        "publication_date": "02 Nov 2020",
        "abstract": "Amyloid-β(Aβ) PET positivity in patients with suspected cerebral amyloid angiopathy (CAA) MRI markers is predictive of a worse cognitive trajectory, and it provides insights into the underlying vascular pathology (CAA vs. hypertensive angiopathy) to facilitate prognostic prediction and appropriate treatment decisions. In this study, we applied two interpretable machine learning algorithms, gradient boosting machine (GBM) and random forest (RF), to predict Aβ PET positivity in patients with CAA MRI markers. In the GBM algorithm, the number of lobar cerebral microbleeds (CMBs), deep CMBs, lacunes, CMBs in dentate nuclei, and age were ranked as the most influential to predict Aβ positivity. In the RF algorithm, the absence of diabetes was additionally chosen. Cut-off values of the above variables predictive of Aβ positivity were as follows: (1) the number of lobar CMBs > 16.4(GBM)/14.3(RF), (2) no deep CMBs(GBM/RF), (3) the number of lacunes > 7.4(GBM/RF), (4) age > 74.3(GBM)/64(RF), (5) no CMBs in dentate nucleus(GBM/RF). The classification performances based on the area under the receiver operating characteristic curve were 0.83 in GBM and 0.80 in RF. Our study demonstrates the utility of interpretable machine learning in the clinical setting by quantifying the relative importance and cutoff values of predictive variables for Aβ positivity in patients with suspected CAA markers.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Optical coherence tomography-based deep-learning model for detecting central serous chorioretinopathy",
        "link": "https://www.nature.com/articles/s41598-020-75816-w",
        "publication_date": "02 Nov 2020",
        "abstract": "Central serous chorioretinopathy (CSC) is a common condition characterized by serous detachment of the neurosensory retina at the posterior pole. We built a deep learning system model to diagnose CSC, and distinguish chronic from acute CSC using spectral domain optical coherence tomography (SD-OCT) images. Data from SD-OCT images of patients with CSC and a control group were analyzed with a convolutional neural network. Sensitivity, specificity, accuracy, and area under the receiver operating characteristic curve (AUROC) were used to evaluate the model. For CSC diagnosis, our model showed an accuracy, sensitivity, and specificity of 93.8%, 90.0%, and 99.1%, respectively; AUROC was 98.9% (95% CI, 0.983–0.995); and its diagnostic performance was comparable with VGG-16, Resnet-50, and the diagnoses of five different ophthalmologists. For distinguishing chronic from acute cases, the accuracy, sensitivity, and specificity were 97.6%, 100.0%, and 92.6%, respectively; AUROC was 99.4% (95% CI, 0.985–1.000); performance was better than VGG-16 and Resnet-50, and was as good as the ophthalmologists. Our model performed well when diagnosing CSC and yielded highly accurate results when distinguishing between acute and chronic cases. Thus, automated deep learning system algorithms could play a role independent of human experts in the diagnosis of CSC.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Performance and clinical utility of supervised machine-learning approaches in detecting familial hypercholesterolaemia in primary care",
        "link": "https://www.nature.com/articles/s41746-020-00349-5",
        "publication_date": "30 Oct 2020",
        "abstract": "Familial hypercholesterolaemia (FH) is a common inherited disorder, causing lifelong elevated low-density lipoprotein cholesterol (LDL-C). Most individuals with FH remain undiagnosed, precluding opportunities to prevent premature heart disease and death. Some machine-learning approaches improve detection of FH in electronic health records, though clinical impact is under-explored. We assessed performance of an array of machine-learning approaches for enhancing detection of FH, and their clinical utility, within a large primary care population. A retrospective cohort study was done using routine primary care clinical records of 4,027,775 individuals from the United Kingdom with total cholesterol measured from 1 January 1999 to 25 June 2019. Predictive accuracy of five common machine-learning algorithms (logistic regression, random forest, gradient boosting machines, neural networks and ensemble learning) were assessed for detecting FH. Predictive accuracy was assessed by area under the receiver operating curves (AUC) and expected vs observed calibration slope; with clinical utility assessed by expected case-review workload and likelihood ratios. There were 7928 incident diagnoses of FH. In addition to known clinical features of FH (raised total cholesterol or LDL-C and family history of premature coronary heart disease), machine-learning (ML) algorithms identified features such as raised triglycerides which reduced the likelihood of FH. Apart from logistic regression (AUC, 0.81), all four other ML approaches had similarly high predictive accuracy (AUC > 0.89). Calibration slope ranged from 0.997 for gradient boosting machines to 1.857 for logistic regression. Among those screened, high probability cases requiring clinical review varied from 0.73% using ensemble learning to 10.16% using deep learning, but with positive predictive values of 15.5% and 2.8% respectively. Ensemble learning exhibited a dominant positive likelihood ratio (45.5) compared to all other ML models (7.0–14.4). Machine-learning models show similar high accuracy in detecting FH, offering opportunities to increase diagnosis. However, the clinical case-finding workload required for yield of cases will differ substantially between models.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Deep learning from “passive feeding” to “selective eating” of real-world data",
        "link": "https://www.nature.com/articles/s41746-020-00350-y",
        "publication_date": "30 Oct 2020",
        "abstract": "Artificial intelligence (AI) based on deep learning has shown excellent diagnostic performance in detecting various diseases with good-quality clinical images. Recently, AI diagnostic systems developed from ultra-widefield fundus (UWF) images have become popular standard-of-care tools in screening for ocular fundus diseases. However, in real-world settings, these systems must base their diagnoses on images with uncontrolled quality (“passive feeding”), leading to uncertainty about their performance. Here, using 40,562 UWF images, we develop a deep learning–based image filtering system (DLIFS) for detecting and filtering out poor-quality images in an automated fashion such that only good-quality images are transferred to the subsequent AI diagnostic system (“selective eating”). In three independent datasets from different clinical institutions, the DLIFS performed well with sensitivities of 96.9%, 95.6% and 96.6%, and specificities of 96.6%, 97.9% and 98.8%, respectively. Furthermore, we show that the application of our DLIFS significantly improves the performance of established AI diagnostic systems in real-world settings. Our work demonstrates that “selective eating” of real-world data is necessary and needs to be considered in the development of image-based AI systems.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Kinetics of SARS-CoV-2 positivity of infected and recovered patients from a single center",
        "link": "https://www.nature.com/articles/s41598-020-75629-x",
        "publication_date": "29 Oct 2020",
        "abstract": "Recurrence of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) positive detection in infected but recovered individuals has been reported. Patients who have recovered from coronavirus disease 2019 (COVID-19) could profoundly impact the health care system. We sought to define the kinetics and relevance of PCR-positive recurrence during recovery from acute COVID-19 to better understand risks for prolonged infectivity and reinfection. A series of 414 patients with confirmed SARS-Cov-2 infection, at The Second Affiliated Hospital of Southern University of Science and Technology in Shenzhen, China from January 11 to April 23, 2020. Statistical analyses were performed of the clinical, laboratory, radiologic image, medical treatment, and clinical course of admission/quarantine/readmission data, and a recurrence predictive algorithm was developed. 16.7% recovered patients with PCR positive recurring one to three times, despite being in strict quarantine. Younger patients with mild pulmonary respiratory syndrome had higher risk of PCR positivity recurrence. The recurrence prediction model had an area under the ROC curve of 0.786. This case series provides characteristics of patients with recurrent SARS-CoV-2 positivity. Use of a prediction algorithm may identify patients at high risk of recurrent SARS-CoV-2 positivity and help to establish protocols for health policy.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting stroke severity with a 3-min recording from the Muse portable EEG system for rapid diagnosis of stroke",
        "link": "https://www.nature.com/articles/s41598-020-75379-w",
        "publication_date": "28 Oct 2020",
        "abstract": "In this study, we demonstrated the use of low-cost portable electroencephalography (EEG) as a method for prehospital stroke diagnosis. We used a portable EEG system to record data from 25 participants, 16 had acute ischemic stroke events, and compared the results to age-matched controls that included stroke mimics. Delta/alpha ratio (DAR), (delta + theta)/(alpha + beta) ratio (DBATR) and pairwise-derived Brain Symmetry Index (pdBSI) were investigated, as well as head movement using the on-board accelerometer and gyroscope. We then used machine learning to distinguish between different subgroups. DAR and DBATR increased in ischemic stroke patients with increasing stroke severity (p = 0.0021, partial η2 = 0.293; p = 0.01, partial η2 = 0.234). Also, pdBSI decreased in low frequencies and increased in high frequencies in patients who had a stroke (p = 0.036, partial η2 = 0.177). Using classification trees, we were able to distinguish moderate to severe stroke patients and from minor stroke and controls, with a 63% sensitivity, 86% specificity and accuracy of 76%. There are significant differences in DAR, DBATR, and pdBSI between patients with ischemic stroke when compared to controls, and these effects scale with severity. We have shown the utility of a low-cost portable EEG system to aid in patient triage and diagnosis as an early detection tool.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Personalized prediction of delayed graft function for recipients of deceased donor kidney transplants with machine learning",
        "link": "https://www.nature.com/articles/s41598-020-75473-z",
        "publication_date": "27 Oct 2020",
        "abstract": "Machine learning (ML) has shown its potential to improve patient care over the last decade. In organ transplantation, delayed graft function (DGF) remains a major concern in deceased donor kidney transplantation (DDKT). To this end, we harnessed ML to build personalized prognostic models to predict DGF. Registry data were obtained on adult DDKT recipients for model development (n = 55,044) and validation (n = 6176). Incidence rates of DGF were 25.1% and 26.3% for the development and validation sets, respectively. Twenty-six predictors were identified via recursive feature elimination with random forest. Five widely-used ML algorithms—logistic regression (LR), elastic net, random forest, artificial neural network (ANN), and extreme gradient boosting (XGB) were trained and compared with a baseline LR model fitted with previously identified risk factors. The new ML models, particularly ANN with the area under the receiver operating characteristic curve (ROC-AUC) of 0.732 and XGB with ROC-AUC of 0.735, exhibited superior performance to the baseline model (ROC-AUC = 0.705). This study demonstrates the use of ML as a viable strategy to enable personalized risk quantification for medical applications. If successfully implemented, our models may aid in both risk quantification for DGF prevention clinical trials and personalized clinical decision making.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning for endoleak detection after endovascular aortic repair",
        "link": "https://www.nature.com/articles/s41598-020-74936-7",
        "publication_date": "27 Oct 2020",
        "abstract": "Diagnosis of endoleak following endovascular aortic repair (EVAR) relies on manual review of multi-slice CT angiography (CTA) by physicians which is a tedious and time-consuming process that is susceptible to error. We evaluate the use of a deep neural network for the detection of endoleak on CTA for post-EVAR patients using a novel data efficient training approach. 50 CTAs and 20 CTAs with and without endoleak respectively were identified based on gold standard interpretation by a cardiovascular subspecialty radiologist. The Endoleak Augmentor, a custom designed augmentation method, provided robust training for the machine learning (ML) model. Predicted segmentation maps underwent post-processing to determine the presence of endoleak. The model was tested against 3 blinded general radiologists and 1 blinded subspecialist using a held-out subset (10 positive endoleak CTAs, 10 control CTAs). Model accuracy, precision and recall for endoleak diagnosis were 95%, 90% and 100% relative to reference subspecialist interpretation (AUC = 0.99). Accuracy, precision and recall was 70/70/70% for generalist1, 50/50/90% for generalist2, and 90/83/100% for generalist3. The blinded subspecialist had concordant interpretations for all test cases compared with the reference. In conclusion, our ML-based approach has similar performance for endoleak diagnosis relative to subspecialists and superior performance compared with generalists.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "TzanckNet: a convolutional neural network to identify cells in the cytology of erosive-vesiculobullous diseases",
        "link": "https://www.nature.com/articles/s41598-020-75546-z",
        "publication_date": "27 Oct 2020",
        "abstract": "Tzanck smear test is a low-cost, rapid and reliable tool which can be used for the diagnosis of many erosive-vesiculobullous, tumoral and granulomatous diseases. Currently its use is limited mainly due to lack of experience in interpretation of the smears. We developed a deep learning model, TzanckNet, that can identify cells in Tzanck smear test findings. TzanckNet was trained on a retrospective development dataset of 2260 Tzanck smear images collected between December 2006 and December 2019. The finalized model was evaluated using a prospective validation dataset of 359 Tzanck smear images collected from 15 patients during January 2020. It is designed to recognize six cell types (acantholytic cells, eosinophils, hypha, multinucleated giant cells, normal keratinocytes and tadpole cells). For 359 images and 6 cell types, TzanckNet made 2154 predictions. The accuracy was 94.3% (95% CI 93.4–95.3), the sensitivity was 83.7% (95% CI 80.3–87.0) and the specificity was 97.3% (95% CI 96.5–98.1). The area under the receiver operating characteristic curve was 0.974. Our results show that TzanckNet has the potential to lower the experience barrier needed to use this test, broadening its user base, and hence improving patient well-being.",
        "conclusions": "Tzanck smear test is a valuable but underappreciated diagnostic tool. This work introduced TzanckNet, a machine learning model that can analyze Tzanck smear findings with high accuracy. It can be used as a clinical decision support system as well as a training tool for new physicians. It has the potential to spread the use of Tzanck smear test, decrease the number of biopsies, prevent unnecessarily long antibiotic treatments, help early diagnoses for fatal diseases, decrease costs, and thus improve patient well-being.",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    }
]