[
    {
        "title": "Comorbidity clusters associated with newly treated type 2 diabetes mellitus: a Bayesian nonparametric analysis",
        "link": "https://www.nature.com/articles/s41598-022-24217-2",
        "publication_date": "30 Nov 2022",
        "abstract": "Type 2 diabetes mellitus (T2DM) is associated with the development of chronic comorbidities, which can lead to high drug utilization and adverse events. We aimed to identify common comorbidity clusters and explore the progression over time in newly treated T2DM patients. The IQVIA Medical Research Data incorporating data from THIN, a Cegedim database of anonymized electronic health records, was used to identify all patients with a first-ever prescription for a non-insulin antidiabetic drug (NIAD) between January 2006 and December 2019. We selected 58 chronic comorbidities of interest and used Bayesian nonparametric models to identify disease clusters and model their progression over time. Among the 175,383 eligible T2DM patients, we identified the 20 most frequent comorbidity clusters, which were comprised of 14 latent features (LFs). Each LF was associated with a primary disease (e.g., 98% of patients in cluster 2, characterized by LF2, had congestive heart failure [CHF]). The presence of certain LFs increased the probability of having another LF active. For example, LF2 (CHF) frequently appeared with LFs related to chronic kidney disease (CKD). Over time, the clusters associated with cardiovascular diseases, such as CHF, progressed rapidly. Moreover, the onset of certain diseases led to further complications. Our models identified established T2DM complications and previously unknown connections, thus, highlighting the potential for Bayesian nonparametric models to characterize complex comorbidity patterns.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Brain single cell transcriptomic profiles in episodic memory phenotypes associated with temporal lobe epilepsy",
        "link": "https://www.nature.com/articles/s41525-022-00339-4",
        "publication_date": "29 Nov 2022",
        "abstract": "Memory dysfunction is prevalent in temporal lobe epilepsy (TLE), but little is known about the underlying molecular etiologies. Single-nucleus RNA sequencing technology was used to examine differences in cellular heterogeneity among left (language-dominant) temporal neocortical tissues from patients with TLE with (n = 4) or without (n = 2) impairment in verbal episodic memory. We observed marked cell heterogeneity between memory phenotypes and identified numerous differentially expressed genes across all brain cell types. The most notable differences were observed in glutamatergic (excitatory) and GABAergic (inhibitory) neurons with an overrepresentation of genes associated with long-term potentiation, long-term depression, and MAPK signaling, processes known to be essential for episodic memory formation.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Low intensity repetitive transcranial magnetic stimulation modulates brain-wide functional connectivity to promote anti-correlated c-Fos expression",
        "link": "https://www.nature.com/articles/s41598-022-24934-8",
        "publication_date": "29 Nov 2022",
        "abstract": "Repetitive transcranial magnetic stimulation (rTMS) induces action potentials to induce plastic changes in the brain with increasing evidence for the therapeutic importance of brain-wide functional network effects of rTMS; however, the influence of sub-action potential threshold (low-intensity; LI-) rTMS on neuronal activity is largely unknown. We investigated whether LI-rTMS modulates neuronal activity and functional connectivity and also specifically assessed modulation of parvalbumin interneuron activity. We conducted a brain-wide analysis of c-Fos, a marker for neuronal activity, in mice that received LI-rTMS to visual cortex. Mice received single or multiple sessions of excitatory 10 Hz LI-rTMS with custom rodent coils or were sham controls. We assessed changes to c-Fos positive cell densities and c-Fos/parvalbumin co-expression. Peak c-Fos expression corresponded with activity during rTMS. We also assessed functional connectivity changes using brain-wide c-Fos-based network analysis. LI-rTMS modulated c-Fos expression in cortical and subcortical regions. c-Fos density changes were most prevalent with acute stimulation, however chronic stimulation decreased parvalbumin interneuron activity, most prominently in the amygdala and striatum. LI-rTMS also increased anti-correlated functional connectivity, with the most prominent effects also in the amygdala and striatum following chronic stimulation. LI-rTMS induces changes in c-Fos expression that suggest modulation of neuronal activity and functional connectivity throughout the brain. Our results suggest that LI-rTMS promotes anticorrelated functional connectivity, possibly due to decreased parvalbumin interneuron activation induced by chronic stimulation. These changes may underpin therapeutic rTMS effects, therefore modulation of subcortical activity supports rTMS for treatment of disorders involving subcortical dysregulation.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Immune gene expression analysis indicates the potential of a self-amplifying Covid-19 mRNA vaccine",
        "link": "https://www.nature.com/articles/s41541-022-00573-y",
        "publication_date": "28 Nov 2022",
        "abstract": "Remarkable potency has been demonstrated for mRNA vaccines in reducing the global burden of the ongoing COVID-19 pandemic. An alternative form of the mRNA vaccine is the self-amplifying mRNA (sa-mRNA) vaccine, which encodes an alphavirus replicase that self-amplifies the full-length mRNA and SARS-CoV-2 spike (S) transgene. However, early-phase clinical trials of sa-mRNA COVID-19 vaccine candidates have questioned the potential of this platform to develop potent vaccines. We examined the immune gene response to a candidate sa-mRNA vaccine against COVID-19, ARCT-021, and compared our findings to the host response to other forms of vaccines. In blood samples from healthy volunteers that participated in a phase I/II clinical trial, greater induction of transcripts involved in Toll-like receptor (TLR) signalling, antigen presentation and complement activation at 1 day post-vaccination was associated with higher anti-S antibody titers. Conversely, transcripts involved in T-cell maturation at day 7 post-vaccination informed the magnitude of eventual S-specific T-cell responses. The transcriptomic signature for ARCT-021 vaccination strongly correlated with live viral vector vaccines, adjuvanted vaccines and BNT162b2 1 day post-vaccination. Moreover, the ARCT-021 signature correlated with day 7 YF17D live-attenuated vaccine transcriptomic responses. Altogether, our findings show that sa-mRNA vaccination induces innate immune responses that are associated with the development of adaptive immunity from other forms of vaccines, supporting further development of this vaccine platform for clinical application.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning did not beat logistic regression in time series prediction for severe asthma exacerbations",
        "link": "https://www.nature.com/articles/s41598-022-24909-9",
        "publication_date": "27 Nov 2022",
        "abstract": "Early detection of severe asthma exacerbations through home monitoring data in patients with stable mild-to-moderate chronic asthma could help to timely adjust medication. We evaluated the potential of machine learning methods compared to a clinical rule and logistic regression to predict severe exacerbations. We used daily home monitoring data from two studies in asthma patients (development: n = 165 and validation: n = 101 patients). Two ML models (XGBoost, one class SVM) and a logistic regression model provided predictions based on peak expiratory flow and asthma symptoms. These models were compared with an asthma action plan rule. Severe exacerbations occurred in 0.2% of all daily measurements in the development (154/92,787 days) and validation cohorts (94/40,185 days). The AUC of the best performing XGBoost was 0.85 (0.82–0.87) and 0.88 (0.86–0.90) for logistic regression in the validation cohort. The XGBoost model provided overly extreme risk estimates, whereas the logistic regression underestimated predicted risks. Sensitivity and specificity were better overall for XGBoost and logistic regression compared to one class SVM and the clinical rule. We conclude that ML models did not beat logistic regression in predicting short-term severe asthma exacerbations based on home monitoring data. Clinical application remains challenging in settings with low event incidence and high false alarm rates with high sensitivity.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Wireless, closed-loop, smart bandage with integrated sensors and stimulators for advanced wound care and accelerated healing",
        "link": "https://www.nature.com/articles/s41587-022-01528-3",
        "publication_date": "24 Nov 2022",
        "abstract": "‘Smart’ bandages based on multimodal wearable devices could enable real-time physiological monitoring and active intervention to promote healing of chronic wounds. However, there has been limited development in incorporation of both sensors and stimulators for the current smart bandage technologies. Additionally, while adhesive electrodes are essential for robust signal transduction, detachment of existing adhesive dressings can lead to secondary damage to delicate wound tissues without switchable adhesion. Here we overcome these issues by developing a flexible bioelectronic system consisting of wirelessly powered, closed-loop sensing and stimulation circuits with skin-interfacing hydrogel electrodes capable of on-demand adhesion and detachment. In mice, we demonstrate that our wound care system can continuously monitor skin impedance and temperature and deliver electrical stimulation in response to the wound environment. Across preclinical wound models, the treatment group healed ~25% more rapidly and with ~50% enhancement in dermal remodeling compared with control. Further, we observed activation of proregenerative genes in monocyte and macrophage cell populations, which may enhance tissue regeneration, neovascularization and dermal recovery.",
        "conclusions": "In summary, we designed and fabricated a miniaturized smart bandage with dual-channel continuous sensing of wound impedance and temperature, as well as a parallel stimulation circuit to deliver programmed electrical cues for accelerated wound healing. Through the integration of sensors and stimulators into one wearable patch, as well as rational design of tissue-interfacing hydrogel electrodes, our wireless smart bandage enables (1) active monitoring and closed-loop treatment of a wound and (2) accelerated healing through a proregenerative mode of action, activated by increased cellular proliferation and recruitment of cells involved in wound repair. This dual-mode integration advances the field of wound healing pathobiology, enabling the optimization of treatment modalities that would allow for better patient mobility and improvement in standard of care.However, additional challenges exist, including production scalability (for example, reduced cost, long-term storage), incorporation of additional sensors (for example, metabolites, biomarkers, pH) and clinical translatability (for example, biocompatibility, biofouling issues). While our preclinical demonstrations showed proof of concept, future work involves extending our smart bandage to a human-sized form factor and running preliminary tests in large-animal models followed by human trials. In addition, we aim to reduce the manufacturing cost of our clinical device to enable broad adoption within a payer system. Finally, our device platform may also be adapted to the management of other diseases, enabling the next generation of closed-loop bioelectronic medicine.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Finding the influential clinical traits that impact on the diagnosis of heart disease using statistical and machine-learning techniques",
        "link": "https://www.nature.com/articles/s41598-022-24633-4",
        "publication_date": "23 Nov 2022",
        "abstract": "In recent years, the omnipresence of cardiac problems has been recognized as an epidemic. With the correct and quick diagnosis, both mortality and morbidity from cardiac disorders can be dramatically reduced. However, frequent medical check-ups are pricey and out of reach for a large number of people, particularly those living in low-income areas. In this paper, certain time-honored statistical techniques are used to determine the factors that lead to heart disease. Also, the findings were validated using various promising machine learning tools. Feature importance approach was employed to rank the clinical parameters of the patients based on the correlation of heart disease. In the case of statistical investigations, nonparametric tests such as the Mann Whitney U test and the Chi square test, as well as correlation analysis with Pearson correlation and Spearman Correlation were used. For additional validation, seven of the potential feature important based ML algorithms were applied. Moreover, Borda count was implemented to acknowledge the combined observation of those ML models. On top of that, SHAP value was calculated as a feature importance technique and for detailed evaluation. This research reveals two aspects of heart disease diagnosis.We found that eight clinical traits are sufficient to diagnose cardiac disorders, in which three traits are the most important sign of heart disease. One of the discoveries of this investigation uncovered chest pain, number of major blood vessels, thalassemia, age, maximum heart rate, cholesterol, oldpeak, and sex as sufficient clinical signs of individuals for the diagnosis of cardiac disorders. Over the above, considering the findings of all three approaches, chest pain, the number of major blood vessels, and thalassemia were identified as the prime factors of heart disease. The research also found, fasting blood sugar does not have a direct impact on cardiac disease. These findings will have the potency to be incredibly useful in clinical investigations as well as risk assessment for patients. Limiting the most critical features can have a significant impact on the diagnosis of heart disease and reduce the severity of health risks and death of patients.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Nature inspired method for noninvasive fetal ECG extraction",
        "link": "https://www.nature.com/articles/s41598-022-24733-1",
        "publication_date": "23 Nov 2022",
        "abstract": "This paper introduces a novel algorithm for effective and accurate extraction of non-invasive fetal electrocardiogram (NI-fECG). In NI-fECG based monitoring, the useful signal is measured along with other signals generated by the pregnant women’s body, especially maternal electrocardiogram (mECG). These signals are more distinct in magnitude and overlap in time and frequency domains, making the fECG extraction extremely challenging. The proposed extraction method combines the Grey wolf algorithm (GWO) with sequential analysis (SA). This innovative combination, forming the GWO-SA method, optimises the parameters required to create a template that matches the mECG, which leads to an accurate elimination of the said signal from the input composite signal. The extraction system was tested on two databases consisting of real signals, namely, Labour and Pregnancy. The databases used to test the algorithms are available on a server at the generalist repositories (figshare) integrated with Matonia et al. (Sci Data 7(1):1–14, 2020). The results show that the proposed method extracts the fetal ECG signal with an outstanding efficacy. The efficacy of the results was evaluated based on accurate detection of the fQRS complexes. The parameters used to evaluate are as follows: accuracy (ACC), sensitivity (SE), positive predictive value (PPV), and F1 score. Due to the stochastic nature of the GWO algorithm, ten individual runs were performed for each record in the two databases to assure stability as well as repeatability. Using these parameters, for the Labour dataset, we achieved an average ACC of 94.60%, F1 of 96.82%, SE of 97.49%, and PPV of 98.96%. For the Pregnancy database, we achieved an average ACC of 95.66%, F1 of 97.44%, SE of 98.07%, and PPV of 97.44%. The obtained results show that the fHR related parameters were determined accurately for most of the records, outperforming the other state-of-the-art approaches. The poorer quality of certain signals have caused deviation from the estimated fHR for certain records in the databases. The proposed algorithm is compared with certain well established algorithms, and has proven to be accurate in its fECG extractions.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Wing Interferential Patterns (WIPs) and machine learning, a step toward automatized tsetse (Glossina spp.) identification",
        "link": "https://www.nature.com/articles/s41598-022-24522-w",
        "publication_date": "22 Nov 2022",
        "abstract": "A simple method for accurately identifying Glossina spp in the field is a challenge to sustain the future elimination of Human African Trypanosomiasis (HAT) as a public health scourge, as well as for the sustainable management of African Animal Trypanosomiasis (AAT). Current methods for Glossina species identification heavily rely on a few well-trained experts. Methodologies that rely on molecular methodologies like DNA barcoding or mass spectrometry protein profiling (MALDI TOFF) haven’t been thoroughly investigated for Glossina sp. Nevertheless, because they are destructive, costly, time-consuming, and expensive in infrastructure and materials, they might not be well adapted for the survey of arthropod vectors involved in the transmission of pathogens responsible for Neglected Tropical Diseases, like HAT. This study demonstrates a new type of methodology to classify Glossina species. In conjunction with a deep learning architecture, a database of Wing Interference Patterns (WIPs) representative of the Glossina species involved in the transmission of HAT and AAT was used. This database has 1766 pictures representing 23 Glossina species. This cost-effective methodology, which requires mounting wings on slides and using a commercially available microscope, demonstrates that WIPs are an excellent medium to automatically recognize Glossina species with very high accuracy.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Quantifying deep neural network uncertainty for atrial fibrillation detection with limited labels",
        "link": "https://www.nature.com/articles/s41598-022-24574-y",
        "publication_date": "22 Nov 2022",
        "abstract": "Atrial fibrillation (AF) is the most common arrhythmia found in the intensive care unit (ICU), and is associated with many adverse outcomes. Effective handling of AF and similar arrhythmias is a vital part of modern critical care, but obtaining knowledge about both disease burden and effective interventions often requires costly clinical trials. A wealth of continuous, high frequency physiological data such as the waveforms derived from electrocardiogram telemetry are promising sources for enriching clinical research. Automated detection using machine learning and in particular deep learning has been explored as a solution for processing these data. However, a lack of labels, increased presence of noise, and inability to assess the quality and trustworthiness of many machine learning model predictions pose challenges to interpretation. In this work, we propose an approach for training deep AF models on limited, noisy data and report uncertainty in their predictions. Using techniques from the fields of weakly supervised learning, we leverage a surrogate model trained on non-ICU data to create imperfect labels for a large ICU telemetry dataset. We combine these weak labels with techniques to estimate model uncertainty without the need for extensive human data annotation. AF detection models trained using this process demonstrated higher classification performance (0.64–0.67 F1 score) and improved calibration (0.05–0.07 expected calibration error).",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Machine learning models for prediction of HF and CKD development in early-stage type 2 diabetes patients",
        "link": "https://www.nature.com/articles/s41598-022-24562-2",
        "publication_date": "21 Nov 2022",
        "abstract": "Chronic kidney disease (CKD) and heart failure (HF) are the first and most frequent comorbidities associated with mortality risks in early-stage type 2 diabetes mellitus (T2DM). However, efficient screening and risk assessment strategies for identifying T2DM patients at high risk of developing CKD and/or HF (CKD/HF) remains to be established. This study aimed to generate a novel machine learning (ML) model to predict the risk of developing CKD/HF in early-stage T2DM patients. The models were derived from a retrospective cohort of 217,054 T2DM patients without a history of cardiovascular and renal diseases extracted from a Japanese claims database. Among algorithms used for the ML, extreme gradient boosting exhibited the best performance for CKD/HF diagnosis and hospitalization after internal validation and was further validated using another dataset including 16,822 patients. In the external validation, 5-years prediction area under the receiver operating characteristic curves for CKD/HF diagnosis and hospitalization were 0.718 and 0.837, respectively. In Kaplan–Meier curves analysis, patients predicted to be at high risk showed significant increase in CKD/HF diagnosis and hospitalization compared with those at low risk. Thus, the developed model predicted the risk of developing CKD/HF in T2DM patients with reasonable probability in the external validation cohort. Clinical approach identifying T2DM at high risk of developing CKD/HF using ML models may contribute to improved prognosis by promoting early diagnosis and intervention.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Multi-modal wound classification using wound image and location by deep neural network",
        "link": "https://www.nature.com/articles/s41598-022-21813-0",
        "publication_date": "21 Nov 2022",
        "abstract": "Wound classification is an essential step of wound diagnosis. An efficient classifier can assist wound specialists in classifying wound types with less financial and time costs and help them decide on an optimal treatment procedure. This study developed a deep neural network-based multi-modal classifier using wound images and their corresponding locations to categorize them into multiple classes, including diabetic, pressure, surgical, and venous ulcers. A body map was also developed to prepare the location data, which can help wound specialists tag wound locations more efficiently. Three datasets containing images and their corresponding location information were designed with the help of wound specialists. The multi-modal network was developed by concatenating the image-based and location-based classifier outputs with other modifications. The maximum accuracy on mixed-class classifications (containing background and normal skin) varies from 82.48 to 100% in different experiments. The maximum accuracy on wound-class classifications (containing only diabetic, pressure, surgical, and venous) varies from 72.95 to 97.12% in various experiments. The proposed multi-modal network also showed a significant improvement in results from the previous works of literature.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Discovery and classification of complex multimorbidity patterns: unravelling chronicity networks and their social profiles",
        "link": "https://www.nature.com/articles/s41598-022-23617-8",
        "publication_date": "21 Nov 2022",
        "abstract": "Multimorbidity can be defined as the presence of two or more chronic diseases in an individual. This condition is associated with reduced quality of life, increased disability, greater functional impairment, increased health care utilisation, greater fragmentation of care and complexity of treatment, and increased mortality. Thus, understanding its epidemiology and inherent complexity is essential to improve the quality of life of patients and to reduce the costs associated with multi-pathology. In this paper, using data from the European Health Survey, we explore the application of Mixed Graphical Models and its combination with social network analysis techniques for the discovery and classification of complex multimorbidity patterns. The results obtained show the usefulness and versatility of this approach for the study of multimorbidity based on the use of graphs, which offer the researcher a holistic view of the relational structure of data with variables of different types and high dimensionality.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Artificial intelligence workflow quantifying muscle features on Hematoxylin–Eosin stained sections reveals dystrophic phenotype amelioration upon treatment",
        "link": "https://www.nature.com/articles/s41598-022-24139-z",
        "publication_date": "19 Nov 2022",
        "abstract": "Cell segmentation is a key step for a wide variety of biological investigations, especially in the context of muscle science. Currently, automated methods still struggle to perform skeletal muscle fiber quantification on Hematoxylin-Eosin (HE) stained histopathological whole slide images due to low contrast. On the other hand, the Deep Learning algorithm Cellpose offers new perspectives considering its increasing adoption for segmentation of a wide range of cells. Combining two open-source tools, Cellpose and QuPath, we developed MyoSOTHES, an automated Myofibers Segmentation wOrkflow Tuned for HE Staining. MyoSOTHES enables solving segmentation inconsistencies encountered by default Cellpose model in presence of large range size cells and provides information related to muscle Feret’s diameter distribution and Centrally Nucleated Fibers, thus depicting muscle health and treatment effects. MyoSOTHES achieves high quality segmentation compared to baseline workflow with a detection F1-score increasing from 0.801 to 0.919 and a Root Mean Square Error (RMSE) on diameter improved by 31%. MyoSOTHES was validated on an animal study featuring gene transfer in \\(\\gamma\\)-Sarcoglycanopathy, for which dose-response effect is visible and conclusions drawn are consistent with those previously published. MyoSOTHES thus paves the way for wide quantification of HE stained muscle sections and retrospective analysis of HE labeled slices used in laboratories for decades.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Profiling mRNA, miRNA and lncRNA expression changes in endothelial cells in response to increasing doses of ionizing radiation",
        "link": "https://www.nature.com/articles/s41598-022-24051-6",
        "publication_date": "19 Nov 2022",
        "abstract": "Recent and past research have highlighted the importance of the endothelium in the manifestation of radiation injury. Our primary focus is on medical triage and management following whole body or partial-body irradiation. Here we investigated the usability of endothelial cells’ radiation response for biodosimetry applications. We profiled the transcriptome in cultured human endothelial cells treated with increasing doses of X-rays. mRNA expression changes were useful 24 h and 72 h post-radiation, microRNA and lncRNA expression changes were useful 72 h after radiation. More mRNA expressions were repressed than induced while more miRNA and lncRNA expressions were induced than repressed. These novel observations imply distinct radiation responsive regulatory mechanisms for coding and non-coding transcripts. It also follows how different RNA species should be explored as biomarkers for different time-points. Radiation-responsive markers which could classify no radiation (i.e., ‘0 Gy’) and dose-differentiating markers were also predicted. IPA analysis showed growth arrest-related processes at 24 h but immune response coordination at the 72 h post-radiation. Collectively, these observations suggest that endothelial cells have a precise dose and time-dependent response to radiation. Further studies in the laboratory are examining if these differences could be captured in the extracellular vesicles released by irradiated endothelial cells.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Model-free phasor image analysis of quantitative myocardial T1 mapping",
        "link": "https://www.nature.com/articles/s41598-022-23872-9",
        "publication_date": "18 Nov 2022",
        "abstract": "Model-free phasor image analysis, well established in fluorescence lifetime imaging and only recently applied to qMRI \\({T}_{2}\\) data processing, is here adapted and validated for myocardial qMRI \\({T}_{1}\\) mapping. Contrarily to routine mono-exponential fitting procedures, phasor enables mapping the lifetime information from all image voxels to a single plot, without resorting to any regression fitting analysis, and describing multi-exponential qMRI decays without biases due to violated modelling assumptions. In this feasibility study, we test the performance of our recently developed full-harmonics phasor method for unravelling partial-volume effects, motion or pathological tissue alteration, respectively on a numerically-simulated dataset, a healthy subject scan, and two pilot patient datasets. Our results show that phasor analysis can be used, as alternative method to fitting analysis or other model-free approaches, to identify motion artifacts or partial-volume effects at the myocardium-blood interface as characteristic deviations, or delineations of scar and remote myocardial tissue in patient data.",
        "conclusions": "In this work, we have evaluated the feasibility of phasor processing method for the analysis of cardiac \\({T}_{1}\\) mapping data. Our data indicate the potential use of phasor analysis, in the form of phasor-coordinate maps, phasor plots and/or phasor-based segmentation images, for the eased depiction of partial volume effects and motion, while retaining good visualization of abnormal relaxation times in patients. Hence, phasor may offer potential as an alternative, model-free, qMRI data analysis method for fast and robust tissue characterization based on conventional myocardial \\({T}_{1}\\) mapping data. Future research is warranted to further validate the clinical value of a phasor-based quality assurance to aid robustness in clinical cardiac \\({T}_{1}\\) mapping of motion artefacts and scar tissue.",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development of a deep learning method for improving diagnostic accuracy for uterine sarcoma cases",
        "link": "https://www.nature.com/articles/s41598-022-23064-5",
        "publication_date": "16 Nov 2022",
        "abstract": "Uterine sarcomas have very poor prognoses and are sometimes difficult to distinguish from uterine leiomyomas on preoperative examinations. Herein, we investigated whether deep neural network (DNN) models can improve the accuracy of preoperative MRI-based diagnosis in patients with uterine sarcomas. Fifteen sequences of MRI for patients (uterine sarcoma group: n = 63; uterine leiomyoma: n = 200) were used to train the models. Six radiologists (three specialists, three practitioners) interpreted the same images for validation. The most important individual sequences for diagnosis were axial T2-weighted imaging (T2WI), sagittal T2WI, and diffusion-weighted imaging. These sequences also represented the most accurate combination (accuracy: 91.3%), achieving diagnostic ability comparable to that of specialists (accuracy: 88.3%) and superior to that of practitioners (accuracy: 80.1%). Moreover, radiologists’ diagnostic accuracy improved when provided with DNN results (specialists: 89.6%; practitioners: 92.3%). Our DNN models are valuable to improve diagnostic accuracy, especially in filling the gap of clinical skills between interpreters. This method can be a universal model for the use of deep learning in the diagnostic imaging of rare tumors.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "ABE8e adenine base editor precisely and efficiently corrects a recurrent COL7A1 nonsense mutation",
        "link": "https://www.nature.com/articles/s41598-022-24184-8",
        "publication_date": "16 Nov 2022",
        "abstract": "Base editing introduces precise single-nucleotide edits in genomic DNA and has the potential to treat genetic diseases such as the blistering skin disease recessive dystrophic epidermolysis bullosa (RDEB), which is characterized by mutations in the COL7A1 gene and type VII collagen (C7) deficiency. Adenine base editors (ABEs) convert A-T base pairs to G-C base pairs without requiring double-stranded DNA breaks or donor DNA templates. Here, we use ABE8e, a recently evolved ABE, to correct primary RDEB patient fibroblasts harboring the recurrent RDEB nonsense mutation c.5047 C > T (p.Arg1683Ter) in exon 54 of COL7A1 and use a next generation sequencing workflow to interrogate post-treatment outcomes. Electroporation of ABE8e mRNA into a bulk population of RDEB patient fibroblasts resulted in remarkably efficient (94.6%) correction of the pathogenic allele, restoring COL7A1 mRNA and expression of C7 protein in western blots and in 3D skin constructs. Off-target DNA analysis did not detect off-target editing in treated patient-derived fibroblasts and there was no detectable increase in A-to-I changes in the RNA. Taken together, we have established a highly efficient pipeline for gene correction in primary fibroblasts with a favorable safety profile. This work lays a foundation for developing therapies for RDEB patients using ex vivo or in vivo base editing strategies.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Novel 3D video action recognition deep learning approach for near real time epileptic seizure classification",
        "link": "https://www.nature.com/articles/s41598-022-23133-9",
        "publication_date": "15 Nov 2022",
        "abstract": "Seizure semiology is a well-established method to classify epileptic seizure types, but requires a significant amount of resources as long-term Video-EEG monitoring needs to be visually analyzed. Therefore, computer vision based diagnosis support tools are a promising approach. In this article, we utilize infrared (IR) and depth (3D) videos to show the feasibility of a 24/7 novel object and action recognition based deep learning (DL) monitoring system to differentiate between epileptic seizures in frontal lobe epilepsy (FLE), temporal lobe epilepsy (TLE) and non-epileptic events. Based on the largest 3Dvideo-EEG database in the world (115 seizures/+680,000 video-frames/427GB), we achieved a promising cross-subject validation f1-score of 0.833±0.061 for the 2 class (FLE vs. TLE) and 0.763 ± 0.083 for the 3 class (FLE vs. TLE vs. non-epileptic) case, from 2 s samples, with an automated semi-specialized depth (Acc.95.65%) and Mask R-CNN (Acc.96.52%) based cropping pipeline to pre-process the videos, enabling a near-real-time seizure type detection and classification tool. Our results demonstrate the feasibility of our novel DL approach to support 24/7 epilepsy monitoring, outperforming all previously published methods.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Development and validation of deep learning ECG-based prediction of myocardial infarction in emergency department patients",
        "link": "https://www.nature.com/articles/s41598-022-24254-x",
        "publication_date": "15 Nov 2022",
        "abstract": "Myocardial infarction diagnosis is a common challenge in the emergency department. In managed settings, deep learning-based models and especially convolutional deep models have shown promise in electrocardiogram (ECG) classification, but there is a lack of high-performing models for the diagnosis of myocardial infarction in real-world scenarios. We aimed to train and validate a deep learning model using ECGs to predict myocardial infarction in real-world emergency department patients. We studied emergency department patients in the Stockholm region between 2007 and 2016 that had an ECG obtained because of their presenting complaint. We developed a deep neural network based on convolutional layers similar to a residual network. Inputs to the model were ECG tracing, age, and sex; and outputs were the probabilities of three mutually exclusive classes: non-ST-elevation myocardial infarction (NSTEMI), ST-elevation myocardial infarction (STEMI), and control status, as registered in the SWEDEHEART and other registries. We used an ensemble of five models. Among 492,226 ECGs in 214,250 patients, 5,416 were recorded with an NSTEMI, 1,818 a STEMI, and 485,207 without a myocardial infarction. In a random test set, our model could discriminate STEMIs/NSTEMIs from controls with a C-statistic of 0.991/0.832 and had a Brier score of 0.001/0.008. The model obtained a similar performance in a temporally separated test set of the study sample, and achieved a C-statistic of 0.985 and a Brier score of 0.002 in discriminating STEMIs from controls in an external test set. We developed and validated a deep learning model with excellent performance in discriminating between control, STEMI, and NSTEMI on the presenting ECG of a real-world sample of the important population of all-comers to the emergency department. Hence, deep learning models for ECG decision support could be valuable in the emergency department.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Identifying the optimal conditioning intensity for stem cell transplantation in patients with myelodysplastic syndrome: a machine learning analysis",
        "link": "https://www.nature.com/articles/s41409-022-01871-8",
        "publication_date": "14 Nov 2022",
        "abstract": "A conditioning regimen is an essential prerequisite of allogeneic hematopoietic stem cell transplantation for patients with myelodysplastic syndrome (MDS). However, the optimal conditioning intensity for a patient may be difficult to establish. This study aimed to identify optimal conditioning intensity (reduced-intensity conditioning regimen [RIC] or myeloablative conditioning regimen [MAC]) for patients with MDS. Overall, 2567 patients with MDS who received their first HCT between 2009 and 2019 were retrospectively analyzed. They were divided into a training cohort and a validation cohort. Using a machine learning-based model, we developed a benefit score for RIC in the training cohort. The validation cohort was divided into a high-score and a low-score group, based on the median benefit score. The endpoint was progression-free survival (PFS). The benefit score for RIC was developed from nine baseline variables in the training cohort. In the validation cohort, the hazard ratios of the PFS in the RIC group compared to the MAC group were 0.65 (95% confidence interval [CI]: 0.48–0.90, P = 0.009) in the high-score group and 1.36 (95% CI: 1.06–1.75, P = 0.017) in the low-score group (P for interaction < 0.001). Machine-learning-based scoring can be useful for the identification of optimal conditioning regimens for patients with MDS.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Enhanced survival prediction using explainable artificial intelligence in heart transplantation",
        "link": "https://www.nature.com/articles/s41598-022-23817-2",
        "publication_date": "14 Nov 2022",
        "abstract": "The most limiting factor in heart transplantation is the lack of donor organs. With enhanced prediction of outcome, it may be possible to increase the life-years from the organs that become available. Applications of machine learning to tabular data, typical of clinical decision support, pose the practical question of interpretation, which has technical and potential ethical implications. In particular, there is an issue of principle about the predictability of complex data and whether this is inherent in the data or strongly dependent on the choice of machine learning model, leading to the so-called accuracy-interpretability trade-off. We model 1-year mortality in heart transplantation data with a self-explaining neural network, which is benchmarked against a deep learning model on the same development data, in an external validation study with two data sets: (1) UNOS transplants in 2017–2018 (n = 4750) for which the self-explaining and deep learning models are comparable in their AUROC 0.628 [0.602,0.654] cf. 0.635 [0.609,0.662] and (2) Scandinavian transplants during 1997–2018 (n = 2293), showing good calibration with AUROCs of 0.626 [0.588,0.665] and 0.634 [0.570, 0.698], respectively, with and without missing data (n = 982). This shows that for tabular data, predictive models can be transparent and capture important nonlinearities, retaining full predictive performance.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Transmembrane water-efflux rate measured by magnetic resonance imaging as a biomarker of the expression of aquaporin-4 in gliomas",
        "link": "https://www.nature.com/articles/s41551-022-00960-9",
        "publication_date": "14 Nov 2022",
        "abstract": "The water-selective channel protein aquaporin-4 (AQP4) contributes to the migration and proliferation of gliomas, and to their resistance to therapy. Here we show, in glioma cell cultures, in subcutaneous and orthotopic gliomas in rats, and in glioma tumours in patients, that transmembrane water-efflux rate is a sensitive biomarker of AQP4 expression and can be measured via conventional dynamic-contrast-enhanced magnetic resonance imaging. Water-efflux rates correlated with stages of glioma proliferation as well as with changes in the heterogeneity of intra-tumoural and inter-tumoural AQP4 in rodent and human gliomas following treatment with temozolomide and with the AQP4 inhibitor TGN020. Regions with low water-efflux rates contained higher fractions of stem-like slow-cycling cells and therapy-resistant cells, suggesting that maps of water-efflux rates could be used to identify gliomas that are resistant to therapies.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Ensemble machine learning identifies genetic loci associated with future worsening of disability in people with multiple sclerosis",
        "link": "https://www.nature.com/articles/s41598-022-23685-w",
        "publication_date": "11 Nov 2022",
        "abstract": "Limited studies have been conducted to identify and validate multiple sclerosis (MS) genetic loci associated with disability progression. We aimed to identify MS genetic loci associated with worsening of disability over time, and to develop and validate ensemble genetic learning model(s) to identify people with MS (PwMS) at risk of future worsening. We examined associations of 208 previously established MS genetic loci with the risk of worsening of disability; we learned ensemble genetic decision rules and validated the predictions in an external dataset. We found 7 genetic loci (rs7731626: HR 0.92, P = 2.4 × 10–5; rs12211604: HR 1.16, P = 3.2 × 10–7; rs55858457: HR 0.93, P = 3.7 × 10–7; rs10271373: HR 0.90, P = 1.1 × 10–7; rs11256593: HR 1.13, P = 5.1 × 10–57; rs12588969: HR = 1.10, P = 2.1 × 10–10; rs1465697: HR 1.09, P = 1.7 × 10–128) associated with risk worsening of disability; most of which were located near or tagged to 13 genomic regions enriched in peptide hormones and steroids biosynthesis pathways by positional and eQTL mapping. The derived ensembles produced a set of genetic decision rules that can be translated to provide additional prognostic values to existing clinical predictions, with the additional benefit of incorporating relevant genetic information into clinical decision making for PwMS. The present study extends our knowledge of MS progression genetics and provides the basis of future studies regarding the functional significance of the identified loci.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Predicting willingness to donate blood based on machine learning: two blood donor recruitments during COVID-19 outbreaks",
        "link": "https://www.nature.com/articles/s41598-022-21215-2",
        "publication_date": "10 Nov 2022",
        "abstract": "Machine learning methods are a novel way to predict and rank donors' willingness to donate blood and to achieve precision recruitment, which can improve the recruitment efficiency and meet the challenge of blood shortage. We collected information about experienced blood donors via short message service (SMS) recruitment and developed 7 machine learning-based recruitment models using PyCharm-Python Environment and 13 features which were described as a method for ranking and predicting donors’ intentions to donate blood with a floating number between 0 and 1. Performance of the prediction models was assessed by the Area under the receiver operating characteristic curve (AUC), accuracy, precision, recall, and F1 score in the full dataset, and by the accuracy in the four sub-datasets. The developed models were applied to prospective validations of recruiting experienced blood donors during two COVID-19 pandemics, while the routine method was used as a control. Overall, a total of 95,476 recruitments via SMS and their donation results were enrolled in our modelling study. The strongest predictor features for the donation of experienced donors were blood donation interval, age, and donation frequency. Among the seven baseline models, the eXtreme Gradient Boosting (XGBoost) and Support vector machine models (SVM) achieved the best performance: mean (95%CI) with the highest AUC: 0.809 (0.806–0.811), accuracy: 0.815 (0.812–0.818), precision: 0.840 (0.835–0.845), and F1 score of XGBoost: 0.843 (0.840–0.845) and recall of SVM: 0.991 (0.988–0.994). The hit rate of the XGBoost model alone and the combined XGBoost and SVM models were 1.25 and 1.80 times higher than that of the conventional method as a control in 2 recruitments respectively, and the hit rate of the high willingness to donate group was 1.96 times higher than that of the low willingness to donate group. Our results suggested that the machine learning models could predict and determine the experienced donors with a strong willingness to donate blood by a ranking score based on personalized donation data and demographical details, significantly improve the recruitment rate of blood donors and help blood agencies to maintain the blood supply in emergencies.",
        "conclusions": "Overall, our research provided a positive answer to the question of whether the donors’ intention to donate blood could be predicted from their donation records and developed 7 SMS recruitment models based on machine learning algorithms, which could predict whether an experienced donor was willing to donate blood, and the level of his willingness by a ranking score based on personalized donation data and demographical details. To our knowledge, this was the first prospective study on blood donor recruitment using a comprehensive scoring method based on machine learning, which predicted and ranked the personalized motivation of blood donors. The results of this study contributed to improving our understanding of what features were most important for donation and helping blood agencies to predict potential blood donors, make personalized recruitment plans to meet the patient’s needs, and improve recruitment efficacy with precision tactics to maintain the blood supply in emergencies.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Proteomic signatures for identification of impaired glucose tolerance",
        "link": "https://www.nature.com/articles/s41591-022-02055-z",
        "publication_date": "10 Nov 2022",
        "abstract": "The implementation of recommendations for type 2 diabetes (T2D) screening and diagnosis focuses on the measurement of glycated hemoglobin (HbA1c) and fasting glucose. This approach leaves a large number of individuals with isolated impaired glucose tolerance (iIGT), who are only detectable through oral glucose tolerance tests (OGTTs), at risk of diabetes and its severe complications. We applied machine learning to the proteomic profiles of a single fasted sample from 11,546 participants of the Fenland study to test discrimination of iIGT defined using the gold-standard OGTTs. We observed significantly improved discriminative performance by adding only three proteins (RTN4R, CBPM and GHR) to the best clinical model (AUROC = 0.80 (95% confidence interval: 0.79–0.86), P = 0.004), which we validated in an external cohort. Increased plasma levels of these candidate proteins were associated with an increased risk for future T2D in an independent cohort and were also increased in individuals genetically susceptible to impaired glucose homeostasis and T2D. Assessment of a limited number of proteins can identify individuals likely to be missed by current diagnostic strategies and at high risk of T2D and its complications.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of the disease course in Friedreich ataxia",
        "link": "https://www.nature.com/articles/s41598-022-23666-z",
        "publication_date": "10 Nov 2022",
        "abstract": "We explored whether disease severity of Friedreich ataxia can be predicted using data from clinical examinations. From the database of the European Friedreich Ataxia Consortium for Translational Studies (EFACTS) data from up to five examinations of 602 patients with genetically confirmed FRDA was included. Clinical instruments and important symptoms of FRDA were identified as targets for prediction, while variables such as genetics, age of disease onset and first symptom of the disease were used as predictors. We used modelling techniques including generalised linear models, support-vector-machines and decision trees. The scale for rating and assessment of ataxia (SARA) and the activities of daily living (ADL) could be predicted with predictive errors quantified by root-mean-squared-errors (RMSE) of 6.49 and 5.83, respectively. Also, we were able to achieve reasonable performance for loss of ambulation (ROC-AUC score of 0.83). However, predictions for the SCA functional assessment (SCAFI) and presence of cardiological symptoms were difficult. In conclusion, we demonstrate that some clinical features of FRDA can be predicted with reasonable error; being a first step towards future clinical applications of predictive modelling. In contrast, targets where predictions were difficult raise the question whether there are yet unknown variables driving the clinical phenotype of FRDA.",
        "conclusions": "In conclusion, in this paper we demonstrated that certain clinical instruments and features relevant for FRDA can be predicted to an extent that allows for an informed estimate about a patient’s disease severity. However, parts of the clinical phenotype of FRDA are still not well understood and this is reflected in subpar predictive performance when attempting to establish predictive modelling for these clinical features. This work can be seen as a promising first step towards a more individualised medicine in FRDA. Much more work, both on optimising modelling for the most promising targets, as well as on the understanding of FRDA as a whole is necessary.",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Lipidomic signatures align with inflammatory patterns and outcomes in critical illness",
        "link": "https://www.nature.com/articles/s41467-022-34420-4",
        "publication_date": "10 Nov 2022",
        "abstract": "Alterations in lipid metabolism have the potential to be markers as well as drivers of pathobiology of acute critical illness. Here, we took advantage of the temporal precision offered by trauma as a common cause of critical illness to identify the dynamic patterns in the circulating lipidome in critically ill humans. The major findings include an early loss of all classes of circulating lipids followed by a delayed and selective lipogenesis in patients destined to remain critically ill. The previously reported survival benefit of early thawed plasma administration was associated with preserved lipid levels that related to favorable changes in coagulation and inflammation biomarkers in causal modelling. Phosphatidylethanolamines (PE) were elevated in patients with persistent critical illness and PE levels were prognostic for worse outcomes not only in trauma but also severe COVID-19 patients. Here we show selective rise in systemic PE as a common prognostic feature of critical illness.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Multi-kingdom gut microbiota analyses define COVID-19 severity and post-acute COVID-19 syndrome",
        "link": "https://www.nature.com/articles/s41467-022-34535-8",
        "publication_date": "10 Nov 2022",
        "abstract": "Our knowledge of the role of the gut microbiome in acute coronavirus disease 2019 (COVID-19) and post-acute COVID-19 is rapidly increasing, whereas little is known regarding the contribution of multi-kingdom microbiota and host-microbial interactions to COVID-19 severity and consequences. Herein, we perform an integrated analysis using 296 fecal metagenomes, 79 fecal metabolomics, viral load in 1378 respiratory tract samples, and clinical features of 133 COVID-19 patients prospectively followed for up to 6 months. Metagenomic-based clustering identifies two robust ecological clusters (hereafter referred to as Clusters 1 and 2), of which Cluster 1 is significantly associated with severe COVID-19 and the development of post-acute COVID-19 syndrome. Significant differences between clusters could be explained by both multi-kingdom ecological drivers (bacteria, fungi, and viruses) and host factors with a good predictive value and an area under the curve (AUC) of 0.98. A model combining host and microbial factors could predict the duration of respiratory viral shedding with 82.1% accuracy (error ± 3 days). These results highlight the potential utility of host phenotype and multi-kingdom microbiota profiling as a prognostic tool for patients with COVID-19.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Establishment of a model for predicting the outcome of induced labor in full-term pregnancy based on machine learning algorithm",
        "link": "https://www.nature.com/articles/s41598-022-21954-2",
        "publication_date": "09 Nov 2022",
        "abstract": "To evaluate and establish a prediction model of the outcome of induced labor based on machine learning algorithm. This was a cross-sectional design. The subjects were divided into primipara and multipara, and the risk factors for the outcomes of induced labor were assessed by multifactor logistic regression analysis. The outcome model of labor induced with oxytocin (OT) was constructed based on the four machine learning algorithms, including AdaBoost, logistic regression, naive Bayes classifier, and support vector machine. Factors, such as accuracy, recall, precision, F1 value, and receiver operating characteristic curve, were used to evaluate the prediction performance of the model, and the clinical application of the model was verified. A total of 907 participants were included in this study. Logistic regression algorithm obtained better results in both primipara and multipara groups compared to the other three models. The accuracy of the model for the prediction of “successful induction of labor” was 94.24% and 96.55%, and that of “failed induction of labor” was 65.00% and 66.67% in the primipara and the multipara groups, respectively. This study established a prediction model of OT-induced labor based on the Logistic regression algorithm, with rapid response, high accuracy, and strong extrapolation, which was critical for obstetric clinical nursing.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Deep learning-based framework for slide-based histopathological image analysis",
        "link": "https://www.nature.com/articles/s41598-022-23166-0",
        "publication_date": "09 Nov 2022",
        "abstract": "Digital pathology coupled with advanced machine learning (e.g., deep learning) has been changing the paradigm of whole-slide histopathological images (WSIs) analysis. Major applications in digital pathology using machine learning include automatic cancer classification, survival analysis, and subtyping from pathological images. While most pathological image analyses are based on patch-wise processing due to the extremely large size of histopathology images, there are several applications that predict a single clinical outcome or perform pathological diagnosis per slide (e.g., cancer classification, survival analysis). However, current slide-based analyses are task-dependent, and a general framework of slide-based analysis in WSI has been seldom investigated. We propose a novel slide-based histopathology analysis framework that creates a WSI representation map, called HipoMap, that can be applied to any slide-based problems, coupled with convolutional neural networks. HipoMap converts a WSI of various shapes and sizes to structured image-type representation. Our proposed HipoMap outperformed existing methods in intensive experiments with various settings and datasets. HipoMap showed the Area Under the Curve (AUC) of 0.96±0.026 (5% improved) in the experiments for lung cancer classification, and c-index of 0.787±0.013 (3.5% improved) and coefficient of determination (\\(R^2\\)) of 0.978±0.032 (24% improved) in survival analysis and survival prediction with TCGA lung cancer data respectively, as a general framework of slide-based analysis with a flexible capability. The results showed significant improvement comparing to the current state-of-the-art methods on each task. We further discussed experimental results of HipoMap as pathological viewpoints and verified the performance using publicly available TCGA datasets. A Python package is available at https://pypi.org/project/hipomap, and the package can be easily installed using Python PIP. The open-source codes in Python are available at: https://github.com/datax-lab/HipoMap.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Deep learning-based image analysis predicts PD-L1 status from H&E-stained histopathology images in breast cancer",
        "link": "https://www.nature.com/articles/s41467-022-34275-9",
        "publication_date": "08 Nov 2022",
        "abstract": "Programmed death ligand-1 (PD-L1) has been recently adopted for breast cancer as a predictive biomarker for immunotherapies. The cost, time, and variability of PD-L1 quantification by immunohistochemistry (IHC) are a challenge. In contrast, hematoxylin and eosin (H&E) is a robust staining used routinely for cancer diagnosis. Here, we show that PD-L1 expression can be predicted from H&E-stained images by employing state-of-the-art deep learning techniques. With the help of two expert pathologists and a designed annotation software, we construct a dataset to assess the feasibility of PD-L1 prediction from H&E in breast cancer. In a cohort of 3,376 patients, our system predicts the PD-L1 status in a high area under the curve (AUC) of 0.91 – 0.93. Our system is validated on two external datasets, including an independent clinical trial cohort, showing consistent prediction performance. Furthermore, the proposed system predicts which cases are prone to pathologists miss-interpretation, showing it can serve as a decision support and quality assurance system in clinical practice.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Intellectually able adults with autism spectrum disorder show typical resting-state EEG activity",
        "link": "https://www.nature.com/articles/s41598-022-22597-z",
        "publication_date": "08 Nov 2022",
        "abstract": "There is broad interest in discovering quantifiable physiological biomarkers for psychiatric disorders to aid diagnostic assessment. However, finding biomarkers for autism spectrum disorder (ASD) has proven particularly difficult, partly due to high heterogeneity. Here, we recorded five minutes eyes-closed rest electroencephalography (EEG) from 186 adults (51% with ASD and 49% without ASD) and investigated the potential of EEG biomarkers to classify ASD using three conventional machine learning models with two-layer cross-validation. Comprehensive characterization of spectral, temporal and spatial dimensions of source-modelled EEG resulted in 3443 biomarkers per recording. We found no significant group-mean or group-variance differences for any of the EEG features. Interestingly, we obtained validation accuracies above 80%; however, the best machine learning model merely distinguished ASD from the non-autistic comparison group with a mean balanced test accuracy of 56% on the entirely unseen test set. The large drop in model performance between validation and testing, stress the importance of rigorous model evaluation, and further highlights the high heterogeneity in ASD. Overall, the lack of significant differences and weak classification indicates that, at the group level, intellectually able adults with ASD show remarkably typical resting-state EEG.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Using machine-learning strategies to solve psychometric problems",
        "link": "https://www.nature.com/articles/s41598-022-23678-9",
        "publication_date": "07 Nov 2022",
        "abstract": "Validating scales for clinical use is a common procedure in medicine and psychology. Through the application of computational methods, we present a new strategy for estimating construct validity and criterion validity. XGBoost, Random Forest and Support-Vector machine learning algorithms were employed in order to make predictions based on the pattern of participants’ responses by systematically controlling computational experiments with artificial experiments whose results are guaranteed. According to these findings, these approaches are capable of achieving construct and criterion validity and therefore could provide an additional layer of evidence to traditional validation approaches. In particular, this study examined the extent to which measured items are inferable by theoretically related items, as well as the extent to which the information carried by a given construct can be translated into other theoretically compatible normative scales based on other constructs (thereby providing information about construct validity); as well as the replicability of clinical decision rules on several partitions (thereby providing information about criterion validity).",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Forecasting individual progression trajectories in Huntington disease enables more powered clinical trials",
        "link": "https://www.nature.com/articles/s41598-022-18848-8",
        "publication_date": "07 Nov 2022",
        "abstract": "Variability in neurodegenerative disease progression poses great challenges for the evaluation of potential treatments. Identifying the persons who will experience significant progression in the short term is key for the implementation of trials with smaller sample sizes. We apply here disease course mapping to forecast biomarker progression for individual carriers of the pathological CAG repeat expansions responsible for Huntington disease. We used data from two longitudinal studies (TRACK-HD and TRACK-ON) to synchronize temporal progression of 15 clinical and imaging biomarkers from 290 participants with Huntington disease. We used then the resulting HD COURSE MAP to forecast clinical endpoints from the baseline data of 11,510 participants from ENROLL-HD, an external validation cohort. We used such forecasts to select participants at risk for progression and compute the power of trials for such an enriched population. HD COURSE MAP forecasts biomarkers 5 years after the baseline measures with a maximum mean absolute error of 10 points for the total motor score and 2.15 for the total functional capacity. This allowed reducing sample sizes in trial up to 50% including participants with a higher risk for progression ensuring a more homogeneous group of participants.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A data driven machine learning approach to differentiate between autism spectrum disorder and attention-deficit/hyperactivity disorder based on the best-practice diagnostic instruments for autism",
        "link": "https://www.nature.com/articles/s41598-022-21719-x",
        "publication_date": "05 Nov 2022",
        "abstract": "Autism spectrum disorder (ASD) and attention-deficit/hyperactivity disorder (ADHD) are two frequently co-occurring neurodevelopmental conditions that share certain symptomatology, including social difficulties. This presents practitioners with challenging (differential) diagnostic considerations, particularly in clinically more complex cases with co-occurring ASD and ADHD. Therefore, the primary aim of the current study was to apply a data-driven machine learning approach (support vector machine) to determine whether and which items from the best-practice clinical instruments for diagnosing ASD (ADOS, ADI-R) would best differentiate between four groups of individuals referred to specialized ASD clinics (i.e., ASD, ADHD, ASD + ADHD, ND = no diagnosis). We found that a subset of five features from both ADOS (clinical observation) and ADI-R (parental interview) reliably differentiated between ASD groups (ASD & ASD + ADHD) and non-ASD groups (ADHD & ND), and these features corresponded to the social-communication but also restrictive and repetitive behavior domains. In conclusion, the results of the current study support the idea that detecting ASD in individuals with suspected signs of the diagnosis, including those with co-occurring ADHD, is possible with considerably fewer items relative to the original ADOS/2 and ADI-R algorithms (i.e., 92% item reduction) while preserving relatively high diagnostic accuracy. Clinical implications and study limitations are discussed.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Distributed lag inspired machine learning for predicting vaccine-induced changes in COVID-19 hospitalization and intensive care unit admission",
        "link": "https://www.nature.com/articles/s41598-022-21969-9",
        "publication_date": "05 Nov 2022",
        "abstract": "Distributed lags play important roles in explaining the short-run dynamic and long-run cumulative effects of features on a response variable. Unlike the usual lag length selection, important lags with significant weights are  selected in a distributed lag model (DLM). Inspired by the importance of distributed lags, this research focuses on the construction of distributed lag inspired machine learning (DLIML) for predicting vaccine-induced changes in COVID-19 hospitalization and intensive care unit (ICU) admission rates. Importance of a lagged feature in DLM is examined by hypothesis testing and a subset of important features are selected by evaluating an information criterion. Akin to the DLM, we demonstrate the selection of distributed lags in machine learning by evaluating importance scores and objective functions. Finally, we apply the DLIML with supervised learning for forecasting daily changes in COVID-19 hospitalization and ICU admission rates in United Kingdom (UK) and United States of America (USA). A sharp decline in hospitalization and ICU admission rates are observed when around 40% people are vaccinated. For one percent more vaccination, daily changes in hospitalization and ICU admission rates are expected to reduce by 4.05 and 0.74 per million after 14 days in UK, and 5.98 and 1.04 per million after 20 days in USA, respectively. Long-run cumulative effects in the DLM demonstrate that the daily changes in hospitalization and ICU admission rates are expected to jitter around the zero line in a long-run. Application of the DLIML selects fewer lagged features but provides qualitatively better forecasting outcome for data-driven healthcare service planning.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A preliminary deep learning study on automatic segmentation of contrast-enhanced bolus in videofluorography of swallowing",
        "link": "https://www.nature.com/articles/s41598-022-21530-8",
        "publication_date": "05 Nov 2022",
        "abstract": "Although videofluorography (VFG) is an effective tool for evaluating swallowing functions, its accurate evaluation requires considerable time and effort. This study aimed to create a deep learning model for automated bolus segmentation on VFG images of patients with healthy swallowing and dysphagia using the artificial intelligence deep learning segmentation method, and to assess the performance of the method. VFG images of 72 swallowing of 12 patients were continuously converted into 15 static images per second. In total, 3910 images were arbitrarily assigned to the training, validation, test 1, and test 2 datasets. In the training and validation datasets, images of colored bolus areas were prepared, along with original images. Using a U-Net neural network, a trained model was created after 500 epochs of training. The test datasets were applied to the trained model, and the performances of automatic segmentation (Jaccard index, Sørensen–Dice coefficient, and sensitivity) were calculated. All performance values for the segmentation of the test 1 and 2 datasets were high, exceeding 0.9. Using an artificial intelligence deep learning segmentation method, we automatically segmented the bolus areas on VFG images; our method exhibited high performance. This model also allowed assessment of aspiration and laryngeal invasion.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "DeepPDT-Net: predicting the outcome of photodynamic therapy for chronic central serous chorioretinopathy using two-stage multimodal transfer learning",
        "link": "https://www.nature.com/articles/s41598-022-22984-6",
        "publication_date": "04 Nov 2022",
        "abstract": "Central serous chorioretinopathy (CSC), characterized by serous detachment of the macular retina, can cause permanent vision loss in the chronic course. Chronic CSC is generally treated with photodynamic therapy (PDT), which is costly and quite invasive, and the results are unpredictable. In a retrospective case–control study design, we developed a two-stage deep learning model to predict 1-year outcome of PDT using initial multimodal clinical data. The training dataset included 166 eyes with chronic CSC and an additional learning dataset containing 745 healthy control eyes. A pre-trained ResNet50-based convolutional neural network was first trained with normal fundus photographs (FPs) to detect CSC and then adapted to predict CSC treatability through transfer learning. The domain-specific ResNet50 successfully predicted treatable and refractory CSC (accuracy, 83.9%). Then other multimodal clinical data were integrated with the FP deep features using XGBoost.The final combined model (DeepPDT-Net) outperformed the domain-specific ResNet50 (accuracy, 88.0%). The FP deep features had the greatest impact on DeepPDT-Net performance, followed by central foveal thickness and age. In conclusion, DeepPDT-Net could solve the PDT outcome prediction task challenging even to retinal specialists. This two-stage strategy, adopting transfer learning and concatenating multimodal data, can overcome the clinical prediction obstacles arising from insufficient datasets.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Representational ethical model calibration",
        "link": "https://www.nature.com/articles/s41746-022-00716-4",
        "publication_date": "04 Nov 2022",
        "abstract": "Equity is widely held to be fundamental to the ethics of healthcare. In the context of clinical decision-making, it rests on the comparative fidelity of the intelligence – evidence-based or intuitive – guiding the management of each individual patient. Though brought to recent attention by the individuating power of contemporary machine learning, such epistemic equity arises in the context of any decision guidance, whether traditional or innovative. Yet no general framework for its quantification, let alone assurance, currently exists. Here we formulate epistemic equity in terms of model fidelity evaluated over learnt multidimensional representations of identity crafted to maximise the captured diversity of the population, introducing a comprehensive framework for Representational Ethical Model Calibration. We demonstrate the use of the framework on large-scale multimodal data from UK Biobank to derive diverse representations of the population, quantify model performance, and institute responsive remediation. We offer our approach as a principled solution to quantifying and assuring epistemic equity in healthcare, with applications across the research, clinical, and regulatory domains.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Data-driven comorbidity analysis of 100 common disorders reveals patient subgroups with differing mortality risks and laboratory correlates",
        "link": "https://www.nature.com/articles/s41598-022-23090-3",
        "publication_date": "02 Nov 2022",
        "abstract": "The populational heterogeneity of a disease, in part due to comorbidity, poses several complexities. Individual comorbidity profiles, on the other hand, contain useful information to refine phenotyping, prognostication, and risk assessment, and they provide clues to underlying biology. Nevertheless, the spectrum and the implications of the diagnosis profiles remain largely uncharted. Here we mapped comorbidity patterns in 100 common diseases using 4-year retrospective data from 526,779 patients and developed an online tool to visualize the results. Our analysis exposed disease-specific patient subgroups with distinctive diagnosis patterns, survival functions, and laboratory correlates. Computational modeling and real-world data shed light on the structure, variation, and relevance of populational comorbidity patterns, paving the way for improved diagnostics, risk assessment, and individualization of care. Variation in outcomes and biological correlates of a disease emphasizes the importance of evaluating the generalizability of current treatment strategies, as well as considering the limitations that selective inclusion criteria pose on clinical trials.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Prediction of early-stage melanoma recurrence using clinical and histopathologic features",
        "link": "https://www.nature.com/articles/s41698-022-00321-4",
        "publication_date": "31 Oct 2022",
        "abstract": "Prognostic analysis for early-stage (stage I/II) melanomas is of paramount importance for customized surveillance and treatment plans. Since immune checkpoint inhibitors have recently been approved for stage IIB and IIC melanomas, prognostic tools to identify patients at high risk of recurrence have become even more critical. This study aims to assess the effectiveness of machine-learning algorithms in predicting melanoma recurrence using clinical and histopathologic features from Electronic Health Records (EHRs). We collected 1720 early-stage melanomas: 1172 from the Mass General Brigham healthcare system (MGB) and 548 from the Dana-Farber Cancer Institute (DFCI). We extracted 36 clinicopathologic features and used them to predict the recurrence risk with supervised machine-learning algorithms. Models were evaluated internally and externally: (1) five-fold cross-validation of the MGB cohort; (2) the MGB cohort for training and the DFCI cohort for testing independently. In the internal and external validations, respectively, we achieved a recurrence classification performance of AUC: 0.845 and 0.812, and a time-to-event prediction performance of time-dependent AUC: 0.853 and 0.820. Breslow tumor thickness and mitotic rate were identified as the most predictive features. Our results suggest that machine-learning algorithms can extract predictive signals from clinicopathologic features for early-stage melanoma recurrence prediction, which will enable the identification of patients that may benefit from adjuvant immunotherapy.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Artificial intelligence used to diagnose osteoporosis from risk factors in clinical data and proposing sports protocols",
        "link": "https://www.nature.com/articles/s41598-022-23184-y",
        "publication_date": "31 Oct 2022",
        "abstract": "Osteoporosis (OP) is characterized by diminished bone mass and deteriorating bone structure that increases the chance of fractures in the spine, hips, and wrists. In this paper, a novel data processing method of artificial intelligence (AI) is used for evaluating, predicting, and classifying OP risk factors in clinical data of men and women separately. Additionally, artificial intelligence was used to suggest the most appropriate sports programs for treatment. Data was obtained from dual-energy x-ray absorption scanning center of Ayatollah Kashani, Milad, and Khatam al-Anbia hospitals in Tehran, Iran. The subjects included 1224 men and women. Models were developed using decision tree, random forest (RF), k-nearest neighbor, support vector machine, gradient boosting (GB), Extra trees, Ada Boost (AB), and artificial neural network multilayer perceptron analysis to predict osteoporosis and to recommend sports programs. Data was divided into training (80%) and test dataset (20%). The results were obtained on a 20% test dataset. Area under receiver operating characteristic curve (AUROC) was used to compare the performance of the models. To predict healthy individuals, osteopenia and osteoporosis, the FR algorithm with AUROC 0.91 performed best in men and the GB algorithm with AUROC 0.95 performed best in women compared to other classification algorithms. Prediction of RF algorithm in women and men with AUROC 0.96 and 0.99, respectively, showed the highest performance in diagnosing the type of exercise for healthy individuals and those with osteopenia and OP. Eight AI algorithms were developed and compared to accurately predict osteoporosis risk factors and classify individuals into three categories: healthy, osteopenia, and OP. In addition, the AI algorithms were developed to recommend the most appropriate sports programs as part of treatment. Applying the AI algorithms in a clinical setting could help primary care providers classify patients with osteoporosis and improve treatment by recommending appropriate exercise programs.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "A robust COVID-19 mortality prediction calculator based on Lymphocyte count, Urea, C-Reactive Protein, Age and Sex (LUCAS) with chest X-rays",
        "link": "https://www.nature.com/articles/s41598-022-21803-2",
        "publication_date": "29 Oct 2022",
        "abstract": "There have been numerous risk tools developed to enable triaging of SARS-CoV-2 positive patients with diverse levels of complexity. Here we presented a simplified risk-tool based on minimal parameters and chest X-ray (CXR) image data that predicts the survival of adult SARS-CoV-2 positive patients at hospital admission. We analysed the NCCID database of patient blood variables and CXR images from 19 hospitals across the UK using multivariable logistic regression. The initial dataset was non-randomly split between development and internal validation dataset with 1434 and 310 SARS-CoV-2 positive patients, respectively. External validation of the final model was conducted on 741 Accident and Emergency (A&E) admissions with suspected SARS-CoV-2 infection from a separate NHS Trust. The LUCAS mortality score included five strongest predictors (Lymphocyte count, Urea, C-reactive protein, Age, Sex), which are available at any point of care with rapid turnaround of results. Our simple multivariable logistic model showed high discrimination for fatal outcome with the area under the receiving operating characteristics curve (AUC-ROC) in development cohort 0.765 (95% confidence interval (CI): 0.738–0.790), in internal validation cohort 0.744 (CI: 0.673–0.808), and in external validation cohort 0.752 (CI: 0.713–0.787). The discriminatory power of LUCAS increased slightly when including the CXR image data. LUCAS can be used to obtain valid predictions of mortality in patients within 60 days of SARS-CoV-2 RT-PCR results into low, moderate, high, or very high risk of fatality.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Spatio-temporal dynamics of three diseases caused by Aedes-borne arboviruses in Mexico",
        "link": "https://www.nature.com/articles/s43856-022-00192-7",
        "publication_date": "28 Oct 2022",
        "abstract": "The intensity of transmission of Aedes-borne viruses is heterogeneous, and multiple factors can contribute to variation at small spatial scales. Illuminating drivers of heterogeneity in prevalence over time and space would provide information for public health authorities. The objective of this study is to detect the spatiotemporal clusters and determine the risk factors of three major Aedes-borne diseases, Chikungunya virus (CHIKV), Dengue virus (DENV), and Zika virus (ZIKV) clusters in Mexico.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [],
            "Attacker Capability": []
        }
    },
    {
        "title": "Genetically-informed prediction of short-term Parkinson’s disease progression",
        "link": "https://www.nature.com/articles/s41531-022-00412-w",
        "publication_date": "28 Oct 2022",
        "abstract": "Parkinson’s disease (PD) treatments modify disease symptoms but have not been shown to slow progression, characterized by gradual and varied motor and non-motor changes overtime. Variation in PD progression hampers clinical research, resulting in long and expensive clinical trials prone to failure. Development of models for short-term PD progression prediction could be useful for shortening the time required to detect disease-modifying drug effects in clinical studies. PD progressors were defined by an increase in MDS-UPDRS scores at 12-, 24-, and 36-months post-baseline. Using only baseline features, PD progression was separately predicted across all timepoints and MDS-UPDRS subparts in independent, optimized, XGBoost models. These predictions plus baseline features were combined into a meta-predictor for 12-month MDS UPDRS Total progression. Data from the Parkinson’s Progression Markers Initiative (PPMI) were used for training with independent testing on the Parkinson’s Disease Biomarkers Program (PDBP) cohort. 12-month PD total progression was predicted with an F-measure 0.77, ROC AUC of 0.77, and PR AUC of 0.76 when tested on a hold-out PPMI set. When tested on PDBP we achieve a F-measure 0.75, ROC AUC of 0.74, and PR AUC of 0.73. Exclusion of genetic predictors led to the greatest loss in predictive accuracy; ROC AUC of 0.66, PR AUC of 0.66–0.68 for both PPMI and PDBP testing. Short-term PD progression can be predicted with a combination of survey-based, neuroimaging, physician examination, and genetic predictors. Dissection of the interplay between genetic risk, motor symptoms, non-motor symptoms, and longer-term expected rates of progression enable generalizable predictions.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Polygenic Health Index, General Health, and Pleiotropy: Sibling Analysis and Disease Risk Reduction",
        "link": "https://www.nature.com/articles/s41598-022-22637-8",
        "publication_date": "28 Oct 2022",
        "abstract": "We construct a polygenic health index as a weighted sum of polygenic risk scores for 20 major disease conditions, including, e.g., coronary artery disease, type 1 and 2 diabetes, schizophrenia, etc. Individual weights are determined by population-level estimates of impact on life expectancy. We validate this index in odds ratios and selection experiments using unrelated individuals and siblings (pairs and trios) from the UK Biobank. Individuals with higher index scores have decreased disease risk across almost all 20 diseases (no significant risk increases), and longer calculated life expectancy. When estimated Disability Adjusted Life Years (DALYs) are used as the performance metric, the gain from selection among ten individuals (highest index score vs average) is found to be roughly 4 DALYs. We find no statistical evidence for antagonistic trade-offs in risk reduction across these diseases. Correlations between genetic disease risks are found to be mostly positive and generally mild. These results have important implications for public health and also for fundamental issues such as pleiotropy and genetic architecture of human disease conditions.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Evaluation of machine learning algorithms for predicting direct-acting antiviral treatment failure among patients with chronic hepatitis C infection",
        "link": "https://www.nature.com/articles/s41598-022-22819-4",
        "publication_date": "27 Oct 2022",
        "abstract": "Despite the availability of efficacious direct-acting antiviral (DAA) therapy, the number of people infected with hepatitis C virus (HCV) continues to rise, and HCV remains a leading cause of liver-related morbidity, liver transplantation, and mortality. We developed and validated machine learning (ML) algorithms to predict DAA treatment failure. Using the HCV-TARGET registry of adults who initiated all-oral DAA treatment, we developed elastic net (EN), random forest (RF), gradient boosting machine (GBM), and feedforward neural network (FNN) ML algorithms. Model performances were compared with multivariable logistic regression (MLR) by assessing C statistics and other prediction evaluation metrics. Among 6525 HCV-infected adults, 308 patients (4.7%) experienced DAA treatment failure. ML models performed similarly in predicting DAA treatment failure (C statistic [95% CI]: EN, 0.74 [0.69–0.79]; RF, 0.74 [0.69–0.80]; GBM, 0.72 [0.67–0.78]; FNN, 0.75 [0.70–0.80]), and all 4 outperformed MLR (C statistic [95% CI]: 0.51 [0.46–0.57]), and EN used the fewest predictors (n = 27). With Youden index, the EN had 58.4% sensitivity and 77.8% specificity, and nine patients were needed to evaluate to identify 1 DAA treatment failure. Over 60% treatment failure were classified in top three risk decile subgroups. EN-identified predictors included male sex, treatment < 8 weeks, treatment discontinuation due to adverse events, albumin level < 3.5 g/dL, total bilirubin level > 1.2 g/dL, advanced liver disease, and use of tobacco, alcohol, or vitamins. Addressing modifiable factors of DAA treatment failure may reduce the burden of retreatment. Machine learning algorithms have the potential to inform public health policies regarding curative treatment of HCV.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Benchmarking emergency department prediction models with machine learning and public electronic health records",
        "link": "https://www.nature.com/articles/s41597-022-01782-9",
        "publication_date": "27 Oct 2022",
        "abstract": "The demand for emergency department (ED) services is increasing across the globe, particularly during the current COVID-19 pandemic. Clinical triage and risk assessment have become increasingly challenging due to the shortage of medical resources and the strain on hospital infrastructure caused by the pandemic. As a result of the widespread use of electronic health records (EHRs), we now have access to a vast amount of clinical data, which allows us to develop prediction models and decision support systems to address these challenges. To date, there is no widely accepted clinical prediction benchmark related to the ED based on large-scale public EHRs. An open-source benchmark data platform would streamline research workflows by eliminating cumbersome data preprocessing, and facilitate comparisons among different studies and methodologies. Based on the Medical Information Mart for Intensive Care IV Emergency Department (MIMIC-IV-ED) database, we created a benchmark dataset and proposed three clinical prediction benchmarks. This study provides future researchers with insights, suggestions, and protocols for managing data and developing predictive tools for emergency care.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Traditional ML",
            "DNN",
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [],
            "Attacker Identity": [
                "patient",
                "healthcare practitioner"
            ],
            "Attacker Capability": []
        }
    },
    {
        "title": "Synthesis and preliminary biological evaluation of gabactyzine, a benactyzine-GABA mutual prodrug, as an organophosphate antidote",
        "link": "https://www.nature.com/articles/s41598-022-23141-9",
        "publication_date": "27 Oct 2022",
        "abstract": "Organophosphates (OPs) are inhibitors of acetylcholinesterase and have deleterious effects on the central nervous system. Clinical manifestations of OP poisoning include convulsions, which represent an underlying toxic neuro-pathological process, leading to permanent neuronal damage. This neurotoxicity is mediated through the cholinergic, GABAergic and glutamatergic (NMDA) systems. Pharmacological interventions in OP poisoning are designed to mitigate these specific neuro-pathological pathways, using anticholinergic drugs and GABAergic agents. Benactyzine is a combined anticholinergic, anti-NMDA compound. Based on previous development of novel GABA derivatives (such as prodrugs based on perphenazine for the treatment of schizophrenia and nortriptyline against neuropathic pain), we describe the synthesis and preliminary testing of a mutual prodrug ester of benactyzine and GABA. It is assumed that once the ester crosses the blood–brain-barrier it will undergo hydrolysis, releasing benactyzine and GABA, which are expected to act synergistically. The combined release of both compounds in the brain offers several advantages over the current OP poisoning treatment protocol: improved efficacy and safety profile (where the inhibitory properties of GABA are expected to counteract the anticholinergic cognitive adverse effects of benactyzine) and enhanced chemical stability compared to benactyzine alone. We present here preliminary results of animal studies, showing promising results with early gabactyzine administration.",
        "conclusions": "Conclusions not available",
        "ml_techniques": [
            "Gen AI"
        ],
        "security_privacy": {
            "Attack Types": [
                "poisoning"
            ],
            "Attacker Identity": [
                "patient"
            ],
            "Attacker Capability": []
        }
    }
]